#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyTorchæ¨¡å‹å·¥å…·ç±»
ç”¨äºåŠ è½½å’Œè¿è¡Œæ— äººæœºåœºæ™¯åˆ†ç±»çš„PyTorchæ¨¡å‹
"""

# ä¸´æ—¶ä¿®å¤ï¼šåœ¨å¯¼å…¥ torch å‰å°è¯•å¤„ç† typing_extensions é—®é¢˜
try:
    import typing_extensions
    # æ£€æŸ¥ TypeIs æ˜¯å¦å¯ç”¨ï¼Œå¦‚æœä¸å¯ç”¨åˆ™æ¨¡æ‹Ÿä¸€ä¸ª
    if not hasattr(typing_extensions, 'TypeIs'):
        typing_extensions.TypeIs = type(lambda: None)
except ImportError:
    pass

# å¯¼å…¥æ ¸å¿ƒä¾èµ–åº“
import torch  # PyTorchæ ¸å¿ƒåº“ï¼Œç”¨äºæ¨¡å‹æ„å»ºå’Œæ¨ç†
import torch.nn as nn  # ç¥ç»ç½‘ç»œå±‚æ¨¡å—
import torchvision.transforms as transforms  # å›¾åƒé¢„å¤„ç†å·¥å…·
from PIL import Image  # PILåº“ï¼Œç”¨äºå›¾åƒè¯»å–å’Œæ ¼å¼è½¬æ¢
import numpy as np  # æ•°å€¼è®¡ç®—åº“ï¼Œå¤„ç†å›¾åƒæ•°ç»„
import cv2  # OpenCVåº“ï¼Œå¤„ç†è§†é¢‘/å›¾åƒæ•°æ®
import os  # æ–‡ä»¶è·¯å¾„æ“ä½œåº“

# ... å…¶ä½™ä»£ç ä¿æŒä¸å˜ ...
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PyTorchæ¨¡å‹å·¥å…·ç±»
ç”¨äºåŠ è½½å’Œè¿è¡Œæ— äººæœºåœºæ™¯åˆ†ç±»çš„PyTorchæ¨¡å‹
æ ¸å¿ƒåŠŸèƒ½ï¼š
1. æ”¯æŒè‡ªå®šä¹‰CNN/ResNet18/MobileNetV2ä¸‰ç§æ¨¡å‹æ¶æ„åŠ è½½
2. å®ç°å›¾åƒé¢„å¤„ç†ã€å•å¼ /æ‰¹é‡å›¾åƒé¢„æµ‹
3. é€‚é…CPU/GPUè®¾å¤‡ï¼Œè‡ªåŠ¨æ£€æµ‹ç¡¬ä»¶ç¯å¢ƒ
"""

# å¯¼å…¥æ ¸å¿ƒä¾èµ–åº“
import torch  # PyTorchæ ¸å¿ƒåº“ï¼Œç”¨äºæ¨¡å‹æ„å»ºå’Œæ¨ç†
import torch.nn as nn  # ç¥ç»ç½‘ç»œå±‚æ¨¡å—
import torchvision.transforms as transforms  # å›¾åƒé¢„å¤„ç†å·¥å…·
from PIL import Image  # PILåº“ï¼Œç”¨äºå›¾åƒè¯»å–å’Œæ ¼å¼è½¬æ¢
import numpy as np  # æ•°å€¼è®¡ç®—åº“ï¼Œå¤„ç†å›¾åƒæ•°ç»„
import cv2  # OpenCVåº“ï¼Œå¤„ç†è§†é¢‘/å›¾åƒæ•°æ®
import os  # æ–‡ä»¶è·¯å¾„æ“ä½œåº“


class PyTorchDroneModel:
    """
    PyTorchæ— äººæœºè§†è§‰åœºæ™¯åˆ†ç±»æ¨¡å‹ç±»
    å°è£…æ¨¡å‹åŠ è½½ã€å›¾åƒé¢„å¤„ç†ã€åœºæ™¯åˆ†ç±»é¢„æµ‹ç­‰æ ¸å¿ƒåŠŸèƒ½
    æ”¯æŒçš„åœºæ™¯ç±»åˆ«ï¼šForest(æ£®æ—)ã€Fire(ç«ç¾)ã€City(åŸå¸‚)ã€Animal(åŠ¨ç‰©)ã€Vehicle(è½¦è¾†)ã€Water(æ°´åŸŸ)
    """

    def __init__(self, model_path=None, device=None):
        """
        åˆå§‹åŒ–æ¨¡å‹ç±»

        Args:
            model_path (str, optional): é¢„è®­ç»ƒæ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤None
            device (torch.device, optional): æ¨¡å‹è¿è¡Œè®¾å¤‡ï¼ˆcpu/cudaï¼‰ï¼Œé»˜è®¤è‡ªåŠ¨æ£€æµ‹
        """
        # æ¨¡å‹å®ä¾‹åˆå§‹åŒ–
        self.model = None
        # è¿è¡Œè®¾å¤‡åˆå§‹åŒ–
        self.device = None
        # åœºæ™¯åˆ†ç±»ç±»åˆ«åç§°ï¼ˆä¸è®­ç»ƒæ—¶æ ‡ç­¾å¯¹åº”ï¼‰
        self.class_names = ['Forest', 'Fire', 'City', 'Animal', 'Vehicle', 'Water']
        # æ¨¡å‹è¾“å…¥å›¾åƒå°ºå¯¸ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        self.img_size = (224, 224)

        # è‡ªåŠ¨æ£€æµ‹/æŒ‡å®šè¿è¡Œè®¾å¤‡
        if device is None:
            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        else:
            self.device = device
        print(f"âœ… ä½¿ç”¨è®¾å¤‡: {self.device}")

        # å®šä¹‰å›¾åƒé¢„å¤„ç†æµæ°´çº¿ï¼ˆä¸è®­ç»ƒæ—¶é¢„å¤„ç†é€»è¾‘ä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Resize(self.img_size),  # è°ƒæ•´å›¾åƒå°ºå¯¸
            transforms.ToTensor(),  # è½¬æ¢ä¸ºTensorï¼ˆ0-1å½’ä¸€åŒ–ï¼‰
            # æ ‡å‡†åŒ–ï¼ˆä½¿ç”¨ImageNetå‡å€¼/æ ‡å‡†å·®ï¼Œé€‚é…é¢„è®­ç»ƒæ¨¡å‹ï¼‰
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

        # å¦‚æœä¼ å…¥æœ‰æ•ˆæ¨¡å‹è·¯å¾„ï¼Œè‡ªåŠ¨åŠ è½½æ¨¡å‹
        if model_path and os.path.exists(model_path):
            self.load_model(model_path)

    def define_model_architecture(self):
        """
        å®šä¹‰è‡ªå®šä¹‰CNNæ¨¡å‹æ¶æ„ï¼ˆéœ€ä¸è®­ç»ƒæ—¶çš„æ¨¡å‹ç»“æ„å®Œå…¨ä¸€è‡´ï¼‰
        é€‚ç”¨äºæ— äººæœºåœºæ™¯åˆ†ç±»çš„è½»é‡çº§å·ç§¯ç¥ç»ç½‘ç»œ

        Returns:
            nn.Module: è‡ªå®šä¹‰CNNæ¨¡å‹å®ä¾‹
        """

        class DroneCNN(nn.Module):
            """å†…éƒ¨è‡ªå®šä¹‰CNNæ¨¡å‹ç±»"""
            def __init__(self, num_classes=6):
                super(DroneCNN, self).__init__()
                # ç‰¹å¾æå–å±‚ï¼ˆ4å±‚å·ç§¯+æ‰¹å½’ä¸€åŒ–+æ¿€æ´»+æ± åŒ–+dropoutï¼‰
                self.features = nn.Sequential(
                    # ç¬¬ä¸€å±‚å·ç§¯ï¼š3é€šé“è¾“å…¥â†’32é€šé“è¾“å‡ºï¼Œ3Ã—3å·ç§¯æ ¸ï¼Œå¡«å……1
                    nn.Conv2d(3, 32, kernel_size=3, padding=1),
                    nn.BatchNorm2d(32),  # æ‰¹å½’ä¸€åŒ–ï¼ŒåŠ é€Ÿè®­ç»ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
                    nn.ReLU(inplace=True),  # ReLUæ¿€æ´»å‡½æ•°ï¼Œinplace=TrueèŠ‚çœå†…å­˜
                    nn.MaxPool2d(kernel_size=2, stride=2),  # 2Ã—2æœ€å¤§æ± åŒ–ï¼Œæ­¥é•¿2
                    nn.Dropout(0.25),  # Dropoutå±‚ï¼Œéšæœºä¸¢å¼ƒ25%ç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ

                    # ç¬¬äºŒå±‚å·ç§¯ï¼š32é€šé“â†’64é€šé“
                    nn.Conv2d(32, 64, kernel_size=3, padding=1),
                    nn.BatchNorm2d(64),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25),

                    # ç¬¬ä¸‰å±‚å·ç§¯ï¼š64é€šé“â†’128é€šé“
                    nn.Conv2d(64, 128, kernel_size=3, padding=1),
                    nn.BatchNorm2d(128),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25),

                    # ç¬¬å››å±‚å·ç§¯ï¼š128é€šé“â†’256é€šé“
                    nn.Conv2d(128, 256, kernel_size=3, padding=1),
                    nn.BatchNorm2d(256),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=2, stride=2),
                    nn.Dropout(0.25),
                )

                # åˆ†ç±»å™¨å±‚ï¼ˆå…¨è¿æ¥å±‚ï¼‰
                self.classifier = nn.Sequential(
                    nn.Flatten(),  # å±•å¹³ç‰¹å¾å›¾ï¼š256Ã—14Ã—14 â†’ 256Ã—14Ã—14
                    # å…¨è¿æ¥å±‚1ï¼šç‰¹å¾å±•å¹³åâ†’512ç»´éšè—å±‚ï¼ˆ224/2^4=14ï¼Œ4æ¬¡æ± åŒ–åå°ºå¯¸ï¼‰
                    nn.Linear(256 * 14 * 14, 512),
                    nn.ReLU(inplace=True),
                    nn.Dropout(0.5),  # ä¸¢å¼ƒ50%ç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
                    nn.Linear(512, num_classes)  # è¾“å‡ºå±‚ï¼š512â†’åˆ†ç±»ç±»åˆ«æ•°
                )

            def forward(self, x):
                """å‰å‘ä¼ æ’­é€»è¾‘"""
                x = self.features(x)  # ç‰¹å¾æå–
                x = self.classifier(x)  # åˆ†ç±»é¢„æµ‹
                return x

        # è¿”å›è‡ªå®šä¹‰æ¨¡å‹å®ä¾‹ï¼ˆåˆ†ç±»ç±»åˆ«æ•°ä¸åœºæ™¯ç±»åˆ«æ•°ä¸€è‡´ï¼‰
        return DroneCNN(num_classes=len(self.class_names))

    def load_resnet18_model(self):
        """
        åŠ è½½é¢„è®­ç»ƒçš„ResNet18æ¨¡å‹å¹¶é€‚é…è‡ªå®šä¹‰åˆ†ç±»ä»»åŠ¡
        ä¿®æ”¹æœ€åä¸€å±‚å…¨è¿æ¥å±‚ï¼Œé€‚é…æ— äººæœº6ç±»åœºæ™¯åˆ†ç±»

        Returns:
            nn.Module: é€‚é…åçš„ResNet18æ¨¡å‹å®ä¾‹
        """
        from torchvision import models

        # åŠ è½½ResNet18éª¨æ¶ï¼ˆä¸åŠ è½½ImageNeté¢„è®­ç»ƒæƒé‡ï¼Œé¿å…ä¸è‡ªå®šä¹‰ä»»åŠ¡å†²çªï¼‰
        model = models.resnet18(pretrained=False)
        # è·å–æœ€åä¸€å±‚å…¨è¿æ¥å±‚çš„è¾“å…¥ç‰¹å¾æ•°
        num_features = model.fc.in_features
        # æ›¿æ¢æœ€åä¸€å±‚å…¨è¿æ¥å±‚ï¼šåŸ1000ç±»â†’è‡ªå®šä¹‰6ç±»
        model.fc = nn.Linear(num_features, len(self.class_names))

        return model

    def load_mobilenetv2_model(self):
        """
        åŠ è½½é¢„è®­ç»ƒçš„MobileNetV2æ¨¡å‹å¹¶é€‚é…è‡ªå®šä¹‰åˆ†ç±»ä»»åŠ¡
        è½»é‡çº§æ¨¡å‹ï¼Œé€‚é…æ— äººæœºåµŒå…¥å¼è®¾å¤‡

        Returns:
            nn.Module: é€‚é…åçš„MobileNetV2æ¨¡å‹å®ä¾‹
        """
        from torchvision import models

        # åŠ è½½MobileNetV2éª¨æ¶ï¼ˆä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼‰
        model = models.mobilenet_v2(pretrained=False)
        # æ›¿æ¢åˆ†ç±»å™¨æœ€åä¸€å±‚ï¼šåŸ1000ç±»â†’è‡ªå®šä¹‰6ç±»
        model.classifier[1] = nn.Linear(model.classifier[1].in_features, len(self.class_names))

        return model

    def load_model(self, model_path, model_type='custom'):
        """
        åŠ è½½é¢„è®­ç»ƒPyTorchæ¨¡å‹æƒé‡

        Args:
            model_path (str): æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆ.pth/.ptï¼‰
            model_type (str): æ¨¡å‹æ¶æ„ç±»å‹ï¼Œå¯é€‰['custom', 'resnet18', 'mobilenet']

        Returns:
            bool: åŠ è½½æˆåŠŸè¿”å›Trueï¼Œå¤±è´¥è¿”å›False
        """
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½PyTorchæ¨¡å‹: {model_path}")

        try:
            # æ ¹æ®æ¨¡å‹ç±»å‹åˆ›å»ºå¯¹åº”æ¶æ„çš„æ¨¡å‹å®ä¾‹
            if model_type == 'resnet18':
                self.model = self.load_resnet18_model()
            elif model_type == 'mobilenet':
                self.model = self.load_mobilenetv2_model()
            else:  # é»˜è®¤åŠ è½½è‡ªå®šä¹‰CNN
                self.model = self.define_model_architecture()

            # åŠ è½½æ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆå…¼å®¹å¤šç§ä¿å­˜æ ¼å¼ï¼‰
            checkpoint = torch.load(model_path, map_location=self.device)

            if isinstance(checkpoint, dict):
                # æƒ…å†µ1ï¼šä¿å­˜çš„æ˜¯æ£€æŸ¥ç‚¹å­—å…¸ï¼ˆåŒ…å«state_dict/ä¼˜åŒ–å™¨å‚æ•°ç­‰ï¼‰
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                elif 'state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['state_dict'])
                else:
                    # æƒ…å†µ2ï¼šå­—å…¸ä»…åŒ…å«æ¨¡å‹æƒé‡
                    self.model.load_state_dict(checkpoint)
            else:
                # æƒ…å†µ3ï¼šç›´æ¥ä¿å­˜çš„æ¨¡å‹å®ä¾‹
                self.model = checkpoint

            # å°†æ¨¡å‹ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆCPU/GPUï¼‰
            self.model = self.model.to(self.device)

            # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆç¦ç”¨Dropout/BatchNormçš„è®­ç»ƒè¡Œä¸ºï¼‰
            self.model.eval()

            # æ‰“å°åŠ è½½æˆåŠŸä¿¡æ¯
            print(f"âœ… PyTorchæ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"ğŸ“Š æ¨¡å‹ç»“æ„: {self.model.__class__.__name__}")
            # è®¡ç®—å¹¶æ‰“å°æ¨¡å‹æ€»å‚æ•°æ•°é‡
            total_params = sum(p.numel() for p in self.model.parameters())
            print(f"ğŸ“Š å‚æ•°æ•°é‡: {total_params:,}")

            return True

        except Exception as e:
            # æ•è·åŠ è½½è¿‡ç¨‹ä¸­çš„æ‰€æœ‰å¼‚å¸¸
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.model = None
            return False

    def preprocess_image(self, image):
        """
        å›¾åƒé¢„å¤„ç†ï¼šå°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºæ¨¡å‹å¯æ¥å—çš„Tensoræ ¼å¼

        Args:
            image (np.ndarray/PIL.Image): è¾“å…¥å›¾åƒï¼ˆOpenCVæ ¼å¼(BGR)æˆ–PILæ ¼å¼(RGB)ï¼‰

        Returns:
            torch.Tensor: é¢„å¤„ç†åçš„4ç»´Tensor (batch_size, channels, height, width)
        """
        # å¤„ç†OpenCVæ ¼å¼å›¾åƒï¼ˆBGRâ†’RGBï¼Œè½¬æ¢ä¸ºPILå›¾åƒï¼‰
        if isinstance(image, np.ndarray):
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGRâ†’RGBè½¬æ¢
            pil_image = Image.fromarray(image_rgb)  # æ•°ç»„â†’PILå›¾åƒ
        else:
            # ç›´æ¥ä½¿ç”¨PILå›¾åƒ
            pil_image = image

        # åº”ç”¨é¢„å¤„ç†æµæ°´çº¿
        tensor = self.transform(pil_image)

        # æ·»åŠ æ‰¹æ¬¡ç»´åº¦ï¼ˆæ¨¡å‹è¦æ±‚æ‰¹é‡è¾“å…¥ï¼Œå•å¼ å›¾åƒbatch_size=1ï¼‰
        tensor = tensor.unsqueeze(0)

        # å°†Tensorç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
        tensor = tensor.to(self.device)

        return tensor

    def predict(self, image):
        """
        å•å¼ å›¾åƒåœºæ™¯åˆ†ç±»é¢„æµ‹

        Args:
            image (np.ndarray/PIL.Image): è¾“å…¥å›¾åƒï¼ˆOpenCV/PILæ ¼å¼ï¼‰

        Returns:
            tuple: (é¢„æµ‹ç±»åˆ«åç§°, ç½®ä¿¡åº¦)ï¼Œé¢„æµ‹å¤±è´¥è¿”å›(None, 0)
        """
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
        if self.model is None:
            print("âš ï¸  æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•é¢„æµ‹")
            return None, 0

        try:
            # å›¾åƒé¢„å¤„ç†
            input_tensor = self.preprocess_image(image)

            # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ˆæ¨ç†é˜¶æ®µæ— éœ€è®¡ç®—æ¢¯åº¦ï¼Œæå‡é€Ÿåº¦ï¼ŒèŠ‚çœå†…å­˜ï¼‰
            with torch.no_grad():
                # æ¨¡å‹å‰å‘ä¼ æ’­ï¼Œè·å–é¢„æµ‹logits
                outputs = self.model(input_tensor)

                # è®¡ç®—softmaxæ¦‚ç‡ï¼ˆå°†logitsè½¬æ¢ä¸º0-1çš„æ¦‚ç‡åˆ†å¸ƒï¼‰
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                # è·å–æœ€å¤§æ¦‚ç‡çš„ç±»åˆ«ç´¢å¼•å’Œç½®ä¿¡åº¦
                confidence, predicted = torch.max(probabilities, 1)

                # è½¬æ¢ä¸ºPythonæ ‡é‡ï¼ˆä»Tensorâ†’æ•°å€¼ï¼‰
                class_idx = predicted.item()
                confidence_value = confidence.item()

                # è·å–ç±»åˆ«åç§°
                if 0 <= class_idx < len(self.class_names):
                    class_name = self.class_names[class_idx]
                else:
                    class_name = f"Class_{class_idx}"  # æœªçŸ¥ç±»åˆ«å…œåº•

                return class_name, confidence_value

        except Exception as e:
            # æ•è·é¢„æµ‹è¿‡ç¨‹ä¸­çš„å¼‚å¸¸
            print(f"âŒ é¢„æµ‹å¤±è´¥: {e}")
            return None, 0

    def predict_batch(self, images):
        """
        æ‰¹é‡å›¾åƒåœºæ™¯åˆ†ç±»é¢„æµ‹ï¼ˆæå‡æ‰¹é‡å¤„ç†æ•ˆç‡ï¼‰

        Args:
            images (list): å›¾åƒåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºnp.ndarray/PIL.Imageæ ¼å¼

        Returns:
            tuple: (é¢„æµ‹ç±»åˆ«åç§°åˆ—è¡¨, ç½®ä¿¡åº¦åˆ—è¡¨)ï¼Œå¤±è´¥è¿”å›([], [])
        """
        if self.model is None:
            print("âš ï¸  æ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•æ‰¹é‡é¢„æµ‹")
            return [], []

        try:
            # é¢„å¤„ç†æ‰€æœ‰å›¾åƒï¼Œç”ŸæˆTensoråˆ—è¡¨
            tensors = []
            for img in images:
                tensor = self.preprocess_image(img)
                tensors.append(tensor)

            # å †å ä¸ºæ‰¹é‡Tensorï¼ˆbatch_size=Nï¼‰
            batch = torch.cat(tensors, dim=0)
            batch = batch.to(self.device)

            # æ¨ç†é˜¶æ®µç¦ç”¨æ¢¯åº¦è®¡ç®—
            with torch.no_grad():
                outputs = self.model(batch)
                probabilities = torch.nn.functional.softmax(outputs, dim=1)
                confidences, predicted = torch.max(probabilities, 1)

            # è§£ææ‰¹é‡é¢„æµ‹ç»“æœ
            results = []
            conf_values = []
            for i in range(len(images)):
                class_idx = predicted[i].item()
                # æ˜ å°„ç±»åˆ«ç´¢å¼•åˆ°åç§°
                if 0 <= class_idx < len(self.class_names):
                    class_name = self.class_names[class_idx]
                else:
                    class_name = f"Class_{class_idx}"

                results.append(class_name)
                conf_values.append(confidences[i].item())

            return results, conf_values

        except Exception as e:
            print(f"âŒ æ‰¹é‡é¢„æµ‹å¤±è´¥: {e}")
            return [], []


def load_pytorch_model(model_path, model_type='custom'):
    """
    åŠ è½½PyTorchæ¨¡å‹çš„ä¾¿æ·å·¥å‚å‡½æ•°

    Args:
        model_path (str): æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        model_type (str): æ¨¡å‹æ¶æ„ç±»å‹ï¼Œå¯é€‰['custom', 'resnet18', 'mobilenet']

    Returns:
        PyTorchDroneModel: æ¨¡å‹å®ä¾‹ï¼ˆåŠ è½½æˆåŠŸï¼‰/Noneï¼ˆåŠ è½½å¤±è´¥ï¼‰
    """
    model = PyTorchDroneModel()
    success = model.load_model(model_path, model_type)
    return model if success else None


def test_model():
    """
    æµ‹è¯•å‡½æ•°ï¼šéªŒè¯æ¨¡å‹æ¶æ„åˆ›å»ºã€åŠ è½½ç­‰æ ¸å¿ƒåŠŸèƒ½
    æ— éœ€å®é™…æƒé‡æ–‡ä»¶ï¼Œä»…æµ‹è¯•æ¨¡å‹ç»“æ„å®Œæ•´æ€§
    """
    print("ğŸ§ª å¼€å§‹æµ‹è¯•PyTorchæ¨¡å‹å·¥å…·ç±»...")

    # åˆ›å»ºéšæœºæµ‹è¯•å›¾åƒï¼ˆ224Ã—224Ã—3ï¼Œæ¨¡æ‹ŸRGBå›¾åƒï¼‰
    test_image = np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8)

    # åˆå§‹åŒ–æ¨¡å‹å®ä¾‹
    model = PyTorchDroneModel()

    # æµ‹è¯•1ï¼šè‡ªå®šä¹‰CNNæ¨¡å‹æ¶æ„åˆ›å»º
    print("\n1. æµ‹è¯•è‡ªå®šä¹‰CNNæ¨¡å‹æ¶æ„...")
    custom_model = model.define_model_architecture()
    total_params = sum(p.numel() for p in custom_model.parameters())
    print(f"âœ… è‡ªå®šä¹‰æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {total_params:,}")

    # æµ‹è¯•2ï¼šResNet18æ¨¡å‹æ¶æ„åŠ è½½
    print("\n2. æµ‹è¯•ResNet18æ¨¡å‹æ¶æ„...")
    resnet_model = model.load_resnet18_model()
    total_params = sum(p.numel() for p in resnet_model.parameters())
    print(f"âœ… ResNet18æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {total_params:,}")

    # æµ‹è¯•3ï¼šMobileNetV2æ¨¡å‹æ¶æ„åŠ è½½
    print("\n3. æµ‹è¯•MobileNetV2æ¨¡å‹æ¶æ„...")
    mobilenet_model = model.load_mobilenetv2_model()
    total_params = sum(p.numel() for p in mobilenet_model.parameters())
    print(f"âœ… MobileNetV2æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œå‚æ•°æ•°é‡: {total_params:,}")

    print("\nğŸ§ª æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")


# ä¸»å‡½æ•°ï¼šä»…åœ¨ç›´æ¥è¿è¡Œè„šæœ¬æ—¶æ‰§è¡Œæµ‹è¯•
if __name__ == "__main__":
    test_model()