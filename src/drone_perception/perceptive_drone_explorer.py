# -*- coding: utf-8 -*-
"""
AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢æ— äººæœº - æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆï¼ˆçº¢è‰²ã€è“è‰²ä¸é»‘è‰²ç‰©ä½“æ£€æµ‹ç‰ˆï¼‰
æ ¸å¿ƒï¼šè§†è§‰æ„ŸçŸ¥ â†’ è¯­ä¹‰ç†è§£ â†’ æ™ºèƒ½å†³ç­– â†’ å®‰å…¨æ‰§è¡Œ
é›†æˆï¼šé…ç½®ç®¡ç†ã€æ—¥å¿—ç³»ç»Ÿã€å¼‚å¸¸æ¢å¤ã€å‰è§†çª—å£æ˜¾ç¤º
æ–°å¢ï¼šå‘é‡åœºé¿éšœç®—æ³•ã€åŸºäºç½‘æ ¼çš„ä¿¡æ¯å¢ç›Šæ¢ç´¢ã€å¹³æ»‘é£è¡Œæ§åˆ¶
æ–°å¢ï¼šæ€§èƒ½ç›‘æ§ä¸æ•°æ®é—­ç¯ç³»ç»Ÿã€çº¢è‰²ã€è“è‰²ä¸é»‘è‰²ç‰©ä½“æ£€æµ‹ä¸è®°å½•
æ–°å¢ï¼šä¿¡æ¯æ˜¾ç¤ºçª—å£ï¼Œåˆ†ç¦»å‰è§†ç”»é¢ä¸ç³»ç»Ÿä¿¡æ¯
ç‰ˆæœ¬: 3.6 (åŒçª—å£ä¸‰è‰²ç‰©ä½“æ£€æµ‹ç‰ˆ)
"""

import airsim
import time
import numpy as np
import cv2
import math
import json
import csv
from collections import deque
from dataclasses import dataclass
from enum import Enum
import threading
import queue
import signal
import sys
from typing import Tuple, List, Optional, Dict, Set, Any
import traceback
import logging
from datetime import datetime
import random
import psutil
import os
import gc

# å¯¼å…¥PILç”¨äºä¸­æ–‡æ–‡æœ¬ç»˜åˆ¶
try:
    from PIL import Image, ImageDraw, ImageFont
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False
    print("âš ï¸ PIL/Pillowæœªå®‰è£…ï¼Œä¸­æ–‡æ˜¾ç¤ºå¯èƒ½ä¸æ­£å¸¸ã€‚è¯·è¿è¡Œ: pip install Pillow")

# å…¨å±€å­—ä½“ç¼“å­˜
_chinese_font_cache = {}

# ============ å¯¼å…¥é…ç½®æ–‡ä»¶ ============
try:
    import config
    CONFIG_LOADED = True
except ImportError as e:
    print(f"âŒ æ— æ³•åŠ è½½é…ç½®æ–‡ä»¶ config.py: {e}")
    print("æ­£åœ¨ä½¿ç”¨é»˜è®¤é…ç½®...")
    CONFIG_LOADED = False
    class DefaultConfig:
        EXPLORATION = {'TOTAL_TIME': 120, 'PREFERRED_SPEED': 2.5, 'BASE_HEIGHT': -15.0,
                      'MAX_ALTITUDE': -30.0, 'MIN_ALTITUDE': -5.0, 'TAKEOFF_HEIGHT': -10.0}
        PERCEPTION = {'DEPTH_NEAR_THRESHOLD': 5.0, 'DEPTH_SAFE_THRESHOLD': 10.0,
                     'MIN_GROUND_CLEARANCE': 2.0, 'MAX_PITCH_ANGLE_DEG': 15,
                     'SCAN_ANGLES': [-60, -45, -30, -15, 0, 15, 30, 45, 60],
                     'HEIGHT_STRATEGY': {'STEEP_SLOPE': -20.0, 'OPEN_SPACE': -12.0,
                                         'DEFAULT': -15.0, 'SLOPE_THRESHOLD': 5.0,
                                         'OPENNESS_THRESHOLD': 0.7},
                     'RED_OBJECT_DETECTION': {'ENABLED': True, 'MIN_AREA': 50,
                                            'MAX_AREA': 10000, 'UPDATE_INTERVAL': 1.0,
                                            'MEMORY_TIME': 5.0},
                     'BLUE_OBJECT_DETECTION': {'ENABLED': True, 'MIN_AREA': 50,
                                              'MAX_AREA': 10000, 'UPDATE_INTERVAL': 1.0,
                                              'MEMORY_TIME': 5.0},
                     'BLACK_OBJECT_DETECTION': {'ENABLED': True, 'MIN_AREA': 50,
                                               'MAX_AREA': 10000, 'UPDATE_INTERVAL': 1.0,
                                               'MEMORY_TIME': 5.0}}
        DISPLAY = {'FRONT_VIEW_WINDOW': {'NAME': "æ— äººæœºå‰è§†ç”»é¢", 'WIDTH': 640, 'HEIGHT': 480,
                                        'ENABLE_SHARPENING': True, 'SHOW_INFO_OVERLAY': True,
                                        'REFRESH_RATE_MS': 30, 'SHOW_RED_OBJECTS': True,
                                        'SHOW_BLUE_OBJECTS': True, 'SHOW_BLACK_OBJECTS': True},
                   'INFO_WINDOW': {'NAME': "æ— äººæœºä¿¡æ¯é¢æ¿", 'WIDTH': 800, 'HEIGHT': 600,
                                  'BACKGROUND_COLOR': (20, 20, 30), 'TEXT_COLOR': (220, 220, 255),
                                  'HIGHLIGHT_COLOR': (0, 200, 255), 'WARNING_COLOR': (0, 100, 255),
                                  'SUCCESS_COLOR': (0, 255, 150), 'REFRESH_RATE_MS': 100,
                                  'SHOW_GRID': True, 'GRID_SIZE': 300,
                                  'SHOW_OBJECTS_STATS': True, 'SHOW_SYSTEM_STATS': True,
                                  'SHOW_PERFORMANCE': True}}
        SYSTEM = {'LOG_LEVEL': 'INFO', 'LOG_TO_FILE': True, 'LOG_FILENAME': 'drone_log.txt',
                 'MAX_RECONNECT_ATTEMPTS': 3, 'RECONNECT_DELAY': 2.0,
                 'ENABLE_HEALTH_CHECK': True, 'HEALTH_CHECK_INTERVAL': 20}
        CAMERA = {'DEFAULT_NAME': "0",
                 'RED_COLOR_RANGE': {'LOWER1': [0, 120, 70], 'UPPER1': [10, 255, 255],
                                    'LOWER2': [170, 120, 70], 'UPPER2': [180, 255, 255]},
                 'BLUE_COLOR_RANGE': {'LOWER': [100, 150, 50], 'UPPER': [130, 255, 255]},
                 'BLACK_COLOR_RANGE': {'LOWER': [0, 0, 0], 'UPPER': [180, 255, 50]}}
        MANUAL = {
            'CONTROL_SPEED': 3.0,
            'ALTITUDE_SPEED': 2.0,
            'YAW_SPEED': 30.0,
            'ENABLE_AUTO_HOVER': True,
            'DISPLAY_CONTROLS': True,
            'SAFETY_ENABLED': True,
            'MAX_MANUAL_SPEED': 5.0,
            'MIN_ALTITUDE_LIMIT': -5.0,
            'MAX_ALTITUDE_LIMIT': -30.0
        }
        INTELLIGENT_DECISION = {
            'VECTOR_FIELD_RADIUS': 8.0,
            'OBSTACLE_REPULSION_GAIN': 3.0,
            'GOAL_ATTRACTION_GAIN': 2.0,
            'SMOOTHING_FACTOR': 0.3,
            'MIN_TURN_ANGLE_DEG': 10,
            'MAX_TURN_ANGLE_DEG': 60,
            'GRID_RESOLUTION': 2.0,
            'GRID_SIZE': 50,
            'INFORMATION_GAIN_DECAY': 0.95,
            'EXPLORATION_FRONTIER_THRESHOLD': 0.3,
            'PID_KP': 1.5,
            'PID_KI': 0.05,
            'PID_KD': 0.2,
            'SMOOTHING_WINDOW_SIZE': 5,
            'ADAPTIVE_SPEED_ENABLED': True,
            'MIN_SPEED_FACTOR': 0.3,
            'MAX_SPEED_FACTOR': 1.5,
            'MEMORY_WEIGHT': 0.7,
            'CURIOUSITY_WEIGHT': 0.3,
            'TARGET_LIFETIME': 15.0,
            'TARGET_REACHED_DISTANCE': 3.0,
            'RED_OBJECT_EXPLORATION': {'ATTRACTION_GAIN': 1.5, 'DETECTION_RADIUS': 10.0,
                                      'MIN_DISTANCE': 2.0, 'EXPLORATION_BONUS': 0.5},
            'BLUE_OBJECT_EXPLORATION': {'ATTRACTION_GAIN': 1.2, 'DETECTION_RADIUS': 8.0,
                                       'MIN_DISTANCE': 2.0, 'EXPLORATION_BONUS': 0.3},
            'BLACK_OBJECT_EXPLORATION': {'ATTRACTION_GAIN': 1.0, 'DETECTION_RADIUS': 8.0,
                                         'MIN_DISTANCE': 2.0, 'EXPLORATION_BONUS': 0.2}
        }
        DEBUG = {
            'SAVE_PERCEPTION_IMAGES': False,
            'IMAGE_SAVE_INTERVAL': 50,
            'LOG_DECISION_DETAILS': False,
            'SAVE_RED_OBJECT_IMAGES': False,
            'SAVE_BLUE_OBJECT_IMAGES': False,
            'SAVE_BLACK_OBJECT_IMAGES': False
        }
        DATA_RECORDING = {
            'ENABLED': True,
            'RECORD_INTERVAL': 0.2,
            'SAVE_TO_CSV': True,
            'SAVE_TO_JSON': True,
            'CSV_FILENAME': 'flight_data.csv',
            'JSON_FILENAME': 'flight_data.json',
            'PERFORMANCE_MONITORING': True,
            'SYSTEM_METRICS_INTERVAL': 5.0,
            'RECORD_RED_OBJECTS': True,
            'RECORD_BLUE_OBJECTS': True,
            'RECORD_BLACK_OBJECTS': True
        }
        PERFORMANCE = {
            'ENABLE_REALTIME_METRICS': True,
            'CPU_WARNING_THRESHOLD': 80.0,
            'MEMORY_WARNING_THRESHOLD': 80.0,
            'LOOP_TIME_WARNING_THRESHOLD': 0.2,
            'SAVE_PERFORMANCE_REPORT': True,
            'REPORT_INTERVAL': 30.0,
        }
    config = DefaultConfig()


class FlightState(Enum):
    """æ— äººæœºé£è¡ŒçŠ¶æ€æšä¸¾"""
    TAKEOFF = "èµ·é£"
    HOVERING = "æ‚¬åœè§‚æµ‹"
    EXPLORING = "ä¸»åŠ¨æ¢ç´¢"
    AVOIDING = "é¿éšœæœºåŠ¨"
    RETURNING = "è¿”èˆªä¸­"
    LANDING = "é™è½"
    EMERGENCY = "ç´§æ€¥çŠ¶æ€"
    MANUAL = "æ‰‹åŠ¨æ§åˆ¶"
    PLANNING = "è·¯å¾„è§„åˆ’"
    RED_OBJECT_INSPECTION = "çº¢è‰²ç‰©ä½“æ£€æŸ¥"
    BLUE_OBJECT_INSPECTION = "è“è‰²ç‰©ä½“æ£€æŸ¥"
    BLACK_OBJECT_INSPECTION = "é»‘è‰²ç‰©ä½“æ£€æŸ¥"


@dataclass
class RedObject:
    """çº¢è‰²ç‰©ä½“æ•°æ®ç»“æ„"""
    id: int
    position: Tuple[float, float, float]
    pixel_position: Tuple[int, int]
    size: float
    confidence: float
    timestamp: float
    last_seen: float
    visited: bool = False


@dataclass
class BlueObject:
    """è“è‰²ç‰©ä½“æ•°æ®ç»“æ„"""
    id: int
    position: Tuple[float, float, float]
    pixel_position: Tuple[int, int]
    size: float
    confidence: float
    timestamp: float
    last_seen: float
    visited: bool = False


@dataclass
class BlackObject:
    """é»‘è‰²ç‰©ä½“æ•°æ®ç»“æ„"""
    id: int
    position: Tuple[float, float, float]
    pixel_position: Tuple[int, int]
    size: float
    confidence: float
    timestamp: float
    last_seen: float
    visited: bool = False


class Vector2D:
    """äºŒç»´å‘é‡ç±»"""
    def __init__(self, x=0.0, y=0.0):
        self.x = x
        self.y = y

    def __add__(self, other):
        return Vector2D(self.x + other.x, self.y + other.y)

    def __sub__(self, other):
        return Vector2D(self.x - other.x, self.y - other.y)

    def __mul__(self, scalar):
        return Vector2D(self.x * scalar, self.y * scalar)

    def __truediv__(self, scalar):
        return Vector2D(self.x / scalar, self.y / scalar)

    def magnitude(self):
        return math.sqrt(self.x**2 + self.y**2)

    def normalize(self):
        mag = self.magnitude()
        if mag > 0:
            return Vector2D(self.x / mag, self.y / mag)
        return Vector2D()

    def rotate(self, angle):
        cos_a = math.cos(angle)
        sin_a = math.sin(angle)
        return Vector2D(
            self.x * cos_a - self.y * sin_a,
            self.x * sin_a + self.y * cos_a
        )

    def to_tuple(self):
        return (self.x, self.y)

    @staticmethod
    def from_angle(angle, magnitude=1.0):
        return Vector2D(magnitude * math.cos(angle), magnitude * math.sin(angle))


class PIDController:
    """PIDæ§åˆ¶å™¨ç±»"""
    def __init__(self, kp, ki, kd, integral_limit=5.0, output_limit=10.0):
        self.kp = kp
        self.ki = ki
        self.kd = kd
        self.integral_limit = integral_limit
        self.output_limit = output_limit

        self.previous_error = 0.0
        self.integral = 0.0
        self.previous_time = time.time()

    def update(self, error, dt=None):
        if dt is None:
            current_time = time.time()
            dt = current_time - self.previous_time
            self.previous_time = current_time

        self.integral += error * dt
        self.integral = max(-self.integral_limit, min(self.integral_limit, self.integral))

        derivative = (error - self.previous_error) / dt if dt > 0 else 0.0
        self.previous_error = error

        output = self.kp * error + self.ki * self.integral + self.kd * derivative
        return max(-self.output_limit, min(self.output_limit, output))


class ExplorationGrid:
    """æ¢ç´¢ç½‘æ ¼åœ°å›¾ç±»"""
    def __init__(self, resolution=2.0, grid_size=50):
        self.resolution = resolution
        self.grid_size = grid_size
        self.half_size = grid_size // 2

        self.grid = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.information_gain = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.obstacle_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.visit_time = np.zeros((grid_size, grid_size), dtype=np.float32)
        self.red_object_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.blue_object_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.black_object_grid = np.zeros((grid_size, grid_size), dtype=bool)
        self.current_idx = (self.half_size, self.half_size)
        self.frontier_cells = set()

        print(f"ğŸ—ºï¸ åˆå§‹åŒ–æ¢ç´¢ç½‘æ ¼: {grid_size}x{grid_size}, åˆ†è¾¨ç‡: {resolution}m")

    def world_to_grid(self, world_x, world_y):
        grid_x = int(world_x / self.resolution) + self.half_size
        grid_y = int(world_y / self.resolution) + self.half_size

        grid_x = max(0, min(self.grid_size - 1, grid_x))
        grid_y = max(0, min(self.grid_size - 1, grid_y))

        return (grid_x, grid_y)

    def grid_to_world(self, grid_x, grid_y):
        world_x = (grid_x - self.half_size) * self.resolution
        world_y = (grid_y - self.half_size) * self.resolution
        return (world_x, world_y)

    def update_position(self, world_x, world_y):
        self.current_idx = self.world_to_grid(world_x, world_y)

        x, y = self.current_idx
        radius = 3

        for dx in range(-radius, radius + 1):
            for dy in range(-radius, radius + 1):
                nx, ny = x + dx, y + dy
                if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                    distance = math.sqrt(dx**2 + dy**2)
                    exploration_value = max(0, 1.0 - distance / radius)
                    self.grid[nx, ny] = max(self.grid[nx, ny], exploration_value)
                    self.visit_time[nx, ny] = time.time()

        self._update_frontiers()

    def _update_frontiers(self):
        self.frontier_cells.clear()

        for x in range(1, self.grid_size - 1):
            for y in range(1, self.grid_size - 1):
                if self.grid[x, y] > 0.7:
                    neighbors = [
                        (x-1, y), (x+1, y), (x, y-1), (x, y+1),
                        (x-1, y-1), (x-1, y+1), (x+1, y-1), (x+1, y+1)
                    ]

                    for nx, ny in neighbors:
                        if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                            if self.grid[nx, ny] < 0.3 and not self.obstacle_grid[nx, ny]:
                                unexplored_neighbors = 0
                                for nnx in range(nx-1, nx+2):
                                    for nny in range(ny-1, ny+2):
                                        if 0 <= nnx < self.grid_size and 0 <= nny < self.grid_size:
                                            if self.grid[nnx, nny] < 0.3:
                                                unexplored_neighbors += 1

                                self.information_gain[nx, ny] = unexplored_neighbors / 9.0
                                self.frontier_cells.add((nx, ny))

    def update_obstacles(self, obstacles_world):
        for obs_x, obs_y in obstacles_world:
            grid_x, grid_y = self.world_to_grid(obs_x, obs_y)

            radius = 2
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.obstacle_grid[nx, ny] = True
                        self.grid[nx, ny] = 0.0

    def update_red_objects(self, red_objects):
        self.red_object_grid.fill(False)

        for obj in red_objects:
            grid_x, grid_y = self.world_to_grid(obj.position[0], obj.position[1])

            radius = 1
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.red_object_grid[nx, ny] = True

    def update_blue_objects(self, blue_objects):
        self.blue_object_grid.fill(False)

        for obj in blue_objects:
            grid_x, grid_y = self.world_to_grid(obj.position[0], obj.position[1])

            radius = 1
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.blue_object_grid[nx, ny] = True

    def update_black_objects(self, black_objects):
        self.black_object_grid.fill(False)

        for obj in black_objects:
            grid_x, grid_y = self.world_to_grid(obj.position[0], obj.position[1])

            radius = 1
            for dx in range(-radius, radius + 1):
                for dy in range(-radius, radius + 1):
                    nx, ny = grid_x + dx, grid_y + dy
                    if 0 <= nx < self.grid_size and 0 <= ny < self.grid_size:
                        self.black_object_grid[nx, ny] = True

    def get_best_exploration_target(self, current_pos, red_objects=None, blue_objects=None, black_objects=None):
        # ä¼˜å…ˆæ£€æŸ¥çº¢è‰²ç‰©ä½“
        if red_objects and len(red_objects) > 0:
            nearest_obj = None
            min_distance = float('inf')
            current_x, current_y = current_pos

            for obj in red_objects:
                if not obj.visited:
                    distance = math.sqrt((obj.position[0] - current_x)**2 +
                                        (obj.position[1] - current_y)**2)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_obj = obj

            if nearest_obj and min_distance < 15.0:
                return (nearest_obj.position[0], nearest_obj.position[1])

        # å…¶æ¬¡æ£€æŸ¥è“è‰²ç‰©ä½“
        if blue_objects and len(blue_objects) > 0:
            nearest_obj = None
            min_distance = float('inf')
            current_x, current_y = current_pos

            for obj in blue_objects:
                if not obj.visited:
                    distance = math.sqrt((obj.position[0] - current_x)**2 +
                                        (obj.position[1] - current_y)**2)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_obj = obj

            if nearest_obj and min_distance < 12.0:
                return (nearest_obj.position[0], nearest_obj.position[1])

        # å†æ¬¡æ£€æŸ¥é»‘è‰²ç‰©ä½“
        if black_objects and len(black_objects) > 0:
            nearest_obj = None
            min_distance = float('inf')
            current_x, current_y = current_pos

            for obj in black_objects:
                if not obj.visited:
                    distance = math.sqrt((obj.position[0] - current_x)**2 +
                                        (obj.position[1] - current_y)**2)
                    if distance < min_distance:
                        min_distance = distance
                        nearest_obj = obj

            if nearest_obj and min_distance < 12.0:
                return (nearest_obj.position[0], nearest_obj.position[1])

        if not self.frontier_cells:
            angle = random.uniform(0, 2 * math.pi)
            distance = 10.0
            return (
                current_pos[0] + distance * math.cos(angle),
                current_pos[1] + distance * math.sin(angle)
            )

        best_score = -1
        best_target = None
        current_x, current_y = current_pos

        for fx, fy in self.frontier_cells:
            info_gain = self.information_gain[fx, fy]

            world_x, world_y = self.grid_to_world(fx, fy)
            distance = math.sqrt((world_x - current_x)**2 + (world_y - current_y)**2)
            distance_cost = min(1.0, distance / 30.0)

            time_since_visit = time.time() - self.visit_time[fx, fy]
            time_factor = min(1.0, time_since_visit / 60.0)

            red_bonus = 0.0
            if self.red_object_grid[fx, fy]:
                red_bonus = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['EXPLORATION_BONUS']

            blue_bonus = 0.0
            if self.blue_object_grid[fx, fy]:
                blue_bonus = config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['EXPLORATION_BONUS']

            black_bonus = 0.0
            if self.black_object_grid[fx, fy]:
                black_bonus = config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['EXPLORATION_BONUS']

            score = (
                config.INTELLIGENT_DECISION['CURIOUSITY_WEIGHT'] * info_gain +
                (1 - config.INTELLIGENT_DECISION['MEMORY_WEIGHT'] * time_factor) -
                distance_cost * 0.3 +
                red_bonus + blue_bonus + black_bonus
            )

            if score > best_score:
                best_score = score
                best_target = (world_x, world_y)

        return best_target

    def visualize_grid(self, size=300):
        if self.grid.size == 0:
            return None

        img_size = min(size, self.grid_size * 5)
        img = np.zeros((img_size, img_size, 3), dtype=np.uint8)

        cell_size = img_size // self.grid_size

        for x in range(self.grid_size):
            for y in range(self.grid_size):
                color = (0, 0, 0)

                if (x, y) == self.current_idx:
                    color = (0, 255, 0)
                elif self.obstacle_grid[x, y]:
                    color = (0, 0, 255)
                elif self.red_object_grid[x, y]:
                    color = (0, 100, 255)  # çº¢è‰²ç‰©ä½“æ˜¾ç¤ºä¸ºæ©™è‰²
                elif self.blue_object_grid[x, y]:
                    color = (255, 100, 0)  # è“è‰²ç‰©ä½“æ˜¾ç¤ºä¸ºé’è‰²
                elif self.black_object_grid[x, y]:
                    color = (128, 128, 128)  # é»‘è‰²ç‰©ä½“æ˜¾ç¤ºä¸ºç°è‰²
                elif self.grid[x, y] > 0.7:
                    color = (200, 200, 200)
                elif self.grid[x, y] > 0.3:
                    color = (100, 100, 100)
                elif (x, y) in self.frontier_cells:
                    gain = self.information_gain[x, y]
                    color = (0, int(255 * gain), int(255 * (1 - gain)))

                x1 = x * cell_size
                y1 = y * cell_size
                x2 = (x + 1) * cell_size
                y2 = (y + 1) * cell_size

                cv2.rectangle(img, (y1, x1), (y2, x2), color, -1)

        return img


class DataLogger:
    """æ•°æ®è®°å½•å™¨ç±»"""

    def __init__(self, enable_csv=True, enable_json=True, csv_filename=None, json_filename=None):
        self.enable_csv = enable_csv
        self.enable_json = enable_json

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        if csv_filename:
            self.csv_filename = csv_filename
        else:
            self.csv_filename = f"flight_data_{timestamp}.csv"

        if json_filename:
            self.json_filename = json_filename
        else:
            self.json_filename = f"flight_data_{timestamp}.json"

        self.data_buffer = []
        self.json_data = {
            "flight_info": {
                "start_time": datetime.now().isoformat(),
                "config_loaded": CONFIG_LOADED,
                "system": config.SYSTEM,
                "exploration": config.EXPLORATION,
                "perception": config.PERCEPTION,
                "intelligent_decision": config.INTELLIGENT_DECISION,
                "performance": config.PERFORMANCE
            },
            "flight_data": []
        }

        self.performance_metrics = {
            "start_time": time.time(),
            "cpu_usage": [],
            "memory_usage": [],
            "loop_times": [],
            "data_points": 0
        }

        self.red_objects_detected = []
        self.blue_objects_detected = []
        self.black_objects_detected = []

        # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶ç¼“å†²åŒºå¤§å°
        self.max_flight_data = config.DATA_RECORDING.get('MAX_FLIGHT_DATA_BUFFER', 500)
        self.max_objects_buffer = config.DATA_RECORDING.get('MAX_OBJECTS_BUFFER', 200)
        self.max_events_buffer = config.DATA_RECORDING.get('MAX_EVENTS_BUFFER', 100)
        self.auto_save_interval = config.DATA_RECORDING.get('AUTO_SAVE_INTERVAL', 60.0)
        self.last_auto_save_time = time.time()
        self.max_metrics_buffer = config.PERFORMANCE.get('MAX_METRICS_BUFFER', 500)

        self.csv_columns = [
            'timestamp', 'loop_count', 'state', 'pos_x', 'pos_y', 'pos_z',
            'vel_x', 'vel_y', 'vel_z', 'yaw', 'pitch', 'roll',
            'obstacle_distance', 'open_space_score', 'terrain_slope',
            'has_obstacle', 'obstacle_direction', 'recommended_height',
            'target_x', 'target_y', 'target_z', 'velocity_command_x',
            'velocity_command_y', 'velocity_command_z', 'yaw_command',
            'battery_level', 'cpu_usage', 'memory_usage', 'loop_time',
            'grid_frontiers', 'grid_explored', 'vector_field_magnitude',
            'adaptive_speed_factor', 'decision_making_time', 'perception_time',
            'red_objects_count', 'red_objects_detected', 'red_objects_visited',
            'blue_objects_count', 'blue_objects_detected', 'blue_objects_visited',
            'black_objects_count', 'black_objects_detected', 'black_objects_visited'
        ]

        if self.enable_csv:
            self._init_csv_file()

        print(f"ğŸ“Š æ•°æ®è®°å½•å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"  CSVæ–‡ä»¶: {self.csv_filename}")
        print(f"  JSONæ–‡ä»¶: {self.json_filename}")

    def _init_csv_file(self):
        try:
            with open(self.csv_filename, 'w', newline='', encoding='utf-8') as f:
                writer = csv.DictWriter(f, fieldnames=self.csv_columns)
                writer.writeheader()
        except Exception as e:
            print(f"âŒ æ— æ³•åˆå§‹åŒ–CSVæ–‡ä»¶: {e}")
            self.enable_csv = False

    def record_flight_data(self, data_dict):
        if not config.DATA_RECORDING['ENABLED']:
            return

        try:
            data_dict['timestamp'] = datetime.now().isoformat()

            if self.enable_csv:
                with open(self.csv_filename, 'a', newline='', encoding='utf-8') as f:
                    writer = csv.DictWriter(f, fieldnames=self.csv_columns)
                    row = {col: data_dict.get(col, '') for col in self.csv_columns}
                    writer.writerow(row)

            if self.enable_json:
                self.json_data['flight_data'].append(data_dict)
                # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶flight_dataé•¿åº¦ï¼Œè¶…è¿‡é™åˆ¶æ—¶ä¿å­˜å¹¶æ¸…ç©º
                if len(self.json_data['flight_data']) >= self.max_flight_data:
                    self._auto_save_and_clear()

            self.performance_metrics['data_points'] += 1

            # å†…å­˜ä¼˜åŒ–ï¼šå®šæœŸè‡ªåŠ¨ä¿å­˜
            current_time = time.time()
            if current_time - self.last_auto_save_time >= self.auto_save_interval:
                self._auto_save_and_clear()
                self.last_auto_save_time = current_time

            if self.performance_metrics['data_points'] % 10 == 0:
                self._collect_system_metrics()

        except Exception as e:
            print(f"âš ï¸ è®°å½•é£è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")

    def record_red_object(self, red_object):
        try:
            red_object_data = {
                'id': red_object.id,
                'position': red_object.position,
                'pixel_position': red_object.pixel_position,
                'size': red_object.size,
                'confidence': red_object.confidence,
                'timestamp': red_object.timestamp,
                'visited': red_object.visited
            }

            # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶ç‰©ä½“è®°å½•åˆ—è¡¨é•¿åº¦
            if len(self.red_objects_detected) >= self.max_objects_buffer:
                self.red_objects_detected = self.red_objects_detected[-self.max_objects_buffer//2:]
            self.red_objects_detected.append(red_object_data)

            if 'red_objects' not in self.json_data:
                self.json_data['red_objects'] = []

            # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶JSONä¸­çš„ç‰©ä½“åˆ—è¡¨é•¿åº¦
            if len(self.json_data['red_objects']) >= self.max_objects_buffer:
                self.json_data['red_objects'] = self.json_data['red_objects'][-self.max_objects_buffer//2:]
            self.json_data['red_objects'].append(red_object_data)

        except Exception as e:
            print(f"âš ï¸ è®°å½•çº¢è‰²ç‰©ä½“æ—¶å‡ºé”™: {e}")

    def record_blue_object(self, blue_object):
        try:
            blue_object_data = {
                'id': blue_object.id,
                'position': blue_object.position,
                'pixel_position': blue_object.pixel_position,
                'size': blue_object.size,
                'confidence': blue_object.confidence,
                'timestamp': blue_object.timestamp,
                'visited': blue_object.visited
            }

            # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶ç‰©ä½“è®°å½•åˆ—è¡¨é•¿åº¦
            if len(self.blue_objects_detected) >= self.max_objects_buffer:
                self.blue_objects_detected = self.blue_objects_detected[-self.max_objects_buffer//2:]
            self.blue_objects_detected.append(blue_object_data)

            if 'blue_objects' not in self.json_data:
                self.json_data['blue_objects'] = []

            # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶JSONä¸­çš„ç‰©ä½“åˆ—è¡¨é•¿åº¦
            if len(self.json_data['blue_objects']) >= self.max_objects_buffer:
                self.json_data['blue_objects'] = self.json_data['blue_objects'][-self.max_objects_buffer//2:]
            self.json_data['blue_objects'].append(blue_object_data)

        except Exception as e:
            print(f"âš ï¸ è®°å½•è“è‰²ç‰©ä½“æ—¶å‡ºé”™: {e}")

    def record_black_object(self, black_object):
        try:
            black_object_data = {
                'id': black_object.id,
                'position': black_object.position,
                'pixel_position': black_object.pixel_position,
                'size': black_object.size,
                'confidence': black_object.confidence,
                'timestamp': black_object.timestamp,
                'visited': black_object.visited
            }

            # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶ç‰©ä½“è®°å½•åˆ—è¡¨é•¿åº¦
            if len(self.black_objects_detected) >= self.max_objects_buffer:
                self.black_objects_detected = self.black_objects_detected[-self.max_objects_buffer//2:]
            self.black_objects_detected.append(black_object_data)

            if 'black_objects' not in self.json_data:
                self.json_data['black_objects'] = []

            # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶JSONä¸­çš„ç‰©ä½“åˆ—è¡¨é•¿åº¦
            if len(self.json_data['black_objects']) >= self.max_objects_buffer:
                self.json_data['black_objects'] = self.json_data['black_objects'][-self.max_objects_buffer//2:]
            self.json_data['black_objects'].append(black_object_data)

        except Exception as e:
            print(f"âš ï¸ è®°å½•é»‘è‰²ç‰©ä½“æ—¶å‡ºé”™: {e}")

    def _collect_system_metrics(self):
        try:
            cpu_percent = psutil.cpu_percent(interval=0.1)
            self.performance_metrics['cpu_usage'].append(cpu_percent)

            memory_info = psutil.virtual_memory()
            memory_percent = memory_info.percent
            self.performance_metrics['memory_usage'].append(memory_percent)

            # å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨é…ç½®çš„æœ€å¤§ç¼“å†²åŒºå¤§å°
            max_length = self.max_metrics_buffer
            if len(self.performance_metrics['cpu_usage']) > max_length:
                self.performance_metrics['cpu_usage'] = self.performance_metrics['cpu_usage'][-max_length:]
            if len(self.performance_metrics['memory_usage']) > max_length:
                self.performance_metrics['memory_usage'] = self.performance_metrics['memory_usage'][-max_length:]

        except Exception as e:
            print(f"âš ï¸ æ”¶é›†ç³»ç»ŸæŒ‡æ ‡æ—¶å‡ºé”™: {e}")

    def record_loop_time(self, loop_time):
        self.performance_metrics['loop_times'].append(loop_time)

        # å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨é…ç½®çš„æœ€å¤§ç¼“å†²åŒºå¤§å°
        max_length = self.max_metrics_buffer
        if len(self.performance_metrics['loop_times']) > max_length:
            self.performance_metrics['loop_times'] = self.performance_metrics['loop_times'][-max_length:]

    def record_event(self, event_type, event_data):
        try:
            event_record = {
                'timestamp': datetime.now().isoformat(),
                'event_type': event_type,
                'event_data': event_data
            }

            if 'events' not in self.json_data:
                self.json_data['events'] = []

            # å†…å­˜ä¼˜åŒ–ï¼šé™åˆ¶eventsåˆ—è¡¨é•¿åº¦
            if len(self.json_data['events']) >= self.max_events_buffer:
                self.json_data['events'] = self.json_data['events'][-self.max_events_buffer//2:]
            self.json_data['events'].append(event_record)

        except Exception as e:
            print(f"âš ï¸ è®°å½•äº‹ä»¶æ—¶å‡ºé”™: {e}")

    def _auto_save_and_clear(self):
        """è‡ªåŠ¨ä¿å­˜æ•°æ®å¹¶æ¸…ç©ºç¼“å†²åŒºï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰"""
        if not self.enable_json or len(self.json_data['flight_data']) == 0:
            return

        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            temp_filename = self.json_filename.replace('.json', f'_temp_{timestamp}.json')
            
            # ä¿å­˜å½“å‰æ•°æ®
            with open(temp_filename, 'w', encoding='utf-8') as f:
                json.dump(self.json_data, f, indent=2, ensure_ascii=False)
            
            # æ¸…ç©ºflight_dataï¼Œä¿ç•™å…¶ä»–æ•°æ®
            saved_count = len(self.json_data['flight_data'])
            self.json_data['flight_data'] = []
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            print(f"ğŸ’¾ è‡ªåŠ¨ä¿å­˜ {saved_count} æ¡æ•°æ®åˆ°: {temp_filename} (å·²æ¸…ç©ºç¼“å†²åŒº)")
        except Exception as e:
            print(f"âš ï¸ è‡ªåŠ¨ä¿å­˜æ•°æ®æ—¶å‡ºé”™: {e}")

    def save_json_data(self):
        if not self.enable_json:
            return

        try:
            self._calculate_performance_stats()

            # çº¢è‰²ç‰©ä½“ç»Ÿè®¡
            if 'red_objects' in self.json_data:
                red_count = len(self.json_data['red_objects'])
                visited_count = sum(1 for obj in self.json_data['red_objects'] if obj.get('visited', False))
                self.json_data['red_objects_summary'] = {
                    'total_detected': red_count,
                    'total_visited': visited_count,
                    'visit_rate': visited_count / red_count if red_count > 0 else 0
                }

            # è“è‰²ç‰©ä½“ç»Ÿè®¡
            if 'blue_objects' in self.json_data:
                blue_count = len(self.json_data['blue_objects'])
                visited_count = sum(1 for obj in self.json_data['blue_objects'] if obj.get('visited', False))
                self.json_data['blue_objects_summary'] = {
                    'total_detected': blue_count,
                    'total_visited': visited_count,
                    'visit_rate': visited_count / blue_count if blue_count > 0 else 0
                }

            # é»‘è‰²ç‰©ä½“ç»Ÿè®¡
            if 'black_objects' in self.json_data:
                black_count = len(self.json_data['black_objects'])
                visited_count = sum(1 for obj in self.json_data['black_objects'] if obj.get('visited', False))
                self.json_data['black_objects_summary'] = {
                    'total_detected': black_count,
                    'total_visited': visited_count,
                    'visit_rate': visited_count / black_count if black_count > 0 else 0
                }

            with open(self.json_filename, 'w', encoding='utf-8') as f:
                json.dump(self.json_data, f, indent=2, ensure_ascii=False)

            print(f"âœ… JSONæ•°æ®å·²ä¿å­˜: {self.json_filename}")

        except Exception as e:
            print(f"âŒ ä¿å­˜JSONæ•°æ®æ—¶å‡ºé”™: {e}")

    def _calculate_performance_stats(self):
        if not self.performance_metrics['cpu_usage']:
            return

        cpu_avg = np.mean(self.performance_metrics['cpu_usage'])
        cpu_max = np.max(self.performance_metrics['cpu_usage'])
        cpu_min = np.min(self.performance_metrics['cpu_usage'])

        mem_avg = np.mean(self.performance_metrics['memory_usage'])
        mem_max = np.max(self.performance_metrics['memory_usage'])
        mem_min = np.min(self.performance_metrics['memory_usage'])

        if self.performance_metrics['loop_times']:
            loop_avg = np.mean(self.performance_metrics['loop_times'])
            loop_max = np.max(self.performance_metrics['loop_times'])
            loop_min = np.min(self.performance_metrics['loop_times'])
        else:
            loop_avg = loop_max = loop_min = 0

        self.json_data['performance_summary'] = {
            'total_data_points': self.performance_metrics['data_points'],
            'total_time_seconds': time.time() - self.performance_metrics['start_time'],
            'cpu_usage': {
                'average': float(cpu_avg),
                'maximum': float(cpu_max),
                'minimum': float(cpu_min)
            },
            'memory_usage': {
                'average': float(mem_avg),
                'maximum': float(mem_max),
                'minimum': float(mem_min)
            },
            'loop_times': {
                'average_seconds': float(loop_avg),
                'maximum_seconds': float(loop_max),
                'minimum_seconds': float(loop_min)
            }
        }

    def generate_performance_report(self):
        try:
            if not self.performance_metrics['cpu_usage']:
                return "æ— æ€§èƒ½æ•°æ®å¯ç”¨"

            self._calculate_performance_stats()

            report = "\n" + "="*60 + "\n"
            report += "ğŸ“Š ç³»ç»Ÿæ€§èƒ½æŠ¥å‘Š\n"
            report += "="*60 + "\n"

            report += f"æ€»æ•°æ®ç‚¹æ•°: {self.performance_metrics['data_points']}\n"
            report += f"è¿è¡Œæ—¶é—´: {time.time() - self.performance_metrics['start_time']:.1f}ç§’\n"

            if self.performance_metrics['cpu_usage']:
                cpu_avg = np.mean(self.performance_metrics['cpu_usage'])
                cpu_max = np.max(self.performance_metrics['cpu_usage'])
                report += f"CPUä½¿ç”¨ç‡: å¹³å‡{cpu_avg:.1f}%, æœ€å¤§{cpu_max:.1f}%\n"

            if self.performance_metrics['memory_usage']:
                mem_avg = np.mean(self.performance_metrics['memory_usage'])
                mem_max = np.max(self.performance_metrics['memory_usage'])
                report += f"å†…å­˜ä½¿ç”¨ç‡: å¹³å‡{mem_avg:.1f}%, æœ€å¤§{mem_max:.1f}%\n"

            if self.performance_metrics['loop_times']:
                loop_avg = np.mean(self.performance_metrics['loop_times'])
                loop_max = np.max(self.performance_metrics['loop_times'])
                report += f"å¾ªç¯æ—¶é—´: å¹³å‡{loop_avg*1000:.1f}ms, æœ€å¤§{loop_max*1000:.1f}ms\n"

            if 'red_objects' in self.json_data:
                red_count = len(self.json_data['red_objects'])
                visited_count = sum(1 for obj in self.json_data['red_objects'] if obj.get('visited', False))
                report += f"çº¢è‰²ç‰©ä½“æ£€æµ‹: æ€»æ•°{red_count}ä¸ª, å·²è®¿é—®{visited_count}ä¸ª\n"

            if 'blue_objects' in self.json_data:
                blue_count = len(self.json_data['blue_objects'])
                visited_count = sum(1 for obj in self.json_data['blue_objects'] if obj.get('visited', False))
                report += f"è“è‰²ç‰©ä½“æ£€æµ‹: æ€»æ•°{blue_count}ä¸ª, å·²è®¿é—®{visited_count}ä¸ª\n"

            if 'black_objects' in self.json_data:
                black_count = len(self.json_data['black_objects'])
                visited_count = sum(1 for obj in self.json_data['black_objects'] if obj.get('visited', False))
                report += f"é»‘è‰²ç‰©ä½“æ£€æµ‹: æ€»æ•°{black_count}ä¸ª, å·²è®¿é—®{visited_count}ä¸ª\n"

            report += "="*60 + "\n"

            warnings = []
            if cpu_avg > config.PERFORMANCE['CPU_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_avg:.1f}%")

            if mem_avg > config.PERFORMANCE['MEMORY_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {mem_avg:.1f}%")

            if loop_avg > config.PERFORMANCE['LOOP_TIME_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å¾ªç¯æ—¶é—´è¿‡é•¿: {loop_avg*1000:.1f}ms")

            if warnings:
                report += "\nâš ï¸ æ€§èƒ½è­¦å‘Š:\n"
                for warning in warnings:
                    report += f"  {warning}\n"

            return report

        except Exception as e:
            return f"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šæ—¶å‡ºé”™: {e}"


@dataclass
class PerceptionResult:
    """æ„ŸçŸ¥ç»“æœæ•°æ®ç»“æ„"""
    has_obstacle: bool = False
    obstacle_distance: float = 100.0
    obstacle_direction: float = 0.0
    terrain_slope: float = 0.0
    open_space_score: float = 0.0
    recommended_height: float = config.PERCEPTION['HEIGHT_STRATEGY']['DEFAULT']
    safe_directions: List[float] = None
    front_image: Optional[np.ndarray] = None
    obstacle_positions: List[Tuple[float, float]] = None
    red_objects: List[RedObject] = None
    red_objects_count: int = 0
    red_objects_image: Optional[np.ndarray] = None
    blue_objects: List[BlueObject] = None
    blue_objects_count: int = 0
    blue_objects_image: Optional[np.ndarray] = None
    black_objects: List[BlackObject] = None
    black_objects_count: int = 0
    black_objects_image: Optional[np.ndarray] = None

    def __post_init__(self):
        if self.safe_directions is None:
            self.safe_directions = []
        if self.obstacle_positions is None:
            self.obstacle_positions = []
        if self.red_objects is None:
            self.red_objects = []
        if self.blue_objects is None:
            self.blue_objects = []
        if self.black_objects is None:
            self.black_objects = []


class VectorFieldPlanner:
    """å‘é‡åœºè§„åˆ’å™¨"""
    def __init__(self):
        self.repulsion_gain = config.INTELLIGENT_DECISION['OBSTACLE_REPULSION_GAIN']
        self.attraction_gain = config.INTELLIGENT_DECISION['GOAL_ATTRACTION_GAIN']
        self.field_radius = config.INTELLIGENT_DECISION['VECTOR_FIELD_RADIUS']
        self.smoothing_factor = config.INTELLIGENT_DECISION['SMOOTHING_FACTOR']
        self.red_attraction_gain = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['ATTRACTION_GAIN']
        self.blue_attraction_gain = config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['ATTRACTION_GAIN']
        self.black_attraction_gain = config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['ATTRACTION_GAIN']

        self.min_turn_angle = math.radians(config.INTELLIGENT_DECISION['MIN_TURN_ANGLE_DEG'])
        self.max_turn_angle = math.radians(config.INTELLIGENT_DECISION['MAX_TURN_ANGLE_DEG'])

        self.vector_history = deque(maxlen=config.INTELLIGENT_DECISION['SMOOTHING_WINDOW_SIZE'])
        self.current_vector = Vector2D()

    def compute_vector(self, current_pos, goal_pos, obstacles, red_objects=None, blue_objects=None, black_objects=None):
        attraction_vector = self._compute_attraction(current_pos, goal_pos)
        repulsion_vector = self._compute_repulsion(current_pos, obstacles)
        red_attraction_vector = Vector2D()
        blue_attraction_vector = Vector2D()
        black_attraction_vector = Vector2D()

        if red_objects:
            red_attraction_vector = self._compute_red_attraction(current_pos, red_objects)

        if blue_objects:
            blue_attraction_vector = self._compute_blue_attraction(current_pos, blue_objects)

        if black_objects:
            black_attraction_vector = self._compute_black_attraction(current_pos, black_objects)

        combined_vector = attraction_vector + repulsion_vector + red_attraction_vector + blue_attraction_vector + black_attraction_vector
        smoothed_vector = self._smooth_vector(combined_vector)
        limited_vector = self._limit_turn_angle(smoothed_vector)

        self.current_vector = limited_vector
        return limited_vector

    def _compute_attraction(self, current_pos, goal_pos):
        if goal_pos is None:
            return Vector2D()

        dx = goal_pos[0] - current_pos[0]
        dy = goal_pos[1] - current_pos[1]
        distance = math.sqrt(dx**2 + dy**2)

        if distance < 0.1:
            return Vector2D()

        strength = min(self.attraction_gain, self.attraction_gain / max(1.0, distance))
        return Vector2D(dx, dy).normalize() * strength

    def _compute_repulsion(self, current_pos, obstacles):
        repulsion = Vector2D()

        for obs_x, obs_y in obstacles:
            dx = current_pos[0] - obs_x
            dy = current_pos[1] - obs_y
            distance = math.sqrt(dx**2 + dy**2)

            if distance < self.field_radius and distance > 0.1:
                strength = self.repulsion_gain * (1.0 / distance**2)
                direction = Vector2D(dx, dy).normalize()
                repulsion += direction * strength

        return repulsion

    def _compute_red_attraction(self, current_pos, red_objects):
        attraction = Vector2D()

        for obj in red_objects:
            if not obj.visited:
                dx = obj.position[0] - current_pos[0]
                dy = obj.position[1] - current_pos[1]
                distance = math.sqrt(dx**2 + dy**2)

                if distance < config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['DETECTION_RADIUS']:
                    strength = self.red_attraction_gain / max(1.0, distance)
                    direction = Vector2D(dx, dy).normalize()
                    attraction += direction * strength

        return attraction

    def _compute_blue_attraction(self, current_pos, blue_objects):
        attraction = Vector2D()

        for obj in blue_objects:
            if not obj.visited:
                dx = obj.position[0] - current_pos[0]
                dy = obj.position[1] - current_pos[1]
                distance = math.sqrt(dx**2 + dy**2)

                if distance < config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['DETECTION_RADIUS']:
                    strength = self.blue_attraction_gain / max(1.0, distance)
                    direction = Vector2D(dx, dy).normalize()
                    attraction += direction * strength

        return attraction

    def _compute_black_attraction(self, current_pos, black_objects):
        attraction = Vector2D()

        for obj in black_objects:
            if not obj.visited:
                dx = obj.position[0] - current_pos[0]
                dy = obj.position[1] - current_pos[1]
                distance = math.sqrt(dx**2 + dy**2)

                if distance < config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['DETECTION_RADIUS']:
                    strength = self.black_attraction_gain / max(1.0, distance)
                    direction = Vector2D(dx, dy).normalize()
                    attraction += direction * strength

        return attraction

    def _smooth_vector(self, new_vector):
        self.vector_history.append(new_vector)

        if len(self.vector_history) < 2:
            return new_vector

        smoothed = Vector2D()
        total_weight = 0.0

        for i, vec in enumerate(reversed(self.vector_history)):
            weight = math.exp(-i * self.smoothing_factor)
            smoothed += vec * weight
            total_weight += weight

        if total_weight > 0:
            smoothed = smoothed / total_weight

        return smoothed

    def _limit_turn_angle(self, vector):
        if self.current_vector.magnitude() < 0.1:
            return vector

        current_angle = math.atan2(self.current_vector.y, self.current_vector.x)
        new_angle = math.atan2(vector.y, vector.x)

        angle_diff = new_angle - current_angle
        angle_diff = (angle_diff + math.pi) % (2 * math.pi) - math.pi

        if abs(angle_diff) > self.max_turn_angle:
            angle_diff = math.copysign(self.max_turn_angle, angle_diff)
        elif abs(angle_diff) < self.min_turn_angle and vector.magnitude() > 0.1:
            angle_diff = math.copysign(self.min_turn_angle, angle_diff)

        magnitude = vector.magnitude()
        limited_angle = current_angle + angle_diff

        return Vector2D.from_angle(limited_angle, magnitude)


def _load_chinese_font(font_size=20):
    """åŠ è½½ä¸­æ–‡å­—ä½“ï¼Œä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åŠ è½½"""
    global _chinese_font_cache
    
    # æ£€æŸ¥ç¼“å­˜
    cache_key = font_size
    if cache_key in _chinese_font_cache:
        return _chinese_font_cache[cache_key]
    
    if not PIL_AVAILABLE:
        return None
    
    font = None
    font_paths = []
    
    # Windowsç³»ç»Ÿå­—ä½“è·¯å¾„
    if platform.system() == "Windows":
        windir = os.environ.get('WINDIR', 'C:\\Windows')
        font_dir = os.path.join(windir, 'Fonts')
        
        # é¦–å…ˆå°è¯•å·²çŸ¥çš„ä¸­æ–‡å­—ä½“æ–‡ä»¶å
        known_fonts = [
            "simhei.ttf",      # é»‘ä½“
            "msyh.ttc",        # å¾®è½¯é›…é»‘
            "msyhbd.ttc",      # å¾®è½¯é›…é»‘ Bold
            "simsun.ttc",      # å®‹ä½“
            "simkai.ttf",      # æ¥·ä½“
            "simli.ttf",       # éš¶ä¹¦
            "STHeiti.ttf",     # åæ–‡é»‘ä½“
            "STSong.ttf",      # åæ–‡å®‹ä½“
        ]
        
        for font_name in known_fonts:
            font_path = os.path.join(font_dir, font_name)
            font_paths.append(font_path)
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•æ‰«æå­—ä½“ç›®å½•
        if os.path.exists(font_dir):
            try:
                for filename in os.listdir(font_dir):
                    filename_lower = filename.lower()
                    # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«ä¸­æ–‡å­—ä½“å…³é”®è¯
                    if any(keyword in filename_lower for keyword in ['simhei', 'msyh', 'simsun', 'simkai', 'simli', 'stheit', 'stsong', 'chinese', 'cjk']):
                        font_path = os.path.join(font_dir, filename)
                        if font_path not in font_paths:
                            font_paths.append(font_path)
            except:
                pass
    
    # ä¹Ÿå°è¯•å¸¸è§çš„è·¯å¾„æ ¼å¼
    common_paths = [
        "C:/Windows/Fonts/simhei.ttf",
        "C:/Windows/Fonts/msyh.ttc",
        "C:/Windows/Fonts/simsun.ttc",
        "C:/Windows/Fonts/msyhbd.ttc",
        "C:/Windows/Fonts/simkai.ttf",
        "C:/Windows/Fonts/simli.ttf",
    ]
    font_paths.extend(common_paths)
    
    # å»é‡
    font_paths = list(dict.fromkeys(font_paths))
    
    # å°è¯•åŠ è½½å­—ä½“
    loaded_font_path = None
    for font_path in font_paths:
        if os.path.exists(font_path):
            try:
                font = ImageFont.truetype(font_path, font_size)
                # å¦‚æœæˆåŠŸåŠ è½½ï¼Œç¼“å­˜å­—ä½“
                loaded_font_path = font_path
                _chinese_font_cache[cache_key] = font
                break
            except Exception as e:
                continue
    
    # å¦‚æœæ‰¾åˆ°äº†å­—ä½“ï¼Œæ‰“å°ä¿¡æ¯ï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
    if loaded_font_path and cache_key == 20:  # åªåœ¨ç¬¬ä¸€æ¬¡åŠ è½½æ—¶æ‰“å°
        print(f"âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“: {os.path.basename(loaded_font_path)}")
    
    # å¦‚æœæ‰¾ä¸åˆ°å­—ä½“ï¼Œç¼“å­˜Noneå¹¶æ‰“å°è­¦å‘Šï¼ˆä»…ç¬¬ä¸€æ¬¡ï¼‰
    if font is None and cache_key == 20:
        print("âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°†ä½¿ç”¨è‹±æ–‡æ˜¾ç¤º")
        if platform.system() == "Windows":
            windir = os.environ.get('WINDIR', 'C:\\Windows')
            font_dir = os.path.join(windir, 'Fonts')
            print(f"   å­—ä½“ç›®å½•: {font_dir}")
            print(f"   è¯·ç¡®ä¿è¯¥ç›®å½•å­˜åœ¨ä¸­æ–‡å­—ä½“æ–‡ä»¶ï¼ˆå¦‚simhei.ttf, msyh.ttcç­‰ï¼‰")
    
    _chinese_font_cache[cache_key] = font
    return font


def put_chinese_text(img, text, position, font_size=20, color=(255, 255, 255), thickness=1):
    """
    åœ¨OpenCVå›¾åƒä¸Šç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬
    ä½¿ç”¨PIL/Pillowæ¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
    """
    if not PIL_AVAILABLE:
        # å¦‚æœPILä¸å¯ç”¨ï¼Œä½¿ç”¨è‹±æ–‡æ›¿ä»£
        text_en = text.replace("çŠ¶æ€:", "State:").replace("ä½ç½®:", "Pos:").replace("çº¢è‰²ç‰©ä½“:", "Red:").replace("è“è‰²ç‰©ä½“:", "Blue:").replace("é»‘è‰²ç‰©ä½“:", "Black:").replace("éšœç¢:", "Obs:").replace("æ‰‹åŠ¨æ§åˆ¶ä¸­...", "Manual Ctrl").replace("ç­‰å¾…æ— äººæœºå›¾åƒ...", "Waiting...").replace("é£è¡ŒçŠ¶æ€:", "State:").replace("éšœç¢è·ç¦»:", "Obs:").replace("å¼€é˜”åº¦:", "Open:").replace("æ¢ç´¢ç½‘æ ¼:", "Grid:").replace("CPUä½¿ç”¨ç‡:", "CPU:").replace("å†…å­˜ä½¿ç”¨ç‡:", "Mem:").replace("å¾ªç¯æ—¶é—´:", "Loop:").replace("æ›´æ–°æ—¶é—´:", "Time:").replace("æŒ‰ Q æˆ– ESC å…³é—­çª—å£", "Press Q/ESC to close").replace("æ¸²æŸ“é”™è¯¯", "Render Error").replace("æ¢ç´¢å‰æ²¿", "Frontier").replace("å½“å‰ä½ç½®", "Current").replace("éšœç¢ç‰©", "Obstacle").replace("å›¾ä¾‹:", "Legend:").replace("æ— äººæœºä¿¡æ¯é¢æ¿", "Info Panel").replace("ç­‰å¾…æ•°æ®...", "Waiting...").replace("ç³»ç»Ÿæ­£åœ¨åˆå§‹åŒ–ï¼Œè¯·ç¨å€™...", "Initializing...")
        cv2.putText(img, text_en, position, cv2.FONT_HERSHEY_SIMPLEX, font_size / 30.0, color, thickness)
        return img
    
    try:
        # å°†OpenCVå›¾åƒè½¬æ¢ä¸ºPILå›¾åƒ
        img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(img_pil)
        
        # åŠ è½½ä¸­æ–‡å­—ä½“
        font = _load_chinese_font(font_size)
        
        if font is None:
            # å¦‚æœæ‰¾ä¸åˆ°å­—ä½“ï¼Œå›é€€åˆ°è‹±æ–‡æ˜¾ç¤º
            raise Exception("æœªæ‰¾åˆ°æ”¯æŒä¸­æ–‡çš„å­—ä½“")
        
        # ç»˜åˆ¶æ–‡æœ¬ï¼ˆPILä½¿ç”¨RGBé¢œè‰²ï¼‰
        color_rgb = (color[2], color[1], color[0])  # BGRè½¬RGB
        
        # PILçš„textå‡½æ•°ä½ç½®å‚æ•°æ˜¯(x, y)
        x, y = position
        draw.text((x, y), text, font=font, fill=color_rgb)
        
        # è½¬æ¢å›OpenCVæ ¼å¼
        img = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        
    except Exception as e:
        # å¦‚æœå‡ºé”™ï¼ˆåŒ…æ‹¬å­—ä½“åŠ è½½å¤±è´¥ï¼‰ï¼Œå›é€€åˆ°è‹±æ–‡æ˜¾ç¤º
        try:
            # å°†ä¸­æ–‡è½¬æ¢ä¸ºè‹±æ–‡
            text_en = text.replace("çŠ¶æ€:", "State:").replace("ä½ç½®:", "Pos:").replace("çº¢è‰²ç‰©ä½“:", "Red:").replace("è“è‰²ç‰©ä½“:", "Blue:").replace("é»‘è‰²ç‰©ä½“:", "Black:").replace("éšœç¢:", "Obs:").replace("æ‰‹åŠ¨æ§åˆ¶ä¸­...", "Manual Ctrl").replace("ç­‰å¾…æ— äººæœºå›¾åƒ...", "Waiting...").replace("é£è¡ŒçŠ¶æ€:", "State:").replace("éšœç¢è·ç¦»:", "Obs:").replace("å¼€é˜”åº¦:", "Open:").replace("æ¢ç´¢ç½‘æ ¼:", "Grid:").replace("CPUä½¿ç”¨ç‡:", "CPU:").replace("å†…å­˜ä½¿ç”¨ç‡:", "Mem:").replace("å¾ªç¯æ—¶é—´:", "Loop:").replace("æ›´æ–°æ—¶é—´:", "Time:").replace("æŒ‰ Q æˆ– ESC å…³é—­çª—å£", "Press Q/ESC to close").replace("æ¸²æŸ“é”™è¯¯", "Render Error").replace("æ¢ç´¢å‰æ²¿", "Frontier").replace("å½“å‰ä½ç½®", "Current").replace("éšœç¢ç‰©", "Obstacle").replace("å›¾ä¾‹:", "Legend:").replace("æ— äººæœºä¿¡æ¯é¢æ¿", "Info Panel").replace("ç­‰å¾…æ•°æ®...", "Waiting...").replace("ç³»ç»Ÿæ­£åœ¨åˆå§‹åŒ–ï¼Œè¯·ç¨å€™...", "Initializing...")
            cv2.putText(img, text_en, position, cv2.FONT_HERSHEY_SIMPLEX, font_size / 30.0, color, thickness)
        except:
            pass
    
    return img


class FrontViewWindow:
    """å‰è§†çª—å£ - æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢å’Œæ‰‹åŠ¨æ§åˆ¶"""

    def __init__(self, window_name=None, width=None, height=None,
                 enable_sharpening=None, show_info=None):
        self.window_name = window_name if window_name else config.DISPLAY['FRONT_VIEW_WINDOW']['NAME']
        self.window_width = width if width is not None else config.DISPLAY['FRONT_VIEW_WINDOW']['WIDTH']
        self.window_height = height if height is not None else config.DISPLAY['FRONT_VIEW_WINDOW']['HEIGHT']
        self.enable_sharpening = (enable_sharpening if enable_sharpening is not None
                                 else config.DISPLAY['FRONT_VIEW_WINDOW']['ENABLE_SHARPENING'])
        self.show_info = (show_info if show_info is not None
                         else config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_INFO_OVERLAY'])

        # å†…å­˜ä¼˜åŒ–ï¼šä½¿ç”¨é…ç½®çš„é˜Ÿåˆ—å¤§å°
        queue_maxsize = config.DISPLAY['FRONT_VIEW_WINDOW'].get('QUEUE_MAXSIZE', 2)
        self.image_queue = queue.Queue(maxsize=queue_maxsize)
        self.reduce_image_copy = config.DISPLAY['FRONT_VIEW_WINDOW'].get('REDUCE_IMAGE_COPY', True)
        self.display_active = True
        self.display_thread = None
        self.paused = False

        self.manual_mode = False
        self.key_states = {}
        self.last_keys = {}

        self.exit_manual_flag = False
        self.exit_display_flag = False

        self.display_stats = {
            'fps': 0.0,
            'last_update': time.time(),
            'frame_count': 0
        }

        self.start()

    def start(self):
        if self.display_thread and self.display_thread.is_alive():
            return

        self.display_active = True
        self.display_thread = threading.Thread(
            target=self._display_loop,
            daemon=True,
            name="FrontViewWindow"
        )
        self.display_thread.start()

    def stop(self):
        self.display_active = False
        self.exit_display_flag = True
        if self.display_thread:
            self.display_thread.join(timeout=2.0)

    def update_image(self, image_data: np.ndarray, info: Optional[Dict] = None,
                     manual_info: Optional[List[str]] = None):
        if not self.display_active or self.paused or image_data is None:
            return

        try:
            if self.enable_sharpening and image_data is not None and image_data.size > 0:
                kernel = np.array([[0, -1, 0],
                                   [-1, 5, -1],
                                   [0, -1, 0]])
                image_data = cv2.filter2D(image_data, -1, kernel)

            if self.image_queue.full():
                try:
                    self.image_queue.get_nowait()
                except queue.Empty:
                    pass

            # å†…å­˜ä¼˜åŒ–ï¼šä»…åœ¨å¿…è¦æ—¶å¤åˆ¶å›¾åƒ
            if self.reduce_image_copy and image_data is not None:
                # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºæˆ–åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œç›´æ¥ä½¿ç”¨å¼•ç”¨ï¼ˆé¿å…å¤åˆ¶ï¼‰
                if self.image_queue.qsize() == 0:
                    display_image = image_data
                else:
                    display_image = image_data.copy()
            else:
                display_image = image_data.copy() if image_data is not None else None
            
            display_packet = {
                'image': display_image,
                'info': info.copy() if info else {},
                'manual_info': manual_info.copy() if manual_info else [],
                'timestamp': time.time()
            }

            self.image_queue.put_nowait(display_packet)

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°å›¾åƒæ—¶å‡ºé”™: {e}")

    def set_manual_mode(self, manual_mode):
        self.manual_mode = manual_mode
        self.exit_manual_flag = False
        self.key_states = {}
        self.last_keys = {}
        print(f"ğŸ”„ {'è¿›å…¥' if manual_mode else 'é€€å‡º'}æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")

    def get_control_inputs(self):
        return self.key_states.copy()

    def should_exit_manual(self):
        return self.exit_manual_flag

    def _display_loop(self):
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, self.window_width, self.window_height)

        wait_img = np.zeros((300, 400, 3), dtype=np.uint8)
        wait_img = put_chinese_text(wait_img, "ç­‰å¾…æ— äººæœºå›¾åƒ...", (50, 150), 24, (255, 255, 255), 2)
        cv2.imshow(self.window_name, wait_img)
        cv2.waitKey(100)

        print("ğŸ’¡ å‰è§†çª—å£æ§åˆ¶:")
        print("   - é€šç”¨æ§åˆ¶: P=æš‚åœ/ç»§ç»­, I=ä¿¡æ¯æ˜¾ç¤º, H=é”åŒ–æ•ˆæœ")
        print("   - éæ‰‹åŠ¨æ¨¡å¼: Q=å…³é—­çª—å£, S=ä¿å­˜æˆªå›¾")
        print("   - æ‰‹åŠ¨æ¨¡å¼: ESC=é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")
        print("\nğŸ® æ‰‹åŠ¨æ§åˆ¶é”®ä½:")
        print("   - W/S: å‰è¿›/åé€€, A/D: å·¦ç§»/å³ç§»")
        print("   - Q/E: ä¸Šå‡/ä¸‹é™, Z/X: å·¦è½¬/å³è½¬")
        print("   - ç©ºæ ¼: æ‚¬åœ, ESC: é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")

        while self.display_active and not self.exit_display_flag:
            display_image = None
            info = {}
            manual_info = []

            try:
                if not self.image_queue.empty():
                    packet = self.image_queue.get_nowait()
                    display_image = packet['image']
                    info = packet['info']
                    manual_info = packet['manual_info']

                    self._update_stats()

                    while not self.image_queue.empty():
                        try:
                            self.image_queue.get_nowait()
                        except queue.Empty:
                            break
            except queue.Empty:
                pass

            if display_image is not None:
                if self.show_info:
                    display_image = self._add_info_overlay(display_image, info, manual_info)

                cv2.imshow(self.window_name, display_image)
            elif self.paused:
                blank = np.zeros((300, 400, 3), dtype=np.uint8)
                cv2.putText(blank, "PAUSED", (120, 150),
                           cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)
                cv2.imshow(self.window_name, blank)

            key = cv2.waitKey(config.DISPLAY['FRONT_VIEW_WINDOW'].get('REFRESH_RATE_MS', 30)) & 0xFF

            current_keys = {}
            if key != 255:
                current_keys[key] = True

                if self.manual_mode:
                    self._handle_manual_mode_key(key)
                else:
                    self._handle_window_control_key(key, display_image)

            self._update_key_states(current_keys)

            try:
                if cv2.getWindowProperty(self.window_name, cv2.WND_PROP_VISIBLE) < 1:
                    print("ğŸ”„ ç”¨æˆ·å…³é—­äº†å‰è§†çª—å£")
                    self.display_active = False
                    break
            except:
                self.display_active = False
                break

        try:
            cv2.destroyWindow(self.window_name)
        except:
            pass
        cv2.waitKey(1)

    def _handle_manual_mode_key(self, key):
        if key == 27:
            print("æ”¶åˆ°é€€å‡ºæ‰‹åŠ¨æ¨¡å¼æŒ‡ä»¤")
            self.exit_manual_flag = True
            return

        self.key_states[key] = True

        if key == 32:
            print("â¸ï¸ æ‚¬åœæŒ‡ä»¤")

    def _handle_window_control_key(self, key, display_image):
        key_char = chr(key).lower() if 0 <= key <= 255 else ''

        if key_char == 'q':
            print("ğŸ”„ ç”¨æˆ·å…³é—­æ˜¾ç¤ºçª—å£")
            self.display_active = False
        elif key_char == 's' and display_image is not None:
            self._save_screenshot(display_image)
        elif key_char == 'p':
            self.paused = not self.paused
            status = "å·²æš‚åœ" if self.paused else "å·²æ¢å¤"
            print(f"â¸ï¸ è§†é¢‘æµ{status}")
        elif key_char == 'i':
            self.show_info = not self.show_info
            status = "å¼€å¯" if self.show_info else "å…³é—­"
            print(f"ğŸ“Š ä¿¡æ¯å åŠ å±‚{status}")
        elif key_char == 'h':
            self.enable_sharpening = not self.enable_sharpening
            status = "å¼€å¯" if self.enable_sharpening else "å…³é—­"
            print(f"ğŸ” å›¾åƒé”åŒ–{status}")

    def _update_key_states(self, current_keys):
        released_keys = []
        for key in list(self.key_states.keys()):
            if key not in current_keys:
                released_keys.append(key)

        for key in released_keys:
            del self.key_states[key]

        self.last_keys = current_keys.copy()

    def _update_stats(self):
        now = time.time()
        self.display_stats['frame_count'] += 1

        if now - self.display_stats['last_update'] >= 1.0:
            self.display_stats['fps'] = self.display_stats['frame_count'] / (now - self.display_stats['last_update'])
            self.display_stats['frame_count'] = 0
            self.display_stats['last_update'] = now

    def _add_info_overlay(self, image: np.ndarray, info: Dict, manual_info: List[str] = None) -> np.ndarray:
        if image is None or image.size == 0:
            return image

        try:
            overlay = image.copy()
            height, width = image.shape[:2]

            is_manual = info.get('state', '') == "æ‰‹åŠ¨æ§åˆ¶"

            info_height = 180 if is_manual and manual_info else 100

            cv2.rectangle(overlay, (0, 0), (width, info_height), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.7, image, 0.3, 0, image)

            state = info.get('state', 'UNKNOWN')
            state_color = (0, 255, 0) if 'æ¢ç´¢' in state else (0, 255, 255) if 'æ‚¬åœ' in state else (255, 255, 0) if 'æ‰‹åŠ¨' in state else (0, 0, 255)
            image = put_chinese_text(image, f"çŠ¶æ€: {state}", (10, 30), 21, state_color, 2)

            pos = info.get('position', (0, 0, 0))
            image = put_chinese_text(image, f"ä½ç½®: ({pos[0]:.1f}, {pos[1]:.1f}, {-pos[2]:.1f}m)", (10, 60), 18, (255, 255, 255), 1)

            red_objects_count = info.get('red_objects_count', 0)
            red_objects_visited = info.get('red_objects_visited', 0)
            blue_objects_count = info.get('blue_objects_count', 0)
            blue_objects_visited = info.get('blue_objects_visited', 0)
            black_objects_count = info.get('black_objects_count', 0)
            black_objects_visited = info.get('black_objects_visited', 0)

            if red_objects_count > 0 or blue_objects_count > 0 or black_objects_count > 0:
                red_text = f"çº¢è‰²ç‰©ä½“: {red_objects_visited}/{red_objects_count}"
                blue_text = f"è“è‰²ç‰©ä½“: {blue_objects_visited}/{blue_objects_count}"
                black_text = f"é»‘è‰²ç‰©ä½“: {black_objects_visited}/{black_objects_count}"
                image = put_chinese_text(image, red_text, (10, 90), 18, (0, 100, 255), 2)
                image = put_chinese_text(image, blue_text, (10, 110), 18, (255, 100, 0), 2)
                image = put_chinese_text(image, black_text, (10, 130), 18, (128, 128, 128), 2)

            if is_manual and manual_info:
                y_start = 170 if (red_objects_count > 0 or blue_objects_count > 0 or black_objects_count > 0) else 100
                for i, line in enumerate(manual_info):
                    y_pos = y_start + i * 20
                    image = put_chinese_text(image, line, (10, y_pos), 15, (200, 255, 200), 1)

                image = put_chinese_text(image, "æ‰‹åŠ¨æ§åˆ¶ä¸­...", (width - 150, 60), 18, (255, 255, 0), 1)
            elif not is_manual and red_objects_count == 0 and blue_objects_count == 0 and black_objects_count == 0:
                obs_dist = info.get('obstacle_distance', 0.0)
                obs_color = (0, 0, 255) if obs_dist < 5.0 else (0, 165, 255) if obs_dist < 10.0 else (0, 255, 0)
                image = put_chinese_text(image, f"éšœç¢: {obs_dist:.1f}m", (10, 90), 21, obs_color, 2)

            fps_text = f"FPS: {self.display_stats['fps']:.1f}"
            cv2.putText(image, fps_text, (width - 120, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)

            return image
        except Exception as e:
            print(f"âš ï¸ æ·»åŠ ä¿¡æ¯å åŠ å±‚å‡ºé”™: {e}")
            return image

    def _save_screenshot(self, image: Optional[np.ndarray]):
        if image is not None and image.size > 0:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"drone_snapshot_{timestamp}.png"
            cv2.imwrite(filename, image)
            print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {filename}")
        else:
            print("âš ï¸ æ— æ³•ä¿å­˜æˆªå›¾ï¼šæ— æœ‰æ•ˆå›¾åƒæ•°æ®")


class InfoDisplayWindow:
    """ä¿¡æ¯æ˜¾ç¤ºçª—å£ - æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€ã€æ¢ç´¢ç½‘æ ¼ã€ç‰©ä½“ç»Ÿè®¡ç­‰ä¿¡æ¯"""

    def __init__(self, window_name=None, width=None, height=None):
        self.window_name = window_name if window_name else config.DISPLAY['INFO_WINDOW']['NAME']
        self.window_width = width if width is not None else config.DISPLAY['INFO_WINDOW']['WIDTH']
        self.window_height = height if height is not None else config.DISPLAY['INFO_WINDOW']['HEIGHT']

        self.display_config = config.DISPLAY['INFO_WINDOW']
        self.info_queue = queue.Queue(maxsize=3)
        self.display_active = True
        self.display_thread = None
        self.last_update = time.time()

        self.start()

    def start(self):
        if self.display_thread and self.display_thread.is_alive():
            return

        self.display_active = True
        self.display_thread = threading.Thread(
            target=self._display_loop,
            daemon=True,
            name="InfoDisplayWindow"
        )
        self.display_thread.start()
        print(f"ğŸ“Š ä¿¡æ¯æ˜¾ç¤ºçª—å£å·²å¯åŠ¨: {self.window_name}")

    def stop(self):
        self.display_active = False
        if self.display_thread:
            self.display_thread.join(timeout=2.0)

    def update_info(self, info_data: Dict):
        if not self.display_active:
            return

        try:
            if self.info_queue.full():
                try:
                    self.info_queue.get_nowait()
                except queue.Empty:
                    pass

            self.info_queue.put_nowait(info_data.copy())

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°ä¿¡æ¯æ•°æ®æ—¶å‡ºé”™: {e}")

    def _display_loop(self):
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.resizeWindow(self.window_name, self.window_width, self.window_height)

        wait_img = self._create_waiting_screen()
        cv2.imshow(self.window_name, wait_img)
        cv2.waitKey(100)

        print("ğŸ“Š ä¿¡æ¯æ˜¾ç¤ºçª—å£å·²å°±ç»ª")
        print("  æ˜¾ç¤ºå†…å®¹: æ¢ç´¢ç½‘æ ¼ã€ç³»ç»ŸçŠ¶æ€ã€ç‰©ä½“ç»Ÿè®¡ã€æ€§èƒ½ä¿¡æ¯")

        last_render_time = time.time()
        info_data = {}

        while self.display_active:
            current_time = time.time()

            # ä»é˜Ÿåˆ—è·å–æœ€æ–°ä¿¡æ¯
            try:
                while not self.info_queue.empty():
                    info_data = self.info_queue.get_nowait()
            except queue.Empty:
                pass

            # å®šæœŸåˆ·æ–°æ˜¾ç¤º
            if current_time - last_render_time >= self.display_config['REFRESH_RATE_MS'] / 1000.0:
                display_image = self._render_info_display(info_data)
                if display_image is not None:
                    cv2.imshow(self.window_name, display_image)
                last_render_time = current_time

            # å¤„ç†çª—å£äº‹ä»¶
            key = cv2.waitKey(10) & 0xFF
            if key == ord('q') or key == 27:  # Qæˆ–ESCå…³é—­çª—å£
                print("ğŸ”„ ç”¨æˆ·å…³é—­ä¿¡æ¯çª—å£")
                self.display_active = False
                break

            try:
                if cv2.getWindowProperty(self.window_name, cv2.WND_PROP_VISIBLE) < 1:
                    print("ğŸ”„ ä¿¡æ¯çª—å£è¢«å…³é—­")
                    self.display_active = False
                    break
            except:
                self.display_active = False
                break

        try:
            cv2.destroyWindow(self.window_name)
        except:
            pass
        cv2.waitKey(1)

    def _create_waiting_screen(self):
        """åˆ›å»ºç­‰å¾…å±å¹•"""
        img = np.zeros((self.window_height, self.window_width, 3), dtype=np.uint8)
        bg_color = self.display_config['BACKGROUND_COLOR']
        img[:, :] = bg_color

        center_x = self.window_width // 2
        center_y = self.window_height // 2

        # æ ‡é¢˜
        title = "æ— äººæœºä¿¡æ¯é¢æ¿"
        img = put_chinese_text(img, title, (center_x - 150, center_y - 100), 36, self.display_config['HIGHLIGHT_COLOR'], 2)

        # çŠ¶æ€ä¿¡æ¯
        status = "ç­‰å¾…æ•°æ®..."
        img = put_chinese_text(img, status, (center_x - 80, center_y), 24, self.display_config['TEXT_COLOR'], 1)

        # æç¤º
        tip = "ç³»ç»Ÿæ­£åœ¨åˆå§‹åŒ–ï¼Œè¯·ç¨å€™..."
        img = put_chinese_text(img, tip, (center_x - 120, center_y + 50), 18, self.display_config['TEXT_COLOR'], 1)

        return img

    def _render_info_display(self, info_data: Dict) -> np.ndarray:
        """æ¸²æŸ“ä¿¡æ¯æ˜¾ç¤º"""
        try:
            # åˆ›å»ºèƒŒæ™¯
            img = np.zeros((self.window_height, self.window_width, 3), dtype=np.uint8)
            bg_color = self.display_config['BACKGROUND_COLOR']
            img[:, :] = bg_color

            text_color = self.display_config['TEXT_COLOR']
            highlight_color = self.display_config['HIGHLIGHT_COLOR']
            warning_color = self.display_config['WARNING_COLOR']
            success_color = self.display_config['SUCCESS_COLOR']

            y_offset = 40
            x_offset = 20

            # æ ‡é¢˜æ 
            title = "æ— äººæœºä¿¡æ¯é¢æ¿"
            img = put_chinese_text(img, title, (self.window_width // 2 - 100, 30), 30, highlight_color, 2)

            # åˆ†éš”çº¿
            cv2.line(img, (10, 50), (self.window_width - 10, 50), text_color, 1)

            y_offset = 80

            # 1. é£è¡ŒçŠ¶æ€ä¿¡æ¯
            if 'state' in info_data:
                state = info_data['state']
                state_color = success_color if 'æ¢ç´¢' in state else highlight_color if 'æ‚¬åœ' in state else warning_color if 'ç´§æ€¥' in state else text_color
                img = put_chinese_text(img, f"é£è¡ŒçŠ¶æ€: {state}", (x_offset, y_offset), 21, state_color, 2)
                y_offset += 30

            # 2. ä½ç½®ä¿¡æ¯
            if 'position' in info_data:
                pos = info_data['position']
                pos_text = f"ä½ç½®: X:{pos[0]:.1f}m Y:{pos[1]:.1f}m é«˜åº¦:{-pos[2]:.1f}m"
                img = put_chinese_text(img, pos_text, (x_offset, y_offset), 18, text_color, 1)
                y_offset += 25

            # 3. ç¯å¢ƒæ„ŸçŸ¥ä¿¡æ¯
            if 'perception' in info_data:
                perception = info_data['perception']
                obs_text = f"éšœç¢è·ç¦»: {perception.get('obstacle_distance', 0):.1f}m"
                obs_color = warning_color if perception.get('obstacle_distance', 0) < 5.0 else text_color
                img = put_chinese_text(img, obs_text, (x_offset, y_offset), 18, obs_color, 1)
                y_offset += 25

                open_text = f"å¼€é˜”åº¦: {perception.get('open_space_score', 0):.2f}"
                img = put_chinese_text(img, open_text, (x_offset, y_offset), 18, text_color, 1)
                y_offset += 25

            # 4. ç‰©ä½“æ£€æµ‹ç»Ÿè®¡
            if 'objects_stats' in info_data:
                objects_stats = info_data['objects_stats']

                # çº¢è‰²ç‰©ä½“ç»Ÿè®¡
                red_total = objects_stats.get('red_total', 0)
                red_visited = objects_stats.get('red_visited', 0)
                red_text = f"çº¢è‰²ç‰©ä½“: {red_visited}/{red_total}"
                red_color = success_color if red_visited > 0 else text_color
                img = put_chinese_text(img, red_text, (x_offset, y_offset), 21, red_color, 1)
                y_offset += 30

                # è“è‰²ç‰©ä½“ç»Ÿè®¡
                blue_total = objects_stats.get('blue_total', 0)
                blue_visited = objects_stats.get('blue_visited', 0)
                blue_text = f"è“è‰²ç‰©ä½“: {blue_visited}/{blue_total}"
                blue_color = success_color if blue_visited > 0 else text_color
                img = put_chinese_text(img, blue_text, (x_offset, y_offset), 21, blue_color, 1)
                y_offset += 30
                
                # é»‘è‰²ç‰©ä½“ç»Ÿè®¡
                black_total = objects_stats.get('black_total', 0)
                black_visited = objects_stats.get('black_visited', 0)
                if black_total > 0:
                    black_text = f"é»‘è‰²ç‰©ä½“: {black_visited}/{black_total}"
                    black_color = success_color if black_visited > 0 else text_color
                    img = put_chinese_text(img, black_text, (x_offset, y_offset), 21, black_color, 1)
                    y_offset += 30

            # 5. æ¢ç´¢ç½‘æ ¼ä¿¡æ¯
            if 'grid_stats' in info_data:
                grid_stats = info_data['grid_stats']
                frontiers = grid_stats.get('frontiers', 0)
                explored = grid_stats.get('explored', 0)
                total = grid_stats.get('total', 1)

                grid_text = f"æ¢ç´¢ç½‘æ ¼: {frontiers}å‰æ²¿ | {explored}/{total}å·²æ¢ç´¢"
                img = put_chinese_text(img, grid_text, (x_offset, y_offset), 18, text_color, 1)
                y_offset += 25

                # æ¢ç´¢è¿›åº¦æ¡
                progress = explored / total if total > 0 else 0
                bar_width = 200
                bar_height = 15
                bar_x = x_offset
                bar_y = y_offset

                # èƒŒæ™¯æ¡
                cv2.rectangle(img, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), (50, 50, 50), -1)
                # è¿›åº¦æ¡
                progress_width = int(bar_width * progress)
                progress_color = (0, int(255 * progress), int(255 * (1 - progress)))
                cv2.rectangle(img, (bar_x, bar_y), (bar_x + progress_width, bar_y + bar_height), progress_color, -1)
                # è¾¹æ¡†
                cv2.rectangle(img, (bar_x, bar_y), (bar_x + bar_width, bar_y + bar_height), text_color, 1)
                # è¿›åº¦æ–‡æœ¬
                progress_text = f"{progress*100:.1f}%"
                cv2.putText(img, progress_text, (bar_x + bar_width + 10, bar_y + 12),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)
                y_offset += 35

            # 6. ç³»ç»Ÿæ€§èƒ½ä¿¡æ¯
            if 'performance' in info_data:
                performance = info_data['performance']
                cpu_usage = performance.get('cpu_usage', 0)
                memory_usage = performance.get('memory_usage', 0)
                loop_time = performance.get('loop_time', 0) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

                cpu_color = warning_color if cpu_usage > 80 else text_color
                mem_color = warning_color if memory_usage > 80 else text_color
                loop_color = warning_color if loop_time > 200 else text_color

                img = put_chinese_text(img, f"CPUä½¿ç”¨ç‡: {cpu_usage:.1f}%", (x_offset, y_offset), 18, cpu_color, 1)
                y_offset += 25

                img = put_chinese_text(img, f"å†…å­˜ä½¿ç”¨ç‡: {memory_usage:.1f}%", (x_offset, y_offset), 18, mem_color, 1)
                y_offset += 25

                img = put_chinese_text(img, f"å¾ªç¯æ—¶é—´: {loop_time:.1f}ms", (x_offset, y_offset), 18, loop_color, 1)
                y_offset += 25

            # 7. æ¢ç´¢ç½‘æ ¼å›¾åƒï¼ˆå³ä¾§ï¼‰
            if self.display_config['SHOW_GRID'] and 'grid_image' in info_data:
                grid_img = info_data['grid_image']
                if grid_img is not None and grid_img.size > 0:
                    grid_size = self.display_config['GRID_SIZE']
                    grid_resized = cv2.resize(grid_img, (grid_size, grid_size))

                    grid_x = self.window_width - grid_size - 20
                    grid_y = 80

                    # æ·»åŠ ç½‘æ ¼æ ‡é¢˜
                    img = put_chinese_text(img, "æ¢ç´¢ç½‘æ ¼", (grid_x, grid_y - 10), 18, highlight_color, 1)

                    # æ·»åŠ å›¾ä¾‹
                    legend_y = grid_y + grid_size + 20
                    img = put_chinese_text(img, "å›¾ä¾‹:", (grid_x, legend_y), 15, text_color, 1)
                    legend_y += 20

                    # å½“å‰ä½ç½®
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 255, 0), -1)
                    img = put_chinese_text(img, "å½“å‰ä½ç½®", (grid_x + 20, legend_y + 12), 12, text_color, 1)
                    legend_y += 25

                    # éšœç¢ç‰©
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 0, 255), -1)
                    img = put_chinese_text(img, "éšœç¢ç‰©", (grid_x + 20, legend_y + 12), 12, text_color, 1)
                    legend_y += 25

                    # çº¢è‰²ç‰©ä½“
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 100, 255), -1)
                    img = put_chinese_text(img, "çº¢è‰²ç‰©ä½“", (grid_x + 20, legend_y + 12), 12, text_color, 1)
                    legend_y += 25

                    # è“è‰²ç‰©ä½“
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (255, 100, 0), -1)
                    img = put_chinese_text(img, "è“è‰²ç‰©ä½“", (grid_x + 20, legend_y + 12), 12, text_color, 1)
                    legend_y += 25

                    # é»‘è‰²ç‰©ä½“
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (128, 128, 128), -1)
                    img = put_chinese_text(img, "é»‘è‰²ç‰©ä½“", (grid_x + 20, legend_y + 12), 12, text_color, 1)
                    legend_y += 25

                    # å‰æ²¿åŒºåŸŸ
                    cv2.rectangle(img, (grid_x, legend_y), (grid_x + 15, legend_y + 15), (0, 200, 0), -1)
                    img = put_chinese_text(img, "æ¢ç´¢å‰æ²¿", (grid_x + 20, legend_y + 12), 12, text_color, 1)

                    # å°†ç½‘æ ¼å›¾åƒæ”¾åˆ°ä¸»å›¾åƒä¸Š
                    img[grid_y:grid_y+grid_size, grid_x:grid_x+grid_size] = grid_resized

            # 8. æ—¶é—´æˆ³
            if 'timestamp' in info_data:
                timestamp = info_data['timestamp']
                time_text = f"æ›´æ–°æ—¶é—´: {timestamp}"
                img = put_chinese_text(img, time_text, (self.window_width - 200, self.window_height - 10), 15, text_color, 1)

            # 9. åº•éƒ¨æç¤º
            hint_text = "æŒ‰ Q æˆ– ESC å…³é—­çª—å£"
            img = put_chinese_text(img, hint_text, (self.window_width // 2 - 80, self.window_height - 30), 15, text_color, 1)

            return img

        except Exception as e:
            print(f"âš ï¸ æ¸²æŸ“ä¿¡æ¯æ˜¾ç¤ºæ—¶å‡ºé”™: {e}")
            error_img = np.zeros((self.window_height, self.window_width, 3), dtype=np.uint8)
            error_img[:, :] = self.display_config['BACKGROUND_COLOR']
            error_img = put_chinese_text(error_img, "æ¸²æŸ“é”™è¯¯", (self.window_width // 2 - 50, self.window_height // 2), 30, warning_color, 2)
            return error_img


class PerceptiveExplorer:
    """åŸºäºæ„ŸçŸ¥çš„è‡ªä¸»æ¢ç´¢æ— äººæœº - æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆï¼ˆåŒè‰²ç‰©ä½“æ£€æµ‹ç‰ˆï¼‰"""

    def __init__(self, drone_name=""):
        self._setup_logging()
        self.logger.info("=" * 60)
        self.logger.info("AirSimNH æ„ŸçŸ¥é©±åŠ¨è‡ªä¸»æ¢ç´¢ç³»ç»Ÿ - åŒçª—å£åŒè‰²ç‰©ä½“æ£€æµ‹ç‰ˆ")
        self.logger.info("=" * 60)

        self.client = None
        self.drone_name = drone_name
        self._connect_to_airsim()

        try:
            self.client.enableApiControl(True, vehicle_name=drone_name)
            self.client.armDisarm(True, vehicle_name=drone_name)
            self.logger.info("âœ… APIæ§åˆ¶å·²å¯ç”¨")
        except Exception as e:
            self.logger.error(f"âŒ å¯ç”¨APIæ§åˆ¶å¤±è´¥: {e}")
            raise

        self.state = FlightState.TAKEOFF
        self.state_history = deque(maxlen=20)
        self.emergency_flag = False

        self.depth_threshold_near = config.PERCEPTION['DEPTH_NEAR_THRESHOLD']
        self.depth_threshold_safe = config.PERCEPTION['DEPTH_SAFE_THRESHOLD']
        self.min_ground_clearance = config.PERCEPTION['MIN_GROUND_CLEARANCE']
        self.max_pitch_angle = math.radians(config.PERCEPTION['MAX_PITCH_ANGLE_DEG'])
        self.scan_angles = config.PERCEPTION['SCAN_ANGLES']

        self.exploration_time = config.EXPLORATION['TOTAL_TIME']
        self.preferred_speed = config.EXPLORATION['PREFERRED_SPEED']
        self.max_altitude = config.EXPLORATION['MAX_ALTITUDE']
        self.min_altitude = config.EXPLORATION['MIN_ALTITUDE']
        self.base_height = config.EXPLORATION['BASE_HEIGHT']
        self.takeoff_height = config.EXPLORATION['TAKEOFF_HEIGHT']

        self.vector_planner = VectorFieldPlanner()
        self.exploration_grid = ExplorationGrid(
            resolution=config.INTELLIGENT_DECISION['GRID_RESOLUTION'],
            grid_size=config.INTELLIGENT_DECISION['GRID_SIZE']
        )

        self.velocity_pid = PIDController(
            config.INTELLIGENT_DECISION['PID_KP'],
            config.INTELLIGENT_DECISION['PID_KI'],
            config.INTELLIGENT_DECISION['PID_KD']
        )
        self.height_pid = PIDController(1.0, 0.1, 0.3)

        self.exploration_target = None
        self.target_update_time = 0
        self.target_lifetime = config.INTELLIGENT_DECISION.get('TARGET_LIFETIME', 15.0)
        self.target_reached_distance = config.INTELLIGENT_DECISION.get('TARGET_REACHED_DISTANCE', 3.0)

        self.red_objects = []
        self.red_object_id_counter = 0
        self.last_red_detection_time = 0
        self.red_detection_interval = config.PERCEPTION['RED_OBJECT_DETECTION']['UPDATE_INTERVAL']
        self.red_object_memory_time = config.PERCEPTION['RED_OBJECT_DETECTION']['MEMORY_TIME']

        self.blue_objects = []
        self.blue_object_id_counter = 0
        self.last_blue_detection_time = 0
        self.blue_detection_interval = config.PERCEPTION['BLUE_OBJECT_DETECTION']['UPDATE_INTERVAL']
        self.blue_object_memory_time = config.PERCEPTION['BLUE_OBJECT_DETECTION']['MEMORY_TIME']

        self.black_objects = []
        self.black_object_id_counter = 0
        self.last_black_detection_time = 0
        self.black_detection_interval = config.PERCEPTION['BLACK_OBJECT_DETECTION']['UPDATE_INTERVAL']
        self.black_object_memory_time = config.PERCEPTION['BLACK_OBJECT_DETECTION']['MEMORY_TIME']

        self.visited_positions = deque(maxlen=100)

        self.loop_count = 0
        self.start_time = time.time()
        self.last_health_check = 0
        self.reconnect_attempts = 0
        self.last_successful_loop = time.time()

        self.data_logger = None
        self.last_data_record_time = 0
        self.data_record_interval = config.DATA_RECORDING.get('RECORD_INTERVAL', 0.2)
        if config.DATA_RECORDING['ENABLED']:
            self._setup_data_logger()

        self.last_performance_report = time.time()
        self.performance_report_interval = config.PERFORMANCE.get('REPORT_INTERVAL', 30.0)

        self.stats = {
            'perception_cycles': 0,
            'decision_cycles': 0,
            'exceptions_caught': 0,
            'obstacles_detected': 0,
            'state_changes': 0,
            'front_image_updates': 0,
            'manual_control_time': 0.0,
            'vector_field_updates': 0,
            'grid_updates': 0,
            'data_points_recorded': 0,
            'average_loop_time': 0.0,
            'max_loop_time': 0.0,
            'min_loop_time': 100.0,
            'red_objects_detected': 0,
            'red_objects_visited': 0,
            'blue_objects_detected': 0,
            'blue_objects_visited': 0,
            'black_objects_detected': 0,
            'black_objects_visited': 0,
        }

        # åˆå§‹åŒ–ä¸¤ä¸ªçª—å£
        self.front_window = None
        self.info_window = None
        self._setup_windows()

        self.manual_control_start = 0
        self.control_keys = {}

        self.logger.info("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"   å¼€å§‹æ—¶é—´: {datetime.now().strftime('%H:%M:%S')}")
        self.logger.info(f"   é¢„è®¡æ¢ç´¢æ—¶é•¿: {self.exploration_time}ç§’")
        self.logger.info(f"   æ™ºèƒ½å†³ç­–: å‘é‡åœºé¿éšœ + ç½‘æ ¼æ¢ç´¢ + ä¸‰è‰²ç‰©ä½“æ£€æµ‹")
        self.logger.info(f"   æ˜¾ç¤ºç³»ç»Ÿ: åŒçª—å£æ¨¡å¼ (å‰è§†çª—å£ + ä¿¡æ¯çª—å£)")
        if config.DATA_RECORDING['ENABLED']:
            self.logger.info(f"   æ•°æ®è®°å½•: CSV + JSON æ ¼å¼")
        if config.PERCEPTION['RED_OBJECT_DETECTION']['ENABLED']:
            self.logger.info(f"   çº¢è‰²ç‰©ä½“æ£€æµ‹: å·²å¯ç”¨")
        if config.PERCEPTION['BLUE_OBJECT_DETECTION']['ENABLED']:
            self.logger.info(f"   è“è‰²ç‰©ä½“æ£€æµ‹: å·²å¯ç”¨")
        if config.PERCEPTION['BLACK_OBJECT_DETECTION']['ENABLED']:
            self.logger.info(f"   é»‘è‰²ç‰©ä½“æ£€æµ‹: å·²å¯ç”¨")

    def _setup_logging(self):
        self.logger = logging.getLogger('DroneExplorer')
        self.logger.setLevel(getattr(logging, config.SYSTEM['LOG_LEVEL']))

        if self.logger.hasHandlers():
            self.logger.handlers.clear()

        console_handler = logging.StreamHandler(sys.stdout)
        console_format = logging.Formatter('%(asctime)s | %(levelname)-8s | %(message)s', datefmt='%H:%M:%S')
        console_handler.setFormatter(console_format)
        self.logger.addHandler(console_handler)

        if config.SYSTEM['LOG_TO_FILE']:
            try:
                file_handler = logging.FileHandler(config.SYSTEM['LOG_FILENAME'], encoding='utf-8')
                file_format = logging.Formatter('%(asctime)s | %(name)s | %(levelname)-8s | %(message)s')
                file_handler.setFormatter(file_format)
                self.logger.addHandler(file_handler)
                self.logger.info(f"ğŸ“ æ—¥å¿—å°†ä¿å­˜è‡³: {config.SYSTEM['LOG_FILENAME']}")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•åˆ›å»ºæ—¥å¿—æ–‡ä»¶: {e}")

    def _setup_data_logger(self):
        try:
            self.data_logger = DataLogger(
                enable_csv=config.DATA_RECORDING['SAVE_TO_CSV'],
                enable_json=config.DATA_RECORDING['SAVE_TO_JSON'],
                csv_filename=config.DATA_RECORDING.get('CSV_FILENAME'),
                json_filename=config.DATA_RECORDING.get('JSON_FILENAME')
            )
            self.logger.info("ğŸ“Š æ•°æ®è®°å½•å™¨åˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®è®°å½•å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.data_logger = None

    def _connect_to_airsim(self):
        max_attempts = config.SYSTEM['MAX_RECONNECT_ATTEMPTS']
        for attempt in range(1, max_attempts + 1):
            try:
                self.logger.info(f"ğŸ”„ å°è¯•è¿æ¥åˆ°AirSim (ç¬¬{attempt}æ¬¡)...")
                self.client = airsim.MultirotorClient()
                self.client.confirmConnection()
                self.logger.info("âœ… æˆåŠŸè¿æ¥åˆ°AirSim")
                self.reconnect_attempts = 0
                return
            except ConnectionRefusedError:
                self.logger.warning(f"âŒ è¿æ¥è¢«æ‹’ç»ï¼Œè¯·ç¡®ä¿AirSimæ­£åœ¨è¿è¡Œ")
            except Exception as e:
                self.logger.warning(f"âŒ è¿æ¥å¤±è´¥: {e}")

            if attempt < max_attempts:
                self.logger.info(f"â³ {config.SYSTEM['RECONNECT_DELAY']}ç§’åé‡è¯•...")
                time.sleep(config.SYSTEM['RECONNECT_DELAY'])

        self.logger.error(f"âŒ ç»è¿‡{max_attempts}æ¬¡å°è¯•åä»æ— æ³•è¿æ¥åˆ°AirSim")
        self.logger.error("è¯·æ£€æŸ¥ï¼š1. AirSimæ˜¯å¦å¯åŠ¨ 2. ç½‘ç»œè®¾ç½® 3. é˜²ç«å¢™")
        sys.exit(1)

    def _check_connection_health(self):
        try:
            self.client.ping()
            self.logger.debug("âœ… è¿æ¥å¥åº·æ£€æŸ¥é€šè¿‡")
            return True
        except Exception as e:
            self.logger.warning(f"âš ï¸ è¿æ¥å¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            try:
                self._connect_to_airsim()
                return True
            except:
                return False

    def _setup_windows(self):
        """åˆå§‹åŒ–ä¸¤ä¸ªæ˜¾ç¤ºçª—å£"""
        try:
            # å‰è§†çª—å£
            self.front_window = FrontViewWindow(
                window_name=f"{config.DISPLAY['FRONT_VIEW_WINDOW']['NAME']} - {self.drone_name or 'AirSimNH'}",
                width=config.DISPLAY['FRONT_VIEW_WINDOW']['WIDTH'],
                height=config.DISPLAY['FRONT_VIEW_WINDOW']['HEIGHT'],
                enable_sharpening=config.DISPLAY['FRONT_VIEW_WINDOW']['ENABLE_SHARPENING'],
                show_info=config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_INFO_OVERLAY']
            )
            self.logger.info("ğŸ¥ å‰è§†çª—å£å·²åˆå§‹åŒ–")

            # ä¿¡æ¯æ˜¾ç¤ºçª—å£
            self.info_window = InfoDisplayWindow(
                window_name=f"{config.DISPLAY['INFO_WINDOW']['NAME']} - {self.drone_name or 'AirSimNH'}",
                width=config.DISPLAY['INFO_WINDOW']['WIDTH'],
                height=config.DISPLAY['INFO_WINDOW']['HEIGHT']
            )
            self.logger.info("ğŸ“Š ä¿¡æ¯æ˜¾ç¤ºçª—å£å·²åˆå§‹åŒ–")

        except Exception as e:
            self.logger.error(f"âŒ çª—å£åˆå§‹åŒ–å¤±è´¥: {e}")

    def _update_info_window(self, perception: PerceptionResult):
        """æ›´æ–°ä¿¡æ¯æ˜¾ç¤ºçª—å£"""
        if not self.info_window:
            return

        try:
            # è·å–æ— äººæœºçŠ¶æ€
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            # æ”¶é›†æ€§èƒ½ä¿¡æ¯
            cpu_usage = psutil.cpu_percent(interval=0) if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0
            memory_usage = psutil.virtual_memory().percent if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0

            # å‡†å¤‡ä¿¡æ¯æ•°æ®
            info_data = {
                'timestamp': datetime.now().strftime("%H:%M:%S"),
                'state': self.state.value,
                'position': (pos.x_val, pos.y_val, pos.z_val),
                'perception': {
                    'obstacle_distance': perception.obstacle_distance,
                    'open_space_score': perception.open_space_score,
                    'has_obstacle': perception.has_obstacle
                },
                'objects_stats': {
                    'red_total': len(self.red_objects),
                    'red_visited': sum(1 for obj in self.red_objects if obj.visited),
                    'blue_total': len(self.blue_objects),
                    'blue_visited': sum(1 for obj in self.blue_objects if obj.visited),
                    'black_total': len(self.black_objects),
                    'black_visited': sum(1 for obj in self.black_objects if obj.visited),
                    'red_in_view': perception.red_objects_count,
                    'blue_in_view': perception.blue_objects_count,
                    'black_in_view': perception.black_objects_count
                },
                'grid_stats': {
                    'frontiers': len(self.exploration_grid.frontier_cells),
                    'explored': np.sum(self.exploration_grid.grid > 0.7),
                    'total': self.exploration_grid.grid_size * self.exploration_grid.grid_size
                },
                'performance': {
                    'cpu_usage': cpu_usage,
                    'memory_usage': memory_usage,
                    'loop_time': self.stats.get('average_loop_time', 0)
                }
            }

            # æ·»åŠ ç½‘æ ¼å›¾åƒ
            if config.DISPLAY['INFO_WINDOW']['SHOW_GRID']:
                grid_img = self.exploration_grid.visualize_grid(size=config.DISPLAY['INFO_WINDOW']['GRID_SIZE'])
                info_data['grid_image'] = grid_img

            # æ›´æ–°ä¿¡æ¯çª—å£
            self.info_window.update_info(info_data)

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ›´æ–°ä¿¡æ¯çª—å£æ—¶å‡ºé”™: {e}")

    def _detect_red_objects(self, image: np.ndarray, depth_array: Optional[np.ndarray] = None) -> Tuple[List[RedObject], np.ndarray]:
        red_objects = []
        marked_image = image.copy() if image is not None else None

        if not config.PERCEPTION['RED_OBJECT_DETECTION']['ENABLED'] or image is None:
            return red_objects, marked_image

        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            lower_red1 = np.array(config.CAMERA['RED_COLOR_RANGE']['LOWER1'])
            upper_red1 = np.array(config.CAMERA['RED_COLOR_RANGE']['UPPER1'])
            lower_red2 = np.array(config.CAMERA['RED_COLOR_RANGE']['LOWER2'])
            upper_red2 = np.array(config.CAMERA['RED_COLOR_RANGE']['UPPER2'])

            mask1 = cv2.inRange(hsv, lower_red1, upper_red1)
            mask2 = cv2.inRange(hsv, lower_red2, upper_red2)
            red_mask = cv2.bitwise_or(mask1, mask2)

            kernel = np.ones((5, 5), np.uint8)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_CLOSE, kernel)
            red_mask = cv2.morphologyEx(red_mask, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(red_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            try:
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                drone_pos = state.kinematics_estimated.position
                orientation = state.kinematics_estimated.orientation
                roll, pitch, yaw = airsim.to_eularian_angles(orientation)
            except:
                drone_pos = None
                yaw = 0.0

            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = config.PERCEPTION['RED_OBJECT_DETECTION']['MIN_AREA']
                max_area = config.PERCEPTION['RED_OBJECT_DETECTION']['MAX_AREA']

                if min_area <= area <= max_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2

                    aspect_ratio = w / h if h > 0 else 1.0
                    confidence = min(1.0, area / 1000.0) * (1.0 / (1.0 + abs(aspect_ratio - 1.0)))

                    world_pos = None
                    if drone_pos is not None and depth_array is not None:
                        try:
                            if 0 <= center_y < depth_array.shape[0] and 0 <= center_x < depth_array.shape[1]:
                                distance = depth_array[center_y, center_x]

                                if 0.5 < distance < 50.0:
                                    height, width = depth_array.shape
                                    fov_h = math.radians(90)

                                    pixel_angle_x = (center_x - width/2) / (width/2) * (fov_h/2)
                                    pixel_angle_y = (center_y - height/2) / (height/2) * (fov_h/2)

                                    z = distance
                                    x_rel = z * math.tan(pixel_angle_x)
                                    y_rel = z * math.tan(pixel_angle_y)

                                    world_x = x_rel * math.cos(yaw) - y_rel * math.sin(yaw) + drone_pos.x_val
                                    world_y = x_rel * math.sin(yaw) + y_rel * math.cos(yaw) + drone_pos.y_val
                                    world_z = drone_pos.z_val

                                    world_pos = (world_x, world_y, world_z)
                        except:
                            pass

                    red_object = RedObject(
                        id=self.red_object_id_counter,
                        position=world_pos if world_pos else (0.0, 0.0, 0.0),
                        pixel_position=(center_x, center_y),
                        size=area,
                        confidence=confidence,
                        timestamp=time.time(),
                        last_seen=time.time(),
                        visited=False
                    )

                    is_new_object = True
                    for existing_obj in self.red_objects:
                        if self._is_same_object(red_object, existing_obj):
                            existing_obj.last_seen = time.time()
                            existing_obj.pixel_position = red_object.pixel_position
                            existing_obj.confidence = max(existing_obj.confidence, confidence)
                            if world_pos:
                                existing_obj.position = world_pos
                            red_object = existing_obj
                            is_new_object = False
                            break

                    if is_new_object:
                        self.red_object_id_counter += 1
                        red_objects.append(red_object)
                        self.stats['red_objects_detected'] += 1
                        self.logger.info(f"ğŸ”´ æ£€æµ‹åˆ°çº¢è‰²ç‰©ä½“ #{red_object.id} (ç½®ä¿¡åº¦: {confidence:.2f})")

                        if self.data_logger and config.DATA_RECORDING['RECORD_RED_OBJECTS']:
                            self.data_logger.record_red_object(red_object)
                    else:
                        red_objects.append(red_object)

                    if marked_image is not None:
                        color = (0, 100, 255)
                        if red_object.visited:
                            color = (0, 200, 0)

                        cv2.rectangle(marked_image, (x, y), (x+w, y+h), color, 2)
                        cv2.circle(marked_image, (center_x, center_y), 5, color, -1)

                        label = f"R:{red_object.id} ({confidence:.2f})"
                        cv2.putText(marked_image, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            current_time = time.time()
            self.red_objects = [obj for obj in self.red_objects
                              if current_time - obj.last_seen < self.red_object_memory_time]

            visited_count = sum(1 for obj in self.red_objects if obj.visited)
            if len(red_objects) > 0:
                self.logger.debug(f"ğŸ”´ å½“å‰çº¢è‰²ç‰©ä½“: {len(self.red_objects)}ä¸ª, å·²è®¿é—®: {visited_count}ä¸ª")

        except Exception as e:
            self.logger.warning(f"âš ï¸ çº¢è‰²ç‰©ä½“æ£€æµ‹å¤±è´¥: {e}")

        return red_objects, marked_image

    def _detect_blue_objects(self, image: np.ndarray, depth_array: Optional[np.ndarray] = None) -> Tuple[List[BlueObject], np.ndarray]:
        blue_objects = []
        marked_image = image.copy() if image is not None else None

        if not config.PERCEPTION['BLUE_OBJECT_DETECTION']['ENABLED'] or image is None:
            return blue_objects, marked_image

        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            lower_blue = np.array(config.CAMERA['BLUE_COLOR_RANGE']['LOWER'])
            upper_blue = np.array(config.CAMERA['BLUE_COLOR_RANGE']['UPPER'])

            blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)

            kernel = np.ones((5, 5), np.uint8)
            blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_CLOSE, kernel)
            blue_mask = cv2.morphologyEx(blue_mask, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(blue_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            try:
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                drone_pos = state.kinematics_estimated.position
                orientation = state.kinematics_estimated.orientation
                roll, pitch, yaw = airsim.to_eularian_angles(orientation)
            except:
                drone_pos = None
                yaw = 0.0

            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = config.PERCEPTION['BLUE_OBJECT_DETECTION']['MIN_AREA']
                max_area = config.PERCEPTION['BLUE_OBJECT_DETECTION']['MAX_AREA']

                if min_area <= area <= max_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2

                    aspect_ratio = w / h if h > 0 else 1.0
                    confidence = min(1.0, area / 1000.0) * (1.0 / (1.0 + abs(aspect_ratio - 1.0)))

                    world_pos = None
                    if drone_pos is not None and depth_array is not None:
                        try:
                            if 0 <= center_y < depth_array.shape[0] and 0 <= center_x < depth_array.shape[1]:
                                distance = depth_array[center_y, center_x]

                                if 0.5 < distance < 50.0:
                                    height, width = depth_array.shape
                                    fov_h = math.radians(90)

                                    pixel_angle_x = (center_x - width/2) / (width/2) * (fov_h/2)
                                    pixel_angle_y = (center_y - height/2) / (height/2) * (fov_h/2)

                                    z = distance
                                    x_rel = z * math.tan(pixel_angle_x)
                                    y_rel = z * math.tan(pixel_angle_y)

                                    world_x = x_rel * math.cos(yaw) - y_rel * math.sin(yaw) + drone_pos.x_val
                                    world_y = x_rel * math.sin(yaw) + y_rel * math.cos(yaw) + drone_pos.y_val
                                    world_z = drone_pos.z_val

                                    world_pos = (world_x, world_y, world_z)
                        except:
                            pass

                    blue_object = BlueObject(
                        id=self.blue_object_id_counter,
                        position=world_pos if world_pos else (0.0, 0.0, 0.0),
                        pixel_position=(center_x, center_y),
                        size=area,
                        confidence=confidence,
                        timestamp=time.time(),
                        last_seen=time.time(),
                        visited=False
                    )

                    is_new_object = True
                    for existing_obj in self.blue_objects:
                        if self._is_same_object_blue(blue_object, existing_obj):
                            existing_obj.last_seen = time.time()
                            existing_obj.pixel_position = blue_object.pixel_position
                            existing_obj.confidence = max(existing_obj.confidence, confidence)
                            if world_pos:
                                existing_obj.position = world_pos
                            blue_object = existing_obj
                            is_new_object = False
                            break

                    if is_new_object:
                        self.blue_object_id_counter += 1
                        blue_objects.append(blue_object)
                        self.stats['blue_objects_detected'] += 1
                        self.logger.info(f"ğŸ”µ æ£€æµ‹åˆ°è“è‰²ç‰©ä½“ #{blue_object.id} (ç½®ä¿¡åº¦: {confidence:.2f})")

                        if self.data_logger and config.DATA_RECORDING['RECORD_BLUE_OBJECTS']:
                            self.data_logger.record_blue_object(blue_object)
                    else:
                        blue_objects.append(blue_object)

                    if marked_image is not None:
                        color = (255, 100, 0)
                        if blue_object.visited:
                            color = (0, 200, 0)

                        cv2.rectangle(marked_image, (x, y), (x+w, y+h), color, 2)
                        cv2.circle(marked_image, (center_x, center_y), 5, color, -1)

                        label = f"B:{blue_object.id} ({confidence:.2f})"
                        cv2.putText(marked_image, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            current_time = time.time()
            self.blue_objects = [obj for obj in self.blue_objects
                               if current_time - obj.last_seen < self.blue_object_memory_time]

            visited_count = sum(1 for obj in self.blue_objects if obj.visited)
            if len(blue_objects) > 0:
                self.logger.debug(f"ğŸ”µ å½“å‰è“è‰²ç‰©ä½“: {len(self.blue_objects)}ä¸ª, å·²è®¿é—®: {visited_count}ä¸ª")

        except Exception as e:
            self.logger.warning(f"âš ï¸ è“è‰²ç‰©ä½“æ£€æµ‹å¤±è´¥: {e}")

        return blue_objects, marked_image

    def _detect_black_objects(self, image: np.ndarray, depth_array: Optional[np.ndarray] = None) -> Tuple[List[BlackObject], np.ndarray]:
        black_objects = []
        marked_image = image.copy() if image is not None else None

        if not config.PERCEPTION['BLACK_OBJECT_DETECTION']['ENABLED'] or image is None:
            return black_objects, marked_image

        try:
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

            lower_black = np.array(config.CAMERA['BLACK_COLOR_RANGE']['LOWER'])
            upper_black = np.array(config.CAMERA['BLACK_COLOR_RANGE']['UPPER'])

            black_mask = cv2.inRange(hsv, lower_black, upper_black)

            kernel = np.ones((5, 5), np.uint8)
            black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_CLOSE, kernel)
            black_mask = cv2.morphologyEx(black_mask, cv2.MORPH_OPEN, kernel)

            contours, _ = cv2.findContours(black_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

            try:
                state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                drone_pos = state.kinematics_estimated.position
                orientation = state.kinematics_estimated.orientation
                roll, pitch, yaw = airsim.to_eularian_angles(orientation)
            except:
                drone_pos = None
                yaw = 0.0

            for contour in contours:
                area = cv2.contourArea(contour)
                min_area = config.PERCEPTION['BLACK_OBJECT_DETECTION']['MIN_AREA']
                max_area = config.PERCEPTION['BLACK_OBJECT_DETECTION']['MAX_AREA']

                if min_area <= area <= max_area:
                    x, y, w, h = cv2.boundingRect(contour)
                    center_x = x + w // 2
                    center_y = y + h // 2

                    aspect_ratio = w / h if h > 0 else 1.0
                    confidence = min(1.0, area / 1000.0) * (1.0 / (1.0 + abs(aspect_ratio - 1.0)))

                    world_pos = None
                    if drone_pos is not None and depth_array is not None:
                        try:
                            if 0 <= center_y < depth_array.shape[0] and 0 <= center_x < depth_array.shape[1]:
                                distance = depth_array[center_y, center_x]

                                if 0.5 < distance < 50.0:
                                    height, width = depth_array.shape
                                    fov_h = math.radians(90)

                                    pixel_angle_x = (center_x - width/2) / (width/2) * (fov_h/2)
                                    pixel_angle_y = (center_y - height/2) / (height/2) * (fov_h/2)

                                    z = distance
                                    x_rel = z * math.tan(pixel_angle_x)
                                    y_rel = z * math.tan(pixel_angle_y)

                                    world_x = x_rel * math.cos(yaw) - y_rel * math.sin(yaw) + drone_pos.x_val
                                    world_y = x_rel * math.sin(yaw) + y_rel * math.cos(yaw) + drone_pos.y_val
                                    world_z = drone_pos.z_val

                                    world_pos = (world_x, world_y, world_z)
                        except:
                            pass

                    black_object = BlackObject(
                        id=self.black_object_id_counter,
                        position=world_pos if world_pos else (0.0, 0.0, 0.0),
                        pixel_position=(center_x, center_y),
                        size=area,
                        confidence=confidence,
                        timestamp=time.time(),
                        last_seen=time.time(),
                        visited=False
                    )

                    is_new_object = True
                    for existing_obj in self.black_objects:
                        if self._is_same_object_black(black_object, existing_obj):
                            existing_obj.last_seen = time.time()
                            existing_obj.pixel_position = black_object.pixel_position
                            existing_obj.confidence = max(existing_obj.confidence, confidence)
                            if world_pos:
                                existing_obj.position = world_pos
                            black_object = existing_obj
                            is_new_object = False
                            break

                    if is_new_object:
                        self.black_object_id_counter += 1
                        black_objects.append(black_object)
                        self.stats['black_objects_detected'] += 1
                        self.logger.info(f"âš« æ£€æµ‹åˆ°é»‘è‰²ç‰©ä½“ #{black_object.id} (ç½®ä¿¡åº¦: {confidence:.2f})")

                        if self.data_logger and config.DATA_RECORDING['RECORD_BLACK_OBJECTS']:
                            self.data_logger.record_black_object(black_object)
                    else:
                        black_objects.append(black_object)

                    if marked_image is not None:
                        color = (128, 128, 128)
                        if black_object.visited:
                            color = (0, 200, 0)

                        cv2.rectangle(marked_image, (x, y), (x+w, y+h), color, 2)
                        cv2.circle(marked_image, (center_x, center_y), 5, color, -1)

                        label = f"K:{black_object.id} ({confidence:.2f})"
                        cv2.putText(marked_image, label, (x, y-10),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)

            current_time = time.time()
            self.black_objects = [obj for obj in self.black_objects
                               if current_time - obj.last_seen < self.black_object_memory_time]

            visited_count = sum(1 for obj in self.black_objects if obj.visited)
            if len(black_objects) > 0:
                self.logger.debug(f"âš« å½“å‰é»‘è‰²ç‰©ä½“: {len(self.black_objects)}ä¸ª, å·²è®¿é—®: {visited_count}ä¸ª")

        except Exception as e:
            self.logger.warning(f"âš ï¸ é»‘è‰²ç‰©ä½“æ£€æµ‹å¤±è´¥: {e}")

        return black_objects, marked_image

    def _is_same_object(self, obj1: RedObject, obj2: RedObject, distance_threshold=2.0) -> bool:
        if obj1.position != (0.0, 0.0, 0.0) and obj2.position != (0.0, 0.0, 0.0):
            distance = math.sqrt(
                (obj1.position[0] - obj2.position[0])**2 +
                (obj1.position[1] - obj2.position[1])**2
            )
            return distance < distance_threshold

        pixel_distance = math.sqrt(
            (obj1.pixel_position[0] - obj2.pixel_position[0])**2 +
            (obj1.pixel_position[1] - obj2.pixel_position[1])**2
        )
        time_diff = abs(obj1.timestamp - obj2.timestamp)

        return pixel_distance < 50 and time_diff < 5.0

    def _is_same_object_blue(self, obj1: BlueObject, obj2: BlueObject, distance_threshold=2.0) -> bool:
        if obj1.position != (0.0, 0.0, 0.0) and obj2.position != (0.0, 0.0, 0.0):
            distance = math.sqrt(
                (obj1.position[0] - obj2.position[0])**2 +
                (obj1.position[1] - obj2.position[1])**2
            )
            return distance < distance_threshold

        pixel_distance = math.sqrt(
            (obj1.pixel_position[0] - obj2.pixel_position[0])**2 +
            (obj1.pixel_position[1] - obj2.pixel_position[1])**2
        )
        time_diff = abs(obj1.timestamp - obj2.timestamp)

        return pixel_distance < 50 and time_diff < 5.0

    def _is_same_object_black(self, obj1: BlackObject, obj2: BlackObject, distance_threshold=2.0) -> bool:
        if obj1.position != (0.0, 0.0, 0.0) and obj2.position != (0.0, 0.0, 0.0):
            distance = math.sqrt(
                (obj1.position[0] - obj2.position[0])**2 +
                (obj1.position[1] - obj2.position[1])**2
            )
            return distance < distance_threshold

        pixel_distance = math.sqrt(
            (obj1.pixel_position[0] - obj2.pixel_position[0])**2 +
            (obj1.pixel_position[1] - obj2.pixel_position[1])**2
        )
        time_diff = abs(obj1.timestamp - obj2.timestamp)

        return pixel_distance < 50 and time_diff < 5.0

    def _check_red_object_proximity(self, current_pos):
        for obj in self.red_objects:
            if not obj.visited:
                distance = math.sqrt(
                    (obj.position[0] - current_pos[0])**2 +
                    (obj.position[1] - current_pos[1])**2
                )

                min_distance = config.INTELLIGENT_DECISION['RED_OBJECT_EXPLORATION']['MIN_DISTANCE']
                if distance < min_distance:
                    obj.visited = True
                    obj.last_seen = time.time()
                    self.stats['red_objects_visited'] += 1

                    self.logger.info(f"âœ… å·²è®¿é—®çº¢è‰²ç‰©ä½“ #{obj.id} (è·ç¦»: {distance:.1f}m)")

                    if self.data_logger:
                        event_data = {
                            'object_id': obj.id,
                            'position': obj.position,
                            'distance': distance,
                            'timestamp': time.time()
                        }
                        self.data_logger.record_event('red_object_visited', event_data)

                    self.change_state(FlightState.RED_OBJECT_INSPECTION)
                    return True

        return False

    def _check_blue_object_proximity(self, current_pos):
        for obj in self.blue_objects:
            if not obj.visited:
                distance = math.sqrt(
                    (obj.position[0] - current_pos[0])**2 +
                    (obj.position[1] - current_pos[1])**2
                )

                min_distance = config.INTELLIGENT_DECISION['BLUE_OBJECT_EXPLORATION']['MIN_DISTANCE']
                if distance < min_distance:
                    obj.visited = True
                    obj.last_seen = time.time()
                    self.stats['blue_objects_visited'] += 1

                    self.logger.info(f"âœ… å·²è®¿é—®è“è‰²ç‰©ä½“ #{obj.id} (è·ç¦»: {distance:.1f}m)")

                    if self.data_logger:
                        event_data = {
                            'object_id': obj.id,
                            'position': obj.position,
                            'distance': distance,
                            'timestamp': time.time()
                        }
                        self.data_logger.record_event('blue_object_visited', event_data)

                    self.change_state(FlightState.BLUE_OBJECT_INSPECTION)
                    return True

        return False

    def _check_black_object_proximity(self, current_pos):
        for obj in self.black_objects:
            if not obj.visited:
                distance = math.sqrt(
                    (obj.position[0] - current_pos[0])**2 +
                    (obj.position[1] - current_pos[1])**2
                )

                min_distance = config.INTELLIGENT_DECISION['BLACK_OBJECT_EXPLORATION']['MIN_DISTANCE']
                if distance < min_distance:
                    obj.visited = True
                    obj.last_seen = time.time()
                    self.stats['black_objects_visited'] += 1

                    self.logger.info(f"âœ… å·²è®¿é—®é»‘è‰²ç‰©ä½“ #{obj.id} (è·ç¦»: {distance:.1f}m)")

                    if self.data_logger:
                        event_data = {
                            'object_id': obj.id,
                            'position': obj.position,
                            'distance': distance,
                            'timestamp': time.time()
                        }
                        self.data_logger.record_event('black_object_visited', event_data)

                    self.change_state(FlightState.BLACK_OBJECT_INSPECTION)
                    return True

        return False

    def get_depth_perception(self) -> PerceptionResult:
        result = PerceptionResult()
        self.stats['perception_cycles'] += 1

        try:
            if config.SYSTEM['ENABLE_HEALTH_CHECK']:
                current_time = time.time()
                if current_time - self.last_successful_loop > 10.0:
                    self.logger.warning("âš ï¸ æ„ŸçŸ¥å¾ªç¯é•¿æ—¶é—´æ— å“åº”ï¼Œå°è¯•æ¢å¤...")
                    self._check_connection_health()

            camera_name = config.CAMERA['DEFAULT_NAME']
            responses = self.client.simGetImages([
                airsim.ImageRequest(
                    camera_name,
                    airsim.ImageType.DepthPlanar,
                    pixels_as_float=True,
                    compress=False
                ),
                airsim.ImageRequest(
                    camera_name,
                    airsim.ImageType.Scene,
                    False,
                    False
                )
            ])

            if not responses or len(responses) < 2:
                self.logger.warning("âš ï¸ å›¾åƒè·å–å¤±è´¥ï¼šå“åº”ä¸ºç©ºæˆ–æ•°é‡ä¸è¶³")
                return result

            depth_img = responses[0]
            depth_array = None
            if depth_img and hasattr(depth_img, 'image_data_float'):
                try:
                    depth_array = np.array(depth_img.image_data_float, dtype=np.float32)
                    depth_array = depth_array.reshape(depth_img.height, depth_img.width)

                    h, w = depth_array.shape

                    front_near = depth_array[h // 2:, w // 3:2 * w // 3]
                    min_front_distance = np.min(front_near) if front_near.size > 0 else 100

                    directions = []
                    for angle_deg in self.scan_angles:
                        angle_rad = math.radians(angle_deg)
                        col = int(w / 2 + (w / 2) * math.tan(angle_rad) * 0.5)
                        col = max(0, min(w - 1, col))

                        col_data = depth_array[h // 2:, col]
                        if col_data.size > 0:
                            dir_distance = np.percentile(col_data, 25)
                            directions.append((angle_rad, dir_distance))

                            if dir_distance > self.depth_threshold_safe:
                                result.safe_directions.append(angle_rad)

                    result.obstacle_positions = self._extract_obstacle_positions(depth_array, h, w)

                    ground_region = depth_array[3 * h // 4:, :]
                    if ground_region.size > 10:
                        row_variances = np.var(ground_region, axis=1)
                        result.terrain_slope = np.mean(row_variances) * 100

                    open_pixels = np.sum(depth_array[h // 2:, :] > self.depth_threshold_safe)
                    total_pixels = depth_array[h // 2:, :].size
                    result.open_space_score = open_pixels / total_pixels if total_pixels > 0 else 0

                    result.has_obstacle = min_front_distance < self.depth_threshold_near
                    result.obstacle_distance = min_front_distance
                    if result.has_obstacle:
                        self.stats['obstacles_detected'] += 1

                    if directions:
                        closest_dir = min(directions, key=lambda x: x[1])
                        result.obstacle_direction = closest_dir[0]

                    if result.terrain_slope > config.PERCEPTION['HEIGHT_STRATEGY']['SLOPE_THRESHOLD']:
                        result.recommended_height = config.PERCEPTION['HEIGHT_STRATEGY']['STEEP_SLOPE']
                    elif result.open_space_score > config.PERCEPTION['HEIGHT_STRATEGY']['OPENNESS_THRESHOLD']:
                        result.recommended_height = config.PERCEPTION['HEIGHT_STRATEGY']['OPEN_SPACE']

                except ValueError as e:
                    self.logger.error(f"âŒ æ·±åº¦å›¾åƒæ•°æ®è½¬æ¢é”™è¯¯: {e}")
                except Exception as e:
                    self.logger.error(f"âŒ æ·±åº¦å›¾åƒå¤„ç†å¼‚å¸¸: {e}")

            front_response = responses[1]
            if front_response and hasattr(front_response, 'image_data_uint8'):
                try:
                    img_array = np.frombuffer(front_response.image_data_uint8, dtype=np.uint8)

                    if len(img_array) > 0:
                        img_rgb = img_array.reshape(front_response.height, front_response.width, 3)
                        img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                        current_time = time.time()

                        # æ£€æµ‹çº¢è‰²ç‰©ä½“
                        if current_time - self.last_red_detection_time >= self.red_detection_interval:
                            red_objects, red_marked_image = self._detect_red_objects(img_bgr, depth_array)
                            result.red_objects = red_objects
                            result.red_objects_count = len(red_objects)
                            result.red_objects_image = red_marked_image
                            self.last_red_detection_time = current_time

                        # æ£€æµ‹è“è‰²ç‰©ä½“
                        if current_time - self.last_blue_detection_time >= self.blue_detection_interval:
                            blue_objects, blue_marked_image = self._detect_blue_objects(img_bgr, depth_array)
                            result.blue_objects = blue_objects
                            result.blue_objects_count = len(blue_objects)
                            result.blue_objects_image = blue_marked_image
                            self.last_blue_detection_time = current_time

                        # æ£€æµ‹é»‘è‰²ç‰©ä½“
                        if current_time - self.last_black_detection_time >= self.black_detection_interval:
                            black_objects, black_marked_image = self._detect_black_objects(img_bgr, depth_array)
                            result.black_objects = black_objects
                            result.black_objects_count = len(black_objects)
                            result.black_objects_image = black_marked_image
                            self.last_black_detection_time = current_time

                        result.front_image = img_bgr

                        display_info = self._prepare_display_info(result)

                        self._update_exploration_grid(result)

                        self._record_flight_data(result)

                        # æ›´æ–°ä¿¡æ¯çª—å£
                        self._update_info_window(result)

                        if self.front_window:
                            manual_info = None
                            if self.state == FlightState.MANUAL:
                                manual_info = self._get_manual_control_info()

                            # å†…å­˜ä¼˜åŒ–ï¼šä»…åœ¨éœ€è¦æ ‡è®°æ—¶æ‰å¤åˆ¶å›¾åƒ
                            has_markers = (config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_RED_OBJECTS'] and result.red_objects_image is not None) or \
                                         (config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLUE_OBJECTS'] and result.blue_objects_image is not None) or \
                                         (config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLACK_OBJECTS'] and result.black_objects_image is not None)
                            
                            if has_markers:
                                display_image = img_bgr.copy()
                                if config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_RED_OBJECTS'] and result.red_objects_image is not None:
                                    red_mask = cv2.inRange(result.red_objects_image, (0, 100, 0), (0, 255, 255))
                                    display_image[red_mask > 0] = result.red_objects_image[red_mask > 0]

                                if config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLUE_OBJECTS'] and result.blue_objects_image is not None:
                                    blue_mask = cv2.inRange(result.blue_objects_image, (255, 100, 0), (255, 255, 255))
                                    display_image[blue_mask > 0] = result.blue_objects_image[blue_mask > 0]

                                if config.DISPLAY['FRONT_VIEW_WINDOW']['SHOW_BLACK_OBJECTS'] and result.black_objects_image is not None:
                                    black_mask = cv2.inRange(result.black_objects_image, (128, 128, 0), (128, 255, 255))
                                    display_image[black_mask > 0] = result.black_objects_image[black_mask > 0]
                            else:
                                # æ²¡æœ‰æ ‡è®°æ—¶ç›´æ¥ä½¿ç”¨åŸå›¾åƒå¼•ç”¨
                                display_image = img_bgr

                            self.front_window.update_image(display_image, display_info, manual_info)
                            self.stats['front_image_updates'] += 1

                except Exception as e:
                    self.logger.warning(f"âš ï¸ å‰è§†å›¾åƒå¤„ç†å¼‚å¸¸: {e}")

            self.last_successful_loop = time.time()

            if self.loop_count % 50 == 0 and config.DEBUG.get('LOG_DECISION_DETAILS', False):
                self.logger.debug(f"æ„ŸçŸ¥ç»“æœ: éšœç¢={result.has_obstacle}, è·ç¦»={result.obstacle_distance:.1f}m, "
                                f"å¼€é˜”åº¦={result.open_space_score:.2f}, çº¢è‰²ç‰©ä½“={result.red_objects_count}ä¸ª, "
                                f"è“è‰²ç‰©ä½“={result.blue_objects_count}ä¸ª, é»‘è‰²ç‰©ä½“={result.black_objects_count}ä¸ª")

        except Exception as e:
            if "ClientException" in str(type(e)) or "Connection" in str(e):
                self.logger.error(f"âŒ AirSimå®¢æˆ·ç«¯å¼‚å¸¸: {e}")
                self.stats['exceptions_caught'] += 1
                if self.data_logger:
                    self.data_logger.record_event('airsim_exception', {'error': str(e)})
                self._check_connection_health()
            else:
                self.logger.error(f"âŒ æ„ŸçŸ¥è¿‡ç¨‹ä¸­å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {e}")
                self.logger.debug(f"å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                self.stats['exceptions_caught'] += 1
                if self.data_logger:
                    self.data_logger.record_event('perception_exception', {'error': str(e)})

        return result

    def _record_flight_data(self, perception: PerceptionResult):
        if not config.DATA_RECORDING['ENABLED'] or not self.data_logger:
            return

        current_time = time.time()
        if current_time - self.last_data_record_time < self.data_record_interval:
            return

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            vel = state.kinematics_estimated.linear_velocity
            orientation = state.kinematics_estimated.orientation

            roll, pitch, yaw = airsim.to_eularian_angles(orientation)

            cpu_usage = psutil.cpu_percent(interval=0) if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0
            memory_usage = psutil.virtual_memory().percent if config.PERFORMANCE['ENABLE_REALTIME_METRICS'] else 0.0

            red_objects_count = perception.red_objects_count
            red_objects_visited = sum(1 for obj in self.red_objects if obj.visited)

            blue_objects_count = perception.blue_objects_count
            blue_objects_visited = sum(1 for obj in self.blue_objects if obj.visited)

            black_objects_count = perception.black_objects_count
            black_objects_visited = sum(1 for obj in self.black_objects if obj.visited)

            data_dict = {
                'timestamp': datetime.now().isoformat(),
                'loop_count': self.loop_count,
                'state': self.state.value,
                'pos_x': pos.x_val,
                'pos_y': pos.y_val,
                'pos_z': pos.z_val,
                'vel_x': vel.x_val,
                'vel_y': vel.y_val,
                'vel_z': vel.z_val,
                'yaw': yaw,
                'pitch': pitch,
                'roll': roll,
                'obstacle_distance': perception.obstacle_distance,
                'open_space_score': perception.open_space_score,
                'terrain_slope': perception.terrain_slope,
                'has_obstacle': perception.has_obstacle,
                'obstacle_direction': perception.obstacle_direction,
                'recommended_height': perception.recommended_height,
                'target_x': self.exploration_target[0] if self.exploration_target else 0.0,
                'target_y': self.exploration_target[1] if self.exploration_target else 0.0,
                'target_z': perception.recommended_height,
                'cpu_usage': cpu_usage,
                'memory_usage': memory_usage,
                'grid_frontiers': len(self.exploration_grid.frontier_cells),
                'grid_explored': np.sum(self.exploration_grid.grid > 0.7),
                'adaptive_speed_factor': self._calculate_adaptive_speed(perception, 0) if hasattr(self, '_calculate_adaptive_speed') else 1.0,
                'red_objects_count': red_objects_count,
                'red_objects_detected': self.stats['red_objects_detected'],
                'red_objects_visited': red_objects_visited,
                'blue_objects_count': blue_objects_count,
                'blue_objects_detected': self.stats['blue_objects_detected'],
                'blue_objects_visited': blue_objects_visited,
                'black_objects_count': black_objects_count,
                'black_objects_detected': self.stats['black_objects_detected'],
                'black_objects_visited': black_objects_visited,
            }

            self.data_logger.record_flight_data(data_dict)
            self.stats['data_points_recorded'] += 1
            self.last_data_record_time = current_time

        except Exception as e:
            self.logger.warning(f"âš ï¸ è®°å½•é£è¡Œæ•°æ®æ—¶å‡ºé”™: {e}")

    def _extract_obstacle_positions(self, depth_array, height, width):
        obstacles = []

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            orientation = state.kinematics_estimated.orientation
            roll, pitch, yaw = airsim.to_eularian_angles(orientation)

            near_mask = depth_array < self.depth_threshold_near * 1.5

            step = 4
            for i in range(0, height, step):
                for j in range(0, width, step):
                    if near_mask[i, j]:
                        distance = depth_array[i, j]

                        fov_h = math.radians(90)
                        pixel_angle_x = (j - width/2) / (width/2) * (fov_h/2)
                        pixel_angle_y = (i - height/2) / (height/2) * (fov_h/2)

                        z = distance
                        x = z * math.tan(pixel_angle_x)
                        y = z * math.tan(pixel_angle_y)

                        world_x = x * math.cos(yaw) - y * math.sin(yaw) + pos.x_val
                        world_y = x * math.sin(yaw) + y * math.cos(yaw) + pos.y_val

                        obstacles.append((world_x, world_y))

            max_obstacles = 20
            if len(obstacles) > max_obstacles:
                obstacles = random.sample(obstacles, max_obstacles)

        except Exception as e:
            self.logger.warning(f"âš ï¸ æå–éšœç¢ç‰©ä½ç½®å¤±è´¥: {e}")

        return obstacles

    def _update_exploration_grid(self, perception: PerceptionResult):
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            self.exploration_grid.update_position(pos.x_val, pos.y_val)

            if perception.obstacle_positions:
                self.exploration_grid.update_obstacles(perception.obstacle_positions)

            if perception.red_objects:
                self.exploration_grid.update_red_objects(perception.red_objects)

            if perception.blue_objects:
                self.exploration_grid.update_blue_objects(perception.blue_objects)

            if perception.black_objects:
                self.exploration_grid.update_black_objects(perception.black_objects)

            self.stats['grid_updates'] += 1

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ›´æ–°æ¢ç´¢ç½‘æ ¼å¤±è´¥: {e}")

    def _prepare_display_info(self, perception: PerceptionResult) -> Dict:
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            info = {
                'state': self.state.value,
                'obstacle_distance': perception.obstacle_distance,
                'position': (pos.x_val, pos.y_val, pos.z_val),
                'loop_count': self.loop_count,
                'red_objects_count': perception.red_objects_count,
                'red_objects_visited': sum(1 for obj in self.red_objects if obj.visited),
                'blue_objects_count': perception.blue_objects_count,
                'blue_objects_visited': sum(1 for obj in self.blue_objects if obj.visited),
                'black_objects_count': perception.black_objects_count,
                'black_objects_visited': sum(1 for obj in self.black_objects if obj.visited),
            }

            if hasattr(self, 'last_decision_info'):
                info['decision_info'] = self.last_decision_info

            if config.DATA_RECORDING['ENABLED']:
                info['data_points'] = self.stats['data_points_recorded']

            return info
        except:
            return {}

    def _get_manual_control_info(self):
        info_lines = []

        if self.control_keys:
            key_names = []
            for key in self.control_keys:
                if key == ord('w'):
                    key_names.append("å‰è¿›")
                elif key == ord('s'):
                    key_names.append("åé€€")
                elif key == ord('a'):
                    key_names.append("å·¦ç§»")
                elif key == ord('d'):
                    key_names.append("å³ç§»")
                elif key == ord('q'):
                    key_names.append("ä¸Šå‡")
                elif key == ord('e'):
                    key_names.append("ä¸‹é™")
                elif key == ord('z'):
                    key_names.append("å·¦è½¬")
                elif key == ord('x'):
                    key_names.append("å³è½¬")
                elif key == 32:
                    key_names.append("æ‚¬åœ")

            if key_names:
                info_lines.append(f"æ§åˆ¶: {', '.join(key_names)}")
        else:
            info_lines.append("æ§åˆ¶: æ‚¬åœ")

        if self.red_objects:
            visited_count = sum(1 for obj in self.red_objects if obj.visited)
            info_lines.append(f"çº¢è‰²ç‰©ä½“: {visited_count}/{len(self.red_objects)}")

        if self.blue_objects:
            visited_count = sum(1 for obj in self.blue_objects if obj.visited)
            info_lines.append(f"è“è‰²ç‰©ä½“: {visited_count}/{len(self.blue_objects)}")

        if self.black_objects:
            visited_count = sum(1 for obj in self.black_objects if obj.visited)
            info_lines.append(f"é»‘è‰²ç‰©ä½“: {visited_count}/{len(self.black_objects)}")

        if self.manual_control_start > 0:
            elapsed = time.time() - self.manual_control_start
            info_lines.append(f"æ‰‹åŠ¨æ¨¡å¼: {elapsed:.1f}ç§’")

        info_lines.append("ESC: é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")

        return info_lines

    def apply_manual_control(self):
        if self.state != FlightState.MANUAL:
            return

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            orientation = state.kinematics_estimated.orientation

            _, _, yaw = airsim.to_eularian_angles(orientation)

            vx, vy, vz, yaw_rate = 0.0, 0.0, 0.0, 0.0

            for key in list(self.control_keys.keys()):
                key_char = chr(key).lower() if 0 <= key <= 255 else ''

                if key_char == 'w':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw)
                elif key_char == 's':
                    vx -= config.MANUAL['CONTROL_SPEED'] * math.cos(yaw)
                    vy -= config.MANUAL['CONTROL_SPEED'] * math.sin(yaw)

                if key_char == 'a':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw + math.pi/2)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw + math.pi/2)
                elif key_char == 'd':
                    vx += config.MANUAL['CONTROL_SPEED'] * math.cos(yaw - math.pi/2)
                    vy += config.MANUAL['CONTROL_SPEED'] * math.sin(yaw - math.pi/2)

                if key_char == 'q':
                    vz = -config.MANUAL['ALTITUDE_SPEED']
                elif key_char == 'e':
                    vz = config.MANUAL['ALTITUDE_SPEED']

                if key_char == 'z':
                    yaw_rate = -math.radians(config.MANUAL['YAW_SPEED'])
                elif key_char == 'x':
                    yaw_rate = math.radians(config.MANUAL['YAW_SPEED'])

                if key == 32:
                    self.client.hoverAsync(vehicle_name=self.drone_name)
                    self.control_keys = {}
                    return

            if config.MANUAL['SAFETY_ENABLED']:
                speed = math.sqrt(vx**2 + vy**2)
                if speed > config.MANUAL['MAX_MANUAL_SPEED']:
                    scale = config.MANUAL['MAX_MANUAL_SPEED'] / speed
                    vx *= scale
                    vy *= scale

                target_z = pos.z_val + vz * 0.1
                if target_z > config.MANUAL['MIN_ALTITUDE_LIMIT']:
                    vz = max(vz, (config.MANUAL['MIN_ALTITUDE_LIMIT'] - pos.z_val) * 10)
                if target_z < config.MANUAL['MAX_ALTITUDE_LIMIT']:
                    vz = min(vz, (config.MANUAL['MAX_ALTITUDE_LIMIT'] - pos.z_val) * 10)

            if vx != 0.0 or vy != 0.0 or vz != 0.0:
                self.client.moveByVelocityAsync(vx, vy, vz, 0.1, vehicle_name=self.drone_name)
            elif yaw_rate != 0.0:
                self.client.rotateByYawRateAsync(yaw_rate, 0.1, vehicle_name=self.drone_name)
            elif config.MANUAL['ENABLE_AUTO_HOVER'] and not self.control_keys:
                self.client.hoverAsync(vehicle_name=self.drone_name)

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ‰‹åŠ¨æ§åˆ¶åº”ç”¨å¤±è´¥: {e}")

    def change_state(self, new_state: FlightState):
        if self.state != new_state:
            old_state = self.state.value
            self.logger.info(f"ğŸ”„ çŠ¶æ€è½¬æ¢: {old_state} â†’ {new_state.value}")
            self.state = new_state
            self.state_history.append((time.time(), new_state))
            self.stats['state_changes'] += 1

            if self.data_logger:
                event_data = {
                    'old_state': old_state,
                    'new_state': new_state.value,
                    'loop_count': self.loop_count
                }
                self.data_logger.record_event('state_change', event_data)

    def run_manual_control(self):
        self.logger.info("=" * 60)
        self.logger.info("å¯åŠ¨æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
        self.logger.info("=" * 60)

        if not self.front_window:
            self.logger.error("âŒ å‰è§†çª—å£æœªåˆå§‹åŒ–")
            return

        try:
            self.change_state(FlightState.MANUAL)
            self.manual_control_start = time.time()

            self.front_window.set_manual_mode(True)

            self.logger.info("ğŸ•¹ï¸ è¿›å…¥æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
            print("\n" + "="*60)
            print("ğŸ® æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼å·²å¯åŠ¨")
            print("="*60)
            print("æ§åˆ¶é”®ä½:")
            print("  W: å‰è¿› | S: åé€€ | A: å·¦ç§» | D: å³ç§»")
            print("  Q: ä¸Šå‡ | E: ä¸‹é™ | Z: å·¦è½¬ | X: å³è½¬")
            print("  ç©ºæ ¼: æ‚¬åœ | ESC: é€€å‡ºæ‰‹åŠ¨æ¨¡å¼")
            print("="*60)
            print("ğŸ’¡ æç¤º: æŒ‰é”®æ—¶æ§åˆ¶æŒç»­ç”Ÿæ•ˆï¼Œæ¾å¼€è‡ªåŠ¨åœæ­¢")
            print("        è¯·åœ¨æ— äººæœºå‰è§†çª—å£æ“ä½œ")
            print("="*60)

            self.control_keys = {}

            manual_active = True
            last_control_time = time.time()
            last_image_time = time.time()

            while manual_active and not self.emergency_flag:
                try:
                    if self.front_window.should_exit_manual():
                        self.logger.info("æ”¶åˆ°é€€å‡ºæ‰‹åŠ¨æ¨¡å¼æŒ‡ä»¤")
                        manual_active = False
                        break

                    if self.front_window:
                        window_keys = self.front_window.get_control_inputs()
                        self.control_keys = window_keys.copy()

                    if not self.front_window.display_active:
                        self.logger.info("å‰è§†çª—å£å·²å…³é—­ï¼Œé€€å‡ºæ‰‹åŠ¨æ¨¡å¼")
                        manual_active = False
                        break

                    current_time = time.time()
                    if current_time - last_control_time >= 0.05:
                        self.apply_manual_control()
                        last_control_time = current_time

                    if current_time - last_image_time >= 0.1:
                        try:
                            camera_name = config.CAMERA['DEFAULT_NAME']
                            responses = self.client.simGetImages([
                                airsim.ImageRequest(
                                    camera_name,
                                    airsim.ImageType.Scene,
                                    False,
                                    False
                                )
                            ])

                            if responses and responses[0] and hasattr(responses[0], 'image_data_uint8'):
                                img_array = np.frombuffer(responses[0].image_data_uint8, dtype=np.uint8)
                                if len(img_array) > 0:
                                    img_rgb = img_array.reshape(responses[0].height, responses[0].width, 3)
                                    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

                                    try:
                                        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                                        pos = state.kinematics_estimated.position
                                        display_info = {
                                            'state': self.state.value,
                                            'position': (pos.x_val, pos.y_val, pos.z_val),
                                            'loop_count': self.loop_count,
                                        }
                                    except:
                                        display_info = {}

                                    if self.front_window:
                                        manual_info = self._get_manual_control_info()
                                        self.front_window.update_image(img_bgr, display_info, manual_info)
                                        last_image_time = current_time
                        except Exception as img_error:
                            pass

                    try:
                        state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                        pos = state.kinematics_estimated.position
                        current_pos = (pos.x_val, pos.y_val)
                        self._check_red_object_proximity(current_pos)
                        self._check_blue_object_proximity(current_pos)
                        self._check_black_object_proximity(current_pos)
                    except:
                        pass

                    time.sleep(0.01)

                except KeyboardInterrupt:
                    self.logger.warning("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ‰‹åŠ¨æ§åˆ¶")
                    manual_active = False
                    break
                except Exception as e:
                    self.logger.error(f"âŒ æ‰‹åŠ¨æ§åˆ¶å¾ªç¯å¼‚å¸¸: {e}")
                    time.sleep(0.1)

            manual_time = time.time() - self.manual_control_start
            self.stats['manual_control_time'] = manual_time

            self.manual_control_start = 0
            self.control_keys = {}
            if self.front_window:
                self.front_window.set_manual_mode(False)

            try:
                self.client.hoverAsync(vehicle_name=self.drone_name).join()
            except:
                pass

            self.logger.info(f"â±ï¸  æ‰‹åŠ¨æ§åˆ¶ç»“æŸï¼ŒæŒç»­æ—¶é—´: {manual_time:.1f}ç§’")

            self.change_state(FlightState.HOVERING)

            print("\n" + "="*60)
            print("æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼å·²ç»“æŸ")
            print(f"æ§åˆ¶æ—¶é—´: {manual_time:.1f}ç§’")
            print(f"æ£€æµ‹åˆ°çº¢è‰²ç‰©ä½“: {self.stats['red_objects_detected']}ä¸ª")
            print(f"æ£€æµ‹åˆ°è“è‰²ç‰©ä½“: {self.stats['blue_objects_detected']}ä¸ª")
            print("="*60)
            print("è¯·é€‰æ‹©ä¸‹ä¸€æ­¥:")
            print("  1. ç»§ç»­è‡ªåŠ¨æ¢ç´¢")
            print("  2. å†æ¬¡è¿›å…¥æ‰‹åŠ¨æ¨¡å¼")
            print("  3. é™è½å¹¶ç»“æŸä»»åŠ¡")
            print("="*60)

            choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

            if choice == '1':
                self.logger.info("ğŸ”„ è¿”å›è‡ªåŠ¨æ¢ç´¢æ¨¡å¼")
                remaining_time = self.exploration_time - (time.time() - self.start_time)
                if remaining_time > 10:
                    self.exploration_time = remaining_time
                    self.run_perception_loop()
                else:
                    self.logger.info("â° å‰©ä½™æ¢ç´¢æ—¶é—´ä¸è¶³ï¼Œå¼€å§‹è¿”èˆª")
                    self._finish_mission()
            elif choice == '2':
                self.logger.info("ğŸ”„ é‡æ–°è¿›å…¥æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
                self.run_manual_control()
            else:
                self.logger.info("ğŸ›¬ ç”¨æˆ·é€‰æ‹©ç»“æŸä»»åŠ¡")
                self._finish_mission()

        except Exception as e:
            self.logger.error(f"âŒ æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼å‘ç”Ÿå¼‚å¸¸: {e}")
            self.logger.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            self.emergency_stop()

    def run_perception_loop(self):
        self.logger.info("=" * 60)
        self.logger.info("å¯åŠ¨æ„ŸçŸ¥-å†³ç­–-æ§åˆ¶ä¸»å¾ªç¯")
        self.logger.info("=" * 60)

        try:
            self.logger.info("ğŸš€ èµ·é£ä¸­...")
            self.client.takeoffAsync(vehicle_name=self.drone_name).join()
            time.sleep(2)

            self.client.moveToZAsync(self.takeoff_height, 3, vehicle_name=self.drone_name).join()
            self.change_state(FlightState.HOVERING)
            time.sleep(2)

            exploration_start = time.time()

            while (time.time() - exploration_start < self.exploration_time and
                   not self.emergency_flag):

                self.loop_count += 1
                loop_start = time.time()

                perception = self.get_depth_perception()

                try:
                    state = self.client.getMultirotorState(vehicle_name=self.drone_name)
                    pos = state.kinematics_estimated.position
                    current_pos = (pos.x_val, pos.y_val)
                    if self._check_red_object_proximity(current_pos):
                        time.sleep(2)
                        self.change_state(FlightState.EXPLORING)
                    if self._check_blue_object_proximity(current_pos):
                        time.sleep(2)
                        self.change_state(FlightState.EXPLORING)
                    if self._check_black_object_proximity(current_pos):
                        time.sleep(2)
                        self.change_state(FlightState.EXPLORING)
                except:
                    pass

                decision = self.make_intelligent_decision(perception)

                self._execute_control_decision(decision)

                loop_time = time.time() - loop_start
                self.stats['average_loop_time'] = (self.stats['average_loop_time'] * (self.loop_count-1) + loop_time) / self.loop_count
                self.stats['max_loop_time'] = max(self.stats['max_loop_time'], loop_time)
                self.stats['min_loop_time'] = min(self.stats['min_loop_time'], loop_time)

                if self.data_logger:
                    self.data_logger.record_loop_time(loop_time)

                current_time = time.time()
                if current_time - self.last_performance_report >= self.performance_report_interval:
                    self._generate_performance_report()
                    self.last_performance_report = current_time

                if self.loop_count % config.SYSTEM.get('HEALTH_CHECK_INTERVAL', 20) == 0:
                    self._report_status(exploration_start, perception)
                    # å†…å­˜ä¼˜åŒ–ï¼šå®šæœŸåƒåœ¾å›æ”¶
                    gc.collect()

                loop_time = time.time() - loop_start
                if loop_time < 0.1:
                    time.sleep(0.1 - loop_time)

            self.logger.info("â° æ¢ç´¢æ—¶é—´åˆ°ï¼Œå¼€å§‹è¿”èˆª")
            self._finish_mission()

        except KeyboardInterrupt:
            self.logger.warning("â¹ï¸ ç”¨æˆ·ä¸­æ–­æ¢ç´¢")
            self.emergency_stop()
        except Exception as e:
            self.logger.error(f"âŒ ä¸»å¾ªç¯å‘ç”Ÿå¼‚å¸¸: {e}")
            self.logger.debug(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            self.emergency_stop()

    def _generate_performance_report(self):
        try:
            if not config.PERFORMANCE['ENABLE_REALTIME_METRICS']:
                return

            cpu_usage = psutil.cpu_percent(interval=0)
            memory_usage = psutil.virtual_memory().percent

            warnings = []
            if cpu_usage > config.PERFORMANCE['CPU_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_usage:.1f}%")

            if memory_usage > config.PERFORMANCE['MEMORY_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_usage:.1f}%")

            avg_loop_time = self.stats.get('average_loop_time', 0)
            if avg_loop_time > config.PERFORMANCE['LOOP_TIME_WARNING_THRESHOLD']:
                warnings.append(f"âš ï¸ å¹³å‡å¾ªç¯æ—¶é—´è¿‡é•¿: {avg_loop_time*1000:.1f}ms")

            if warnings:
                self.logger.warning("ğŸ“Š æ€§èƒ½è­¦å‘Š:")
                for warning in warnings:
                    self.logger.warning(f"  {warning}")

            if self.data_logger:
                performance_data = {
                    'timestamp': datetime.now().isoformat(),
                    'cpu_usage': cpu_usage,
                    'memory_usage': memory_usage,
                    'average_loop_time': avg_loop_time,
                    'max_loop_time': self.stats.get('max_loop_time', 0),
                    'min_loop_time': self.stats.get('min_loop_time', 0),
                    'warnings': warnings
                }
                self.data_logger.record_event('performance_report', performance_data)

        except Exception as e:
            self.logger.warning(f"âš ï¸ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Šæ—¶å‡ºé”™: {e}")

    def make_intelligent_decision(self, perception: PerceptionResult) -> Tuple[float, float, float, float]:
        self.stats['decision_cycles'] += 1
        decision_start = time.time()

        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            vel = state.kinematics_estimated.linear_velocity

            target_vx, target_vy, target_z, target_yaw = 0.0, 0.0, perception.recommended_height, 0.0

            if self.state == FlightState.TAKEOFF:
                target_z = self.takeoff_height
                if pos.z_val < self.takeoff_height + 0.5:
                    self.change_state(FlightState.HOVERING)

            elif self.state == FlightState.HOVERING:
                target_yaw = (time.time() % 10) * 0.2

                current_time = time.time()
                if (self.exploration_target is None or
                    current_time - self.target_update_time > self.target_lifetime):

                    self.exploration_target = self.exploration_grid.get_best_exploration_target(
                        (pos.x_val, pos.y_val),
                        perception.red_objects,
                        perception.blue_objects,
                        perception.black_objects
                    )
                    self.target_update_time = current_time

                    if self.exploration_target:
                        self.logger.info(f"ğŸ¯ æ–°æ¢ç´¢ç›®æ ‡: {self.exploration_target[0]:.1f}, {self.exploration_target[1]:.1f}")

                if self.exploration_target:
                    self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.EXPLORING:
                if perception.has_obstacle:
                    self.change_state(FlightState.AVOIDING)
                    target_vx, target_vy = -vel.x_val * 2, -vel.y_val * 2
                else:
                    current_pos = (pos.x_val, pos.y_val)

                    if self.exploration_target is None:
                        self.exploration_target = self.exploration_grid.get_best_exploration_target(
                            current_pos,
                            perception.red_objects,
                            perception.blue_objects,
                            perception.black_objects
                        )
                        self.target_update_time = time.time()

                    vector = self.vector_planner.compute_vector(
                        current_pos,
                        self.exploration_target,
                        perception.obstacle_positions,
                        perception.red_objects,
                        perception.blue_objects,
                        perception.black_objects
                    )

                    speed_factor = self._calculate_adaptive_speed(perception, vector.magnitude())

                    target_speed = self.preferred_speed * speed_factor
                    current_speed = math.sqrt(vel.x_val**2 + vel.y_val**2)
                    speed_error = target_speed - current_speed
                    speed_adjustment = self.velocity_pid.update(speed_error)

                    final_vector = vector.normalize() * (target_speed + speed_adjustment)
                    target_vx = final_vector.x
                    target_vy = final_vector.y

                    self.stats['vector_field_updates'] += 1

                    self.last_decision_info = {
                        'vector_angle': math.atan2(vector.y, vector.x),
                        'vector_magnitude': vector.magnitude(),
                        'grid_score': len(self.exploration_grid.frontier_cells) / 100.0,
                        'speed_factor': speed_factor,
                        'red_objects_in_view': perception.red_objects_count,
                        'blue_objects_in_view': perception.blue_objects_count,
                        'black_objects_in_view': perception.black_objects_count,
                        'decision_time': time.time() - decision_start
                    }

                    if self.exploration_target:
                        distance_to_target = math.sqrt(
                            (self.exploration_target[0] - current_pos[0])**2 +
                            (self.exploration_target[1] - current_pos[1])**2
                        )
                        if distance_to_target < self.target_reached_distance:
                            self.exploration_target = None
                            self.change_state(FlightState.HOVERING)
                            self.logger.info("âœ… åˆ°è¾¾æ¢ç´¢ç›®æ ‡")

            elif self.state == FlightState.AVOIDING:
                if perception.has_obstacle:
                    current_pos = (pos.x_val, pos.y_val)

                    avoid_vector = self.vector_planner.compute_vector(
                        current_pos,
                        None,
                        perception.obstacle_positions,
                        perception.red_objects,
                        perception.blue_objects,
                        perception.black_objects
                    )

                    if avoid_vector.magnitude() > 0.1:
                        avoid_vector = avoid_vector.normalize() * 1.5
                        target_vx = avoid_vector.x
                        target_vy = avoid_vector.y

                    target_z = pos.z_val - 3
                else:
                    self.change_state(FlightState.EXPLORING)
                    time.sleep(1)

            elif self.state == FlightState.RED_OBJECT_INSPECTION:
                target_vx, target_vy = 0.0, 0.0
                time.sleep(2)
                self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.BLUE_OBJECT_INSPECTION:
                target_vx, target_vy = 0.0, 0.0
                time.sleep(2)
                self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.BLACK_OBJECT_INSPECTION:
                target_vx, target_vy = 0.0, 0.0
                time.sleep(2)
                self.change_state(FlightState.EXPLORING)

            elif self.state == FlightState.EMERGENCY:
                target_vx, target_vy, target_yaw = 0, 0, 0
                target_z = max(pos.z_val, -20)

            elif self.state == FlightState.PLANNING:
                target_vx, target_vy = 0, 0
                target_z = perception.recommended_height

            height_error = target_z - pos.z_val
            height_adjustment = self.height_pid.update(height_error)
            target_z += height_adjustment

            target_z = max(self.max_altitude, min(self.min_altitude, target_z))

            decision_time = time.time() - decision_start
            self.last_decision_info['total_decision_time'] = decision_time

            return target_vx, target_vy, target_z, target_yaw

        except Exception as e:
            self.logger.error(f"âŒ å†³ç­–è¿‡ç¨‹å¼‚å¸¸: {e}")
            if self.data_logger:
                self.data_logger.record_event('decision_exception', {'error': str(e)})
            return 0.0, 0.0, self.base_height, 0.0

    def _calculate_adaptive_speed(self, perception: PerceptionResult, vector_magnitude: float) -> float:
        if not config.INTELLIGENT_DECISION['ADAPTIVE_SPEED_ENABLED']:
            return 1.0

        open_factor = min(1.0, perception.open_space_score * 1.2)

        if perception.obstacle_distance < self.depth_threshold_near * 2:
            obs_factor = max(0.3, perception.obstacle_distance / (self.depth_threshold_near * 2))
        else:
            obs_factor = 1.0

        vector_factor = min(1.0, vector_magnitude * 2)

        red_factor = 0.8 if perception.red_objects_count > 0 else 1.0
        blue_factor = 0.8 if perception.blue_objects_count > 0 else 1.0
        black_factor = 0.8 if perception.black_objects_count > 0 else 1.0
        color_factor = min(red_factor, blue_factor, black_factor)

        speed_factor = open_factor * obs_factor * vector_factor * color_factor * 0.7

        speed_factor = max(
            config.INTELLIGENT_DECISION['MIN_SPEED_FACTOR'],
            min(config.INTELLIGENT_DECISION['MAX_SPEED_FACTOR'], speed_factor)
        )

        return speed_factor

    def _execute_control_decision(self, decision):
        try:
            target_vx, target_vy, target_z, target_yaw = decision

            if self.state in [FlightState.EXPLORING, FlightState.AVOIDING, FlightState.PLANNING,
                              FlightState.RED_OBJECT_INSPECTION, FlightState.BLUE_OBJECT_INSPECTION,
                              FlightState.BLACK_OBJECT_INSPECTION]:
                self.client.moveByVelocityZAsync(
                    target_vx, target_vy, target_z, 0.5,
                    drivetrain=airsim.DrivetrainType.MaxDegreeOfFreedom,
                    yaw_mode=airsim.YawMode(is_rate=False, yaw_or_rate=target_yaw),
                    vehicle_name=self.drone_name
                )
            else:
                self.client.moveToPositionAsync(
                    0, 0, target_z, 2,
                    vehicle_name=self.drone_name
                )

            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position
            self.visited_positions.append((pos.x_val, pos.y_val, pos.z_val))

        except Exception as e:
            self.logger.warning(f"âš ï¸ æ§åˆ¶æŒ‡ä»¤æ‰§è¡Œå¤±è´¥: {e}")
            if self.data_logger:
                self.data_logger.record_event('control_exception', {'error': str(e)})
            try:
                self.client.hoverAsync(vehicle_name=self.drone_name).join()
            except:
                pass

    def _report_status(self, exploration_start, perception):
        elapsed = time.time() - exploration_start
        try:
            state = self.client.getMultirotorState(vehicle_name=self.drone_name)
            pos = state.kinematics_estimated.position

            self.logger.info(f"\nğŸ“Š ç³»ç»ŸçŠ¶æ€æŠ¥å‘Š [å¾ªç¯#{self.loop_count}]")
            self.logger.info(f"   è¿è¡Œæ—¶é—´: {elapsed:.1f}s / {self.exploration_time}s")
            self.logger.info(f"   é£è¡ŒçŠ¶æ€: {self.state.value}")
            self.logger.info(f"   å½“å‰ä½ç½®: ({pos.x_val:.1f}, {pos.y_val:.1f}, {-pos.z_val:.1f}m)")
            self.logger.info(f"   ç¯å¢ƒæ„ŸçŸ¥: éšœç¢{'æœ‰' if perception.has_obstacle else 'æ— '} "
                            f"| è·ç¦»={perception.obstacle_distance:.1f}m "
                            f"| å¼€é˜”åº¦={perception.open_space_score:.2f}")
            self.logger.info(f"   çº¢è‰²ç‰©ä½“: æ£€æµ‹åˆ°{perception.red_objects_count}ä¸ª "
                            f"| å·²è®¿é—®{self.stats['red_objects_visited']}ä¸ª")
            self.logger.info(f"   è“è‰²ç‰©ä½“: æ£€æµ‹åˆ°{perception.blue_objects_count}ä¸ª "
                            f"| å·²è®¿é—®{self.stats['blue_objects_visited']}ä¸ª")
            self.logger.info(f"   é»‘è‰²ç‰©ä½“: æ£€æµ‹åˆ°{perception.black_objects_count}ä¸ª "
                            f"| å·²è®¿é—®{self.stats['black_objects_visited']}ä¸ª")
            self.logger.info(f"   æ™ºèƒ½å†³ç­–: å‘é‡åœº{self.stats['vector_field_updates']}æ¬¡ "
                            f"| ç½‘æ ¼æ›´æ–°{self.stats['grid_updates']}æ¬¡")
            self.logger.info(f"   æ¢ç´¢ç½‘æ ¼: å‰æ²¿{len(self.exploration_grid.frontier_cells)}ä¸ª")
            self.logger.info(f"   ç³»ç»Ÿç»Ÿè®¡: å¼‚å¸¸{self.stats['exceptions_caught']}æ¬¡ "
                            f"| çŠ¶æ€åˆ‡æ¢{self.stats['state_changes']}æ¬¡")
            self.logger.info(f"   æ•°æ®è®°å½•: {self.stats['data_points_recorded']}ä¸ªæ•°æ®ç‚¹")
            self.logger.info(f"   æ€§èƒ½ç»Ÿè®¡: å¹³å‡å¾ªç¯{self.stats['average_loop_time']*1000:.1f}ms "
                            f"| æœ€å¤§{self.stats['max_loop_time']*1000:.1f}ms "
                            f"| æœ€å°{self.stats['min_loop_time']*1000:.1f}ms")
            if self.stats['manual_control_time'] > 0:
                self.logger.info(f"   æ‰‹åŠ¨æ§åˆ¶: {self.stats['manual_control_time']:.1f}ç§’")
        except:
            self.logger.info("çŠ¶æ€æŠ¥å‘Š: æ— æ³•è·å–æ— äººæœºçŠ¶æ€")

    def _finish_mission(self):
        self.logger.info("=" * 60)
        self.logger.info("æ¢ç´¢ä»»åŠ¡å®Œæˆï¼Œå¼€å§‹è¿”èˆªç¨‹åº")
        self.logger.info("=" * 60)

        self.change_state(FlightState.RETURNING)

        try:
            self.logger.info("â†©ï¸ è¿”å›èµ·å§‹åŒºåŸŸ...")
            self.client.moveToPositionAsync(0, 0, -10, 4, vehicle_name=self.drone_name).join()
            time.sleep(2)

            self.logger.info("ğŸ›¬ é™è½ä¸­...")
            self.change_state(FlightState.LANDING)
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(3)

        except Exception as e:
            self.logger.error(f"âŒ é™è½è¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸: {e}")

        finally:
            self._cleanup_system()

            self._generate_summary_report()

    def _cleanup_system(self):
        self.logger.info("ğŸ§¹ æ¸…ç†ç³»ç»Ÿèµ„æº...")

        try:
            self.client.armDisarm(False, vehicle_name=self.drone_name)
            self.client.enableApiControl(False, vehicle_name=self.drone_name)
            self.logger.info("âœ… æ— äººæœºæ§åˆ¶å·²å®‰å…¨é‡Šæ”¾")
        except:
            self.logger.warning("âš ï¸ é‡Šæ”¾æ§åˆ¶æ—¶å‡ºç°å¼‚å¸¸")

        if self.front_window:
            self.front_window.stop()
            self.logger.info("âœ… å‰è§†çª—å£å·²å…³é—­")

        if self.info_window:
            self.info_window.stop()
            self.logger.info("âœ… ä¿¡æ¯çª—å£å·²å…³é—­")

        if self.data_logger:
            self.logger.info("ğŸ’¾ æ­£åœ¨ä¿å­˜é£è¡Œæ•°æ®...")
            self.data_logger.save_json_data()

            if config.PERFORMANCE['SAVE_PERFORMANCE_REPORT']:
                performance_report = self.data_logger.generate_performance_report()
                self.logger.info(performance_report)

                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                report_filename = f"performance_report_{timestamp}.txt"
                with open(report_filename, 'w', encoding='utf-8') as f:
                    f.write(performance_report)
                self.logger.info(f"ğŸ“„ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")

    def _generate_summary_report(self):
        total_time = time.time() - self.start_time

        self.logger.info("\n" + "=" * 60)
        self.logger.info("ğŸ ä»»åŠ¡æ€»ç»“æŠ¥å‘Š")
        self.logger.info("=" * 60)
        self.logger.info(f"   æ€»è¿è¡Œæ—¶é—´: {total_time:.1f}ç§’")
        self.logger.info(f"   æ€»å¾ªç¯æ¬¡æ•°: {self.loop_count}")
        if total_time > 0:
            self.logger.info(f"   å¹³å‡å¾ªç¯é¢‘ç‡: {self.loop_count/total_time:.1f} Hz")
        self.logger.info(f"   æ¢ç´¢èˆªç‚¹æ•°é‡: {len(self.visited_positions)}")
        self.logger.info(f"   çŠ¶æ€åˆ‡æ¢æ¬¡æ•°: {self.stats['state_changes']}")
        self.logger.info(f"   æ£€æµ‹åˆ°éšœç¢æ¬¡æ•°: {self.stats['obstacles_detected']}")
        self.logger.info(f"   çº¢è‰²ç‰©ä½“æ£€æµ‹: {self.stats['red_objects_detected']}ä¸ª")
        self.logger.info(f"   çº¢è‰²ç‰©ä½“è®¿é—®: {self.stats['red_objects_visited']}ä¸ª")
        self.logger.info(f"   è“è‰²ç‰©ä½“æ£€æµ‹: {self.stats['blue_objects_detected']}ä¸ª")
        self.logger.info(f"   è“è‰²ç‰©ä½“è®¿é—®: {self.stats['blue_objects_visited']}ä¸ª")
        self.logger.info(f"   é»‘è‰²ç‰©ä½“æ£€æµ‹: {self.stats['black_objects_detected']}ä¸ª")
        self.logger.info(f"   é»‘è‰²ç‰©ä½“è®¿é—®: {self.stats['black_objects_visited']}ä¸ª")
        self.logger.info(f"   å‘é‡åœºè®¡ç®—æ¬¡æ•°: {self.stats['vector_field_updates']}")
        self.logger.info(f"   ç½‘æ ¼æ›´æ–°æ¬¡æ•°: {self.stats['grid_updates']}")
        self.logger.info(f"   æ¢ç´¢å‰æ²¿æ•°é‡: {len(self.exploration_grid.frontier_cells)}")
        self.logger.info(f"   å‰è§†å›¾åƒæ›´æ–°æ¬¡æ•°: {self.stats['front_image_updates']}")
        self.logger.info(f"   æ•°æ®è®°å½•ç‚¹æ•°: {self.stats['data_points_recorded']}")
        self.logger.info(f"   æ‰‹åŠ¨æ§åˆ¶æ—¶é—´: {self.stats['manual_control_time']:.1f}ç§’")
        self.logger.info(f"   æ•è·çš„å¼‚å¸¸æ•°: {self.stats['exceptions_caught']}")
        self.logger.info(f"   é‡è¿å°è¯•æ¬¡æ•°: {self.reconnect_attempts}")
        self.logger.info(f"   å¹³å‡å¾ªç¯æ—¶é—´: {self.stats['average_loop_time']*1000:.1f}ms")
        self.logger.info(f"   æœ€å¤§å¾ªç¯æ—¶é—´: {self.stats['max_loop_time']*1000:.1f}ms")
        self.logger.info(f"   æœ€å°å¾ªç¯æ—¶é—´: {self.stats['min_loop_time']*1000:.1f}ms")

        try:
            report_filename = f"mission_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write("AirSimNH æ— äººæœºä»»åŠ¡æŠ¥å‘Š (æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆ - åŒçª—å£åŒè‰²ç‰©ä½“æ£€æµ‹ç‰ˆ)\n")
                f.write("=" * 50 + "\n")
                f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»è¿è¡Œæ—¶é—´: {total_time:.1f}ç§’\n")
                f.write(f"æ€»å¾ªç¯æ¬¡æ•°: {self.loop_count}\n")
                f.write(f"æ¢ç´¢èˆªç‚¹æ•°é‡: {len(self.visited_positions)}\n")
                f.write(f"çŠ¶æ€åˆ‡æ¢æ¬¡æ•°: {self.stats['state_changes']}\n")
                f.write(f"å‘é‡åœºè®¡ç®—æ¬¡æ•°: {self.stats['vector_field_updates']}\n")
                f.write(f"ç½‘æ ¼æ›´æ–°æ¬¡æ•°: {self.stats['grid_updates']}\n")
                f.write(f"æ¢ç´¢å‰æ²¿æ•°é‡: {len(self.exploration_grid.frontier_cells)}\n")
                f.write(f"æ•°æ®è®°å½•ç‚¹æ•°: {self.stats['data_points_recorded']}\n")
                f.write(f"æ‰‹åŠ¨æ§åˆ¶æ—¶é—´: {self.stats['manual_control_time']:.1f}ç§’\n")
                f.write(f"çº¢è‰²ç‰©ä½“æ£€æµ‹æ€»æ•°: {self.stats['red_objects_detected']}ä¸ª\n")
                f.write(f"çº¢è‰²ç‰©ä½“å·²è®¿é—®æ•°: {self.stats['red_objects_visited']}ä¸ª\n")
                f.write(f"è“è‰²ç‰©ä½“æ£€æµ‹æ€»æ•°: {self.stats['blue_objects_detected']}ä¸ª\n")
                f.write(f"è“è‰²ç‰©ä½“å·²è®¿é—®æ•°: {self.stats['blue_objects_visited']}ä¸ª\n")
                f.write(f"é»‘è‰²ç‰©ä½“æ£€æµ‹æ€»æ•°: {self.stats['black_objects_detected']}ä¸ª\n")
                f.write(f"é»‘è‰²ç‰©ä½“å·²è®¿é—®æ•°: {self.stats['black_objects_visited']}ä¸ª\n")
                f.write(f"å¼‚å¸¸æ•è·æ¬¡æ•°: {self.stats['exceptions_caught']}\n")
                f.write(f"å‰è§†å›¾åƒæ›´æ–°æ¬¡æ•°: {self.stats['front_image_updates']}\n")
                f.write(f"å¹³å‡å¾ªç¯æ—¶é—´: {self.stats['average_loop_time']*1000:.1f}ms\n")
                f.write(f"æœ€å¤§å¾ªç¯æ—¶é—´: {self.stats['max_loop_time']*1000:.1f}ms\n")
                f.write(f"æœ€å°å¾ªç¯æ—¶é—´: {self.stats['min_loop_time']*1000:.1f}ms\n")
                f.write("=" * 50 + "\n")
                f.write("æ™ºèƒ½å†³ç­–é…ç½®:\n")
                for key, value in config.INTELLIGENT_DECISION.items():
                    f.write(f"  {key}: {value}\n")
                f.write("=" * 50 + "\n")
                f.write("é£è¡Œèˆªç‚¹è®°å½•:\n")
                for i, pos in enumerate(self.visited_positions[:20]):
                    f.write(f"  èˆªç‚¹{i+1}: ({pos[0]:.1f}, {pos[1]:.1f}, {pos[2]:.1f})\n")
                if len(self.visited_positions) > 20:
                    f.write(f"  ... è¿˜æœ‰{len(self.visited_positions)-20}ä¸ªèˆªç‚¹\n")
                f.write("=" * 50 + "\n")
                f.write("æ•°æ®è®°å½•ä¿¡æ¯:\n")
                if self.data_logger and config.DATA_RECORDING['ENABLED']:
                    f.write(f"  CSVæ–‡ä»¶: {self.data_logger.csv_filename}\n")
                    f.write(f"  JSONæ–‡ä»¶: {self.data_logger.json_filename}\n")
                else:
                    f.write("  æ•°æ®è®°å½•æœªå¯ç”¨\n")
            self.logger.info(f"ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_filename}")
        except Exception as e:
            self.logger.warning(f"âš ï¸ æ— æ³•ä¿å­˜æŠ¥å‘Šæ–‡ä»¶: {e}")

    def emergency_stop(self):
        if self.emergency_flag:
            return

        self.logger.error("\nğŸ†˜ ç´§æ€¥åœæ­¢ç¨‹åºå¯åŠ¨!")
        self.emergency_flag = True

        self.change_state(FlightState.EMERGENCY)

        try:
            self.client.hoverAsync(vehicle_name=self.drone_name).join()
            time.sleep(1)
            self.client.landAsync(vehicle_name=self.drone_name).join()
            time.sleep(2)
            self.logger.info("âœ… ç´§æ€¥é™è½æŒ‡ä»¤å·²å‘é€")
        except Exception as e:
            self.logger.error(f"âš ï¸ ç´§æ€¥é™è½å¼‚å¸¸: {e}")

        if self.front_window:
            self.front_window.stop()

        if self.info_window:
            self.info_window.stop()

        self._cleanup_system()


# ==================== ä¸»ç¨‹åºå…¥å£ ====================

def main():
    print("=" * 70)
    print("AirSimNH æ— äººæœºæ„ŸçŸ¥æ¢ç´¢ç³»ç»Ÿ - æ™ºèƒ½å†³ç­–å¢å¼ºç‰ˆï¼ˆåŒçª—å£åŒè‰²ç‰©ä½“æ£€æµ‹ç‰ˆï¼‰")
    print(f"å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"é…ç½®çŠ¶æ€: {'å·²åŠ è½½' if CONFIG_LOADED else 'ä½¿ç”¨é»˜è®¤é…ç½®'}")
    print(f"æ—¥å¿—çº§åˆ«: {config.SYSTEM['LOG_LEVEL']}")
    print(f"æ¢ç´¢æ—¶é—´: {config.EXPLORATION['TOTAL_TIME']}ç§’")
    print("=" * 70)
    print("æ™ºèƒ½å†³ç­–ç‰¹æ€§:")
    print("  â€¢ å‘é‡åœºé¿éšœç®—æ³• (VFH)")
    print("  â€¢ åŸºäºç½‘æ ¼çš„ä¿¡æ¯å¢ç›Šæ¢ç´¢")
    print("  â€¢ PIDå¹³æ»‘é£è¡Œæ§åˆ¶")
    print("  â€¢ è‡ªé€‚åº”é€Ÿåº¦è°ƒæ•´")
    print("  â€¢ æ€§èƒ½ç›‘æ§ä¸æ•°æ®é—­ç¯")
    print("  â€¢ çº¢è‰²ä¸è“è‰²ç‰©ä½“æ£€æµ‹ä¸è®°å½•")
    print("=" * 70)
    print("æ˜¾ç¤ºç³»ç»Ÿ:")
    print("  â€¢ åŒçª—å£æ¨¡å¼: å‰è§†çª—å£ + ä¿¡æ¯çª—å£")
    print("  â€¢ å‰è§†çª—å£: æ‘„åƒå¤´ç”»é¢ã€æ‰‹åŠ¨æ§åˆ¶")
    print("  â€¢ ä¿¡æ¯çª—å£: ç³»ç»ŸçŠ¶æ€ã€æ¢ç´¢ç½‘æ ¼ã€ç‰©ä½“ç»Ÿè®¡")
    print("=" * 70)
    print("æ•°æ®è®°å½•:")
    print(f"  â€¢ CSVæ ¼å¼: {config.DATA_RECORDING.get('SAVE_TO_CSV', False)}")
    print(f"  â€¢ JSONæ ¼å¼: {config.DATA_RECORDING.get('SAVE_TO_JSON', False)}")
    print(f"  â€¢ æ€§èƒ½ç›‘æ§: {config.DATA_RECORDING.get('PERFORMANCE_MONITORING', False)}")
    print(f"  â€¢ çº¢è‰²ç‰©ä½“è®°å½•: {config.DATA_RECORDING.get('RECORD_RED_OBJECTS', False)}")
    print(f"  â€¢ è“è‰²ç‰©ä½“è®°å½•: {config.DATA_RECORDING.get('RECORD_BLUE_OBJECTS', False)}")
    print("=" * 70)

    print("\nè¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("  1. æ™ºèƒ½æ¢ç´¢æ¨¡å¼ (AIè‡ªä¸»å†³ç­–ï¼ŒåŒ…å«åŒè‰²ç‰©ä½“æ£€æµ‹)")
    print("  2. æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼ (é”®ç›˜æ§åˆ¶)")
    print("  3. æ··åˆæ¨¡å¼ (å…ˆè‡ªåŠ¨æ¢ç´¢ï¼Œåå¯åˆ‡æ¢)")
    print("=" * 50)

    mode_choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

    explorer = None
    try:
        explorer = PerceptiveExplorer(drone_name="")

        def signal_handler(sig, frame):
            print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­ï¼Œæ­£åœ¨å®‰å…¨åœæ­¢...")
            if explorer:
                explorer.emergency_stop()
            sys.exit(0)

        signal.signal(signal.SIGINT, signal_handler)

        if mode_choice == '1':
            print("\n" + "="*50)
            print("å¯åŠ¨æ™ºèƒ½æ¢ç´¢æ¨¡å¼ï¼ˆå«åŒè‰²ç‰©ä½“æ£€æµ‹ï¼‰")
            print("="*50)
            print("æ³¨æ„ï¼šå°†æ‰“å¼€ä¸¤ä¸ªçª—å£:")
            print("  1. å‰è§†çª—å£ - æ˜¾ç¤ºæ‘„åƒå¤´ç”»é¢")
            print("  2. ä¿¡æ¯çª—å£ - æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€å’Œæ¢ç´¢ä¿¡æ¯")
            print("="*50)
            explorer.run_perception_loop()

        elif mode_choice == '2':
            print("\n" + "="*50)
            print("å¯åŠ¨æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
            print("="*50)

            print("æ­£åœ¨èµ·é£...")
            explorer.client.takeoffAsync(vehicle_name="").join()
            time.sleep(2)
            explorer.client.moveToZAsync(-10, 3, vehicle_name="").join()
            time.sleep(2)
            print("èµ·é£å®Œæˆï¼Œå¯ä»¥å¼€å§‹æ‰‹åŠ¨æ§åˆ¶")
            print("è¯·åˆ‡æ¢åˆ°æ— äººæœºå‰è§†çª—å£ï¼Œä½¿ç”¨WSADé”®æ§åˆ¶")

            explorer.run_manual_control()

        elif mode_choice == '3':
            print("\n" + "="*50)
            print("å¯åŠ¨æ··åˆæ¨¡å¼")
            print("="*50)

            explorer.logger.info("ğŸ” å¼€å§‹æ™ºèƒ½æ¢ç´¢ï¼ˆå«åŒè‰²ç‰©ä½“æ£€æµ‹ï¼‰...")
            original_time = config.EXPLORATION['TOTAL_TIME']
            explorer.exploration_time = min(60, original_time)

            explorer.run_perception_loop()

            if not explorer.emergency_flag:
                print("\n" + "="*50)
                print("æ™ºèƒ½æ¢ç´¢é˜¶æ®µç»“æŸ")
                print(f"æ£€æµ‹åˆ°çº¢è‰²ç‰©ä½“: {explorer.stats['red_objects_detected']}ä¸ª")
                print(f"æ£€æµ‹åˆ°è“è‰²ç‰©ä½“: {explorer.stats['blue_objects_detected']}ä¸ª")
                print(f"æ£€æµ‹åˆ°é»‘è‰²ç‰©ä½“: {explorer.stats['black_objects_detected']}ä¸ª")
                print("è¯·é€‰æ‹©ä¸‹ä¸€æ­¥:")
                print("  1. è¿›å…¥æ‰‹åŠ¨æ§åˆ¶æ¨¡å¼")
                print("  2. ç»§ç»­æ™ºèƒ½æ¢ç´¢")
                print("  3. ç»“æŸä»»åŠ¡è¿”èˆª")
                print("="*50)

                next_choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()

                if next_choice == '1':
                    explorer.run_manual_control()
                elif next_choice == '2':
                    explorer.exploration_time = original_time - 60
                    if explorer.exploration_time > 10:
                        explorer.run_perception_loop()
                    else:
                        explorer.logger.info("â° å‰©ä½™æ—¶é—´ä¸è¶³ï¼Œå¼€å§‹è¿”èˆª")
                        explorer._finish_mission()
                else:
                    explorer._finish_mission()

        else:
            print("âŒ æ— æ•ˆçš„é€‰æ‹©ï¼Œç¨‹åºé€€å‡º")
            if explorer:
                explorer._cleanup_system()

    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¯åŠ¨å¼‚å¸¸: {e}")
        traceback.print_exc()

        try:
            if explorer and explorer.client:
                explorer.client.landAsync().join()
                explorer.client.armDisarm(False)
                explorer.client.enableApiControl(False)
        except:
            pass


if __name__ == "__main__":
    main()